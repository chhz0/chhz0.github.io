[{"content":" Makefile 快速入门\n概述 makefile 关系到了整个工程的编译规则，makefile 定义了一系列的规则来指定，哪些文件需要先编译，哪些文件后需要编译，哪些文件需要重新编译，甚者进行更复杂的功能操作，makefile 像 shell脚本一样，其中也可以执行操作系统的命令。\nmakefile带来的好处是-“自动化编译”，一旦写好，一个make命令，整个工程完全自动编译，极大提高了软件开发的效率。make是一个命令工具，是一个解释makefile中指令的命令工具。\nMakefile结构说明 makefile 主要包含了五个东西：变量定义，显示规则，隐晦规则，文件标示和注释。\n变量定义。在makefile中我们需要定义一系列的变量，一般是字符串，当makefile被执行时，其中的变量都会被扩展到相应的引用位置上。 显示规则。说明了如何生成一个或者多个目标文件，由makefile的书写者明显指出，要生成的文件，文件的依赖文件，生成的文件。【可类似shell脚本】 隐晦规则。由于make有自动推导功能，使用隐晦的规则可以让我们比较粗糙地简略书写makefile 文件指示。其中包括了三个部分。\\ 注释。Makefile中只有行注释，使用 # 字符 Makefile中的预定义变量 预定变量 说明 $* 不包含扩展名的目标文件名称 $+ 所有的依赖文件，以空格分开，并以出现的先后为序，可能包含重复的依赖文件 $\u0026lt; 第一个依赖文件的名称 $? 所有的依赖文件，以空格分开，这些依赖文件的修改日期比目标的创建日期晚 $@ 目标的完整名称 $^ 所有的依赖文件，以空格分开，不包含重复的依赖文件 $% 如果目标是归档成员，则该变量表示目标的归档成员名称 Go Makefile 使用makefile快速编译Go web程序，期望：\n高级、简单的命令。比如：compile start stop watch 等等 管理具体项目环境的变量，它应该包含 .env 文件 开发模式，修改时自动编译 开发模式，修改时自动重启服务 开发模式，简洁地显示编译的错误信息 具体项目的GOPATH，可以在vendor目录维护依赖包 简化文件查看， 1. 环境变量 在makefile中 include为项目定义环境变量，第一行如下\ninclude .env ^^^ (待补充\u0026hellip;)\nfinal.最终版本 include .env PROJECTNAME=$(shell basename \u0026#34;$(PWD)\u0026#34;) # Go related variables. GOBASE=$(shell pwd) GOPATH=\u0026#34;$(GOBASE)/vendor:$(GOBASE) GOBIN=$(GOBASE)/bin GOFILES=$(wildcard *.go) # Redirect error output to a file, so we can show it in development mode. STDERR=/tmp/.$(PROJECTNAME)-stderr.txt # PID file will keep the process id of the server PID=/tmp/.$(PROJECTNAME).pid # Make is verbose in Linux. Make it silent. MAKEFLAGS += --silent ## install: Install missing dependencies. Runs `go get` internally. e.g; make install get=github.com/foo/bar install: go-get ## start: Start in development mode. Auto-starts when code changes. start: bash -c \u0026#34;trap \u0026#39;make stop\u0026#39; EXIT; $(MAKE) compile start-server watch run=\u0026#39;make compile start-server\u0026#39;\u0026#34; ## stop: Stop development mode. stop: stop-server start-server: stop-server @echo \u0026#34; \u0026gt; $(PROJECTNAME) is available at $(ADDR)\u0026#34; @-$(GOBIN)/$(PROJECTNAME) 2\u0026gt;\u0026amp;1 \u0026amp; echo $$! \u0026gt; $(PID) @cat $(PID) | sed \u0026#34;/^/s/^/ \\\u0026gt; PID: /\u0026#34; stop-server: @-touch $(PID) @-kill `cat $(PID)` 2\u0026gt; /dev/null || true @-rm $(PID) ## watch: Run given command when code changes. e.g; make watch run=\u0026#34;echo \u0026#39;hey\u0026#39;\u0026#34; watch: @GOPATH=$(GOPATH) GOBIN=$(GOBIN) yolo -i . -e vendor -e bin -c \u0026#34;$(run)\u0026#34; restart-server: stop-server start-server ## compile: Compile the binary. compile: @-touch $(STDERR) @-rm $(STDERR) @-$(MAKE) -s go-compile 2\u0026gt; $(STDERR) @cat $(STDERR) | sed -e \u0026#39;1s/.*/\\nError:\\n/\u0026#39; | sed \u0026#39;s/make\\[.*/ /\u0026#39; | sed \u0026#34;/^/s/^/ /\u0026#34; 1\u0026gt;\u0026amp;2 ## exec: Run given command, wrapped with custom GOPATH. e.g; make exec run=\u0026#34;go test ./...\u0026#34; exec: @GOPATH=$(GOPATH) GOBIN=$(GOBIN) $(run) ## clean: Clean build files. Runs `go clean` internally. clean: @(MAKEFILE) go-clean go-compile: go-clean go-get go-build go-build: @echo \u0026#34; \u0026gt; Building binary...\u0026#34; @GOPATH=$(GOPATH) GOBIN=$(GOBIN) go build -o $(GOBIN)/$(PROJECTNAME) $(GOFILES) go-generate: @echo \u0026#34; \u0026gt; Generating dependency files...\u0026#34; @GOPATH=$(GOPATH) GOBIN=$(GOBIN) go generate $(generate) go-get: @echo \u0026#34; \u0026gt; Checking if there is any missing dependencies...\u0026#34; @GOPATH=$(GOPATH) GOBIN=$(GOBIN) go get $(get) go-install: @GOPATH=$(GOPATH) GOBIN=$(GOBIN) go install $(GOFILES) go-clean: @echo \u0026#34; \u0026gt; Cleaning build cache\u0026#34; @GOPATH=$(GOPATH) GOBIN=$(GOBIN) go clean .PHONY: help all: help help: Makefile @echo @echo \u0026#34; Choose a command run in \u0026#34;$(PROJECTNAME)\u0026#34;:\u0026#34; @echo @sed -n \u0026#39;s/^##//p\u0026#39; $\u0026lt; | column -t -s \u0026#39;:\u0026#39; | sed -e \u0026#39;s/^/ /\u0026#39; @echo 相关资料 (陈皓) 跟我一起写 Makefile（一）_haoel的博客-CSDN博客_makefile标签 Makefile由浅入深\u0026ndash;教程、干货 - 知乎 (zhihu.com) ","date":"2025-07-04","id":0,"permalink":"/blogs/2025/0704.makefile-learn/","summary":"Makefile 快速入门","tags":"Makefile","title":"Makefile-learn"},{"content":" MySQL 事务\n1.事务有哪些特征 原子性，隔离性，一致性，持久性\n原子性：要么全做，要么全不做\n隔离性：保证其它的状态转换不会影响到本次状态的转\n一致性：数据全部符合现实世界的约束\n持久性： 更新后的数据存储到磁盘\nInnoDB引擎通过以下技术来保证事务的四个特性\n持久性是通过 redo log（重做日志）来保证\n原子性是通过 undo log（回滚日志）来保证\n隔离性是通过 mvcc（多版本并发控制）或者锁机制来保证\n一致性是通过持久性+原子性+隔离性来保证\n2.并发事务会引发的问题 MySQL服务端是允许多个客户端连接，这意味着MySQL会出现同时处理多个事务的情况\n在同时处理多个事务的时候，可能会出现脏读、不可重复读、幻读的问题\n脏读：一个事务读到了另一个未提交事务修改过的数据\n不可重复读：在一个事务中多次读取同一个数据，出现前后两次读到的数据不一样的情况\n幻读：在一个事务中多次查询某个符合查询条件的记录数量，如果出现前后两次查询到的记录数据不一样的情况\n以上三个现象，问题的严重性是 脏读 \u0026gt; 不可重复读 \u0026gt; 幻读\n3.事务的隔离级别 四种隔离级别：\n读未提交：指一个事务还没有提交时，它做的变更就能被其他事务看到\n读提交：指一个事务提交之后，它做的变更才能被其他事务看到\n可重复读：指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB引擎的默认隔离级别\n串行化：对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生读写冲突的时候，后访问的事务必须等前一个事务执行完成\n按隔离水平高低排序如下：\n串行化 \u0026gt; 可重复读 \u0026gt; 读已提交 \u0026gt; 读未提交\n针对不同的隔离级别：并发事务时可能发生的现象也不同\n读未提交：脏读、不可重复读、幻读\n读提交：不可重复读、幻读\n可重复读：幻读\n串行化：\n可重复读的隔离级别下，可以很大程度上避免幻读现象的发生，所以MySQL不使用串行化隔离级别来避免幻读现象的发生，因为串行化隔离级别会影响性能\nInnoDB在默认隔离级别：可重复读的情况下很大程度上解决幻读现象的解决方案有两种：\n针对**快照读（普通 select 语句），**是通过MVCC方式解决幻读\n针对**当前读（select \u0026hellip; for update），**通过next-key lock（记录锁+间隙锁）方式解决了幻读\n四种隔离事务是怎么实现的\n对于读未提交：可以读到未提交事务修改的数据，所以直接读取就行\n对于串行化，通过加读写锁的方式来避免并行访问\n对于读提交和可重复读这两种隔离级别的事务，是通过Read View来实现的，它们的区别是在于创建Read View时，读提交隔离级别是在每个语句执行之前都会重新生成一个Read View；而可重复读隔离级别是启动事务时生成一个Read View，然后整个事务都在用这个Read View\n在执行开启事务命令，并不意味着启动了事务：\n在MySQL中，开启事务有两种命令，分别是：\nbegin/start transaction，执行命令后，并不意味着事务启动，只有执行了第一条select语句，才是事务真正启动的时机\nstart transaction with consistent snapshot，马上启动事务\nRead View在MVCC中是如何工作的？ Read View的四个字段\n\u0026lt;creator_trx_id\u0026gt; \u0026lt;m_ids\u0026gt; \u0026lt;min_trx_id\u0026gt; \u0026lt;max_trx_id\u0026gt; creator_trx_id:创建该Read View的事务的事务id\nm_ids:指创建Read View时，当前数据库中活跃事务的事务id列表\nmin_trx_id:生成ReadView时系统中活跃的事务中最小的事务id，即m_ids中的最小的事务id，也是表示活跃的事务最早的那个\nmax_trx_id:表示生成ReadView时系统中应该分配给下一个事务的id值\n这里还需要了解聚簇索引记录中的两个隐藏列，trx_id和roll_pointer\ntrx_id，当一个事务对某条聚簇索引进行改动时，会把该事务的事务id记录在trx_id隐藏列中\nroll_pointer，这个隐藏列是指针，指向每一个旧版本记录\n有了ReadView，以及undo log，在访问某条记录的时，按照以下步骤进行判断：\ntrx_id == creator_trx_id ，意味着当前事务在访问自己修改过的记录，可以访问\ntrx_id \u0026lt; min_trx_id ，表明生成该版本的事务在当前事务生成Read View前已经提交，可以访问\ntrx_id \u0026gt; max_trx_id ，表明生成该版本的事务在当前事务生成Read View后才开启，不可以访问\nmin_trx_id \u0026lt; trx_id \u0026lt; max_trx_ix ，还需要再进一步判断\ntrx_id 存在 m_ids 中，说明创建Read View时生成该版本的事务还是活跃的，不可以访问\ntrx_id 不在 m_ids 中，说明创建Read View时生成该版本的事务已经提交了，可以访问\nRead COMMITTD、REPETABLE READ这两种隔离级别的一个很大不同：生成ReadView的时机不同，REAED COMMITTD在每一次进行普通select操作前都会生成一个ReadView，而REPEATABLE READ只在第一次进行普通SELECT操作前生成一个ReadView，之后的查询操作都重复使用这个ReadView，不会再生成一个新的ReadView\n这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。\n可重复读是如何工作的？ 可重复读隔离级别是启动事务时生成一个Read View，然后整个事务期间都在用这个Read View\n如果某个事物开启后，去读取记录，发现记录的trx_id 比自己事物id小且在活跃的事物id列表里面有该事务id，那么该事务不会读取该版本的记录，而是沿着undo log链条往下找旧版本的记录，直到找到trx_id比事务b小的min_trx_id值的第一条记录\n读提交是如何工作的？ 读提交隔离事件在每次读取数据的时候，都会生成一个新的Read View\n","date":"2025-07-03","id":1,"permalink":"/notes/database/mysql/mysql-transaction/","summary":"MySQL 事务","tags":"MySQL","title":"Mysql Transaction(bate)"},{"content":" MySQL 日志 - undo log | redo log | bin log\n先理解执行一条sql语句，在mysql内部会发生什么？\n以执行一条update 语句为例：\n客户端会先通过连接器建立连接，连接器会判断用户身份\n这里是一条update语句，所以不需要经过查询缓存（注意，当表上有更新语句，会把整个查询缓存清空，所以在Mysql8.0这个功能就被移除了）\n解析器会通过词法分析识别出关键字，构建出语法树，接着做语法分析，判断输入的语句是否符合MySQL语法\n预处理器会判断表和字段是否存在\n优化器确定执行计划（使用索引或者全表查询）\n执行器负责具体执行，找到这一行然后更新\n不过，更新语句的流程会涉及到undo log**，redo log，binlog**三种日志：\nundo log（回滚日志）：是InnoDB存储引擎生成的日志，实现了事务中的原子性，主要用于事务回滚和MVCC\nredo log（重做日志）：是InnoDB存储引擎生成的日志，实现了事务中的持久性，主要用于掉电等故障恢复\nbing log（归档日志）：是Server层生成的日志，主要用于数据备份和主从复制\n1.为什么需要undo log？ 在执行一条“增删改”语句的时候，MySQL会隐式开启事务，执行完后自动提交事务\nMySQL中执行一条语句后是否自动提交事务，是由autocommit 参数来决定的，默认是开启的\n当事务执行过程中，都记录下回滚时需要的信息到一个日志中，那么在事务执行过程中发生MySQL崩溃后，可以通过这个日志回滚到事务之前的数据\n实现这一机制就是 undo log**（回滚日志），它保证了事务的ACID特性中的原子性**\n每当InnoDB引擎对每种操作进行回滚时，进行相反操作就行：\n插入 - 删除\n删除 - 插入\n更新 - 更新为旧值\n一条记录每次进行操作产生的undo log格式都有一个roll_pointer和一个trx_id事务id：\ntrx_id：记录该记录是被哪些事务修改的\nroll_pointer：指针可以将这些undo log串成一个链表，这个链表被称为版本链\n另外，undo log可以跟Read View一起实现MVCC（多版本并发控制）：\n对于 读提交 和 可重复读 隔离级别的事务来说，它们的快照读（普通select语句）是通过Read View + undo log来实现的，区别在于创建Read View的时机不同\n读提交：是在每一个select都会生成一个新的Read View，也意味着事务期间的多次读取同一数据，前后两次读的数据可能会出现不一致（不可重复读）\n可重复读：是在启动事务时生成一个Read View，然后整个事务期间都在用这个Read View，这样保证了事务期间读到的数据都是事务启动时的记录\n这两个隔离级别实现是通过事务的Read View里的字段和记录两个隐藏列trx_id和roll_pointer的对比\n事务隔离级别是怎么实现的？\n因此，undo log两大作用：\n实现事务回滚，保障事务的原子性\n实现MVCC（多版本并发控制）关键因素之一\nUndo log是如何刷盘？\nUndo log和数据页的刷盘策略是一样的，都需要通过redo log保证持久化\nBuffer pool中有undo 页，对undo页的修改都会被记录到redo log。redo log每秒刷盘，提交事务时也会刷盘，数据页和undo 页都是靠这个机制保证持久化\n2.为什么需要Buffer Pool？ MySQL的数据都是存储在磁盘中的，那么我们更新一条记录，得先从磁盘读取该记录，然后在内存中修改记录，修改完之后并不会直接写回磁盘，而是缓存起来，这样下次查询语句命中这条记录，就不需要从磁盘读取数据\n为此，InnoDB存储引擎设计了一个**缓冲池****Buffer Pool，**来提高数据库的读写性能\n暂时无法在飞书文档外展示此内容\n有了Buffer Pool后：\n当读取数据时，如果数据存在于Buffer Pool中，客户端会直接读取Buffer Pool中的数据，否则再去磁盘中读取\n当修改数据时，如果数据存在Buffer Pool中，那么直接修改Buffer Pool中数据所在的页，然后将页设置为脏页****（该页上的数据和磁盘上的不一样），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择以一个合适的时机将脏页写入到磁盘\nBuffer Pool缓冲了什么？ InnoDB会把存储的数据划分为若干个页，以页为磁盘和内存交互的基本单位，一个页的默认大小为16K\nBuffer Pool同样按 页 来划分\n在MySQL启动的时候，InnoDB会为Buffer Pool申请一片连续的内存空间，然后按照默认的**16k** 的大小划分一个个的页，Buffer Pool中的页叫做缓冲页。\nBuffer Pool除了缓存索引页和数据页，还包括Undo页，插入缓存，自适应哈希索引，锁信息等\nUndo 页是记录什么？\n开启事务后，InnoDB层更新记录前，首先要记录相应的undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是生成一个undo log，undo log会写入到undo页面\n查询一条记录，就只需要缓存一条记录吗？\n不是，当查询一条记录的时候，InnoDB会将整个页的数据加载到Buffer Pool中，将页加载到Buffer Pool后，再通过页里的页目录去定位到某条具体的记录 换一个角度看B+树\n3.为什么需要 redo log？ Buffer Pool是提高了读写效率，但是Buffer Pool是基于内存的，而内存总是不可靠，出现断电重启时内存里没来得及落盘的脏页数据就会丢失\n为了防止断电导致数据丢失，当一条记录需要更新，InnoDB就会先更新内存（同时标记为脏读页），然后将本次对这个页的修改以redo log的形式记录下来，这时候才算更新完成\n后续，InnoDB引擎会在适合的适合，由后台线程将Buffer Pool的脏页刷新到磁盘里，这个就是WAL****（Write-Ahead-Logging）技术\nWAL技术指的是，MySQL的写操作并不是立刻写到磁盘上面，而是先写日志，然后在合适的时间再写到磁盘上。\n什么是redo log？ redo log是物理日志，记录了某个数据页做了什么修改，每当执行一个事务就会产生这样的一条或者多条物理日志\n在事务提交的时候，只要先将redo log持久化到磁盘即可，可以不需要等待到将缓存在Buffer Pool里的脏页数据持久化到磁盘\n当系统崩溃时，虽然脏页数据没有持久化，但是redo log语句持久化了，接着Mysql重启后，可以根据redo log的内容，将所有数据恢复到最新的状态\n被修改undo页面，需要记录对应redo log吗？ 需要的。\n开启事务后，InnoDB层要更新记录前，首先要记录相应的undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是生成一条undo log，undo log会写入Buffer Pool中的Undo页面\n不过，在内存修改该undo页面后，需要记录对应的redo log\nredo log和undo log区别在哪里？ 这两种日志都是InnoDB引擎下的日志，它们的区别在于：\nredo log记录了事务完成后的数据状态，记录的是更新之后的值；\nundo log记录了事务开始前的数据状态，记录的是更新之前的值；\n当事务提交之前发生崩溃，重启后会通过undo log回滚事务，事务提交之后发生崩溃，重启后会通过redo log恢复事务\n暂时无法在飞书文档外展示此内容\n有了redo log，再通过WAL技术，InnoDB可以保证即使数据库发生异常重启后，之前已提交的记录都不会丢失，这个能力就是 crash-safe（崩溃恢复）\nredo log****保证了事务四大特性中的持久性\nredo log要写磁盘，数据也要写磁盘，为什么要多次一举？ 写入redo log的方式是由了追加操作，所以磁盘操作是顺序写，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是随机写\n磁盘的顺序写比随机写要高效得多，因此redo log写入磁盘的开销更小\n可以说，这是WAL技术的另外一个优点：MySQL****的写操作从磁盘的随机写变成了顺序写\n至此，针对为什么需要redo log这个问题我们有两个答案：\n实现事务的持久性，让MySQL有crash-safe能力\n将写操作从随机写到顺序写，提高MySQL写入磁盘的性能\n产生的redo log是直接写入磁盘的吗 不是，redo log也有自己的缓存——redo log buffer，每当产生redo log时，会先写入到redo log buffer，后续再持久化到磁盘：\nRedo log buffer默认的大小是16MB，可以通过innodb_log_Buffer_size 参数动态的调整大小，增大它的大小可以让MySQL处理大事务时不必写入磁盘，进而提高IO性能\nredo log什么时候刷盘？ 缓存在redo log buffer里的redo log还是在内存中，它会在以下的时机刷新到磁盘\nMySQL正常关闭时\n当redo log buffer中记录的写入量大于redo log buffer内存空间一半时，就会触发落盘\nInnoDB的后台线程每隔1s，将redo log buffer持久到磁盘\n每次事务提交时都将缓存在redo log buffer里的redo log直接持久化到磁盘（这个策略可以通过innodb_flush_log_at_trx_commit 参数控制）\ninnodb_flush_log_at_trx_commit 参数控制的时候什么？ 设置参数为0时，表示每次事务提交时，还是将redo log留在redo log buffer，该模式下事务提交时不主动触发写入到磁盘的操作\n设置参数为1时，表示每次事务提交时，都将缓存在redo log buffer里的redo log直接持久化到磁盘，这样可以保证MySQL异常重启之后的数据不会丢失\n设置参数为2时，表示每次事务提交时，都只是缓存在redo log buffer里的redo log写到redo log文件，注意写入到 redo log文件并不意味着写入到了磁盘，而是写入到了Page Cache，就行写入到了操作系统的文件缓存\ninnodb_flush_log_at_trx_commit 为0和2时，什么时候才将redo log写入磁盘？ InnoDB的后台线程每隔1s：\n针对参数0：会把缓存在redo log buffer中的redo log，通过write()写到操作系统的Page cache，然后调用fsync() 持久化到磁盘。所以参数为0的策略，MySQL进程崩溃会导致上一秒所有事务数据的丢失\n正对参数2：调用fsync() ，将缓存在操作系统中Page Cache里的redo log持久化到磁盘，所以参数为2的策略，较取值为0情况下更安全，因为MySQL进程的崩溃并不会丢失数据，只有在操作系统崩溃或者系统断电的情况下，上一秒所有的事务数据才可能丢失\ninnodb_flush_log_at_trx_commit 三个参数的应用场景是什么？ redo log 文件写满了怎么办？ 默认情况下，innoDB存储引擎有一个重做日志文件组（redo log Group），重做日志文件组由2个redo log文件组成，这两个redo 日志的文件名叫：ib_logfile0 和ib_logfile1\n在重做日志组中，每个redo log file的大小都是固定且一致的\n重做日志组是以循环写的方式工作，从头开始写，写到末尾就回到开头，相当于一个环形\nInnoDB存储引擎会先写ib_logfile0文件，当ib_logfile0文件被写满的时候，会切换至ib_logfile1文件，1写满时会被切换到0文件\nredo log是为了防止Buffer Pool中的脏页丢失而设计的，那么随着系统运行，Buffer Pool的脏页刷新到了磁盘，那么redo log对应的记录也就没有了\nredo log是循环写的方式，相当于一个环形，InnoDB用Write pos表示redo log当前记录写到的位置，用checkpoint表示当前要擦除的位置\nwrite pos和check point的移动都是顺时针方向\nwrite pos ~ check point之间的部分（红色），用来记录新的更新记录\ncheck point ~ write pos 之间的部分（蓝色），待落盘的脏数据页记录\n如果write pos追上checkpoint，就意味着redo log文件满了，这时MySQL不能再执行新的更新操作，也就是MySQL会发生阻塞（因此针对并发量大的系统，适当增大redo log文件的大小非常重要），此时会停下来将Buffer Pool中的脏页刷新到磁盘中，然后标记redo log哪些记录可以被擦除，接着对旧的redo log记录进行擦除，等擦除完旧记录腾出空间，checkpoint就会往后移动，MySQL恢复正常运行，继续执行新的更新操作\n4.为什么需要binlog？ 前面的undo log和redo log都是InnoDB存储引擎生成的日志\nMySQL在完成一条更新操作后，Server层还会生成一条binlog，等之后事务提交的时候，会将事务执行过程中产生的所有binlog统一写入binlog文件\nbinlog文件记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作\n为什么有了binlog，还要redo log？\n因为最开始MySQL只有MyISAM引擎，没有InnoDB引擎，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档\n而InnoDB是另外一个公司以插件的形式引入MySQL的，既然只依靠binlog是没有crash-safe能力的，所以InnoDB使用redo log来实现crash-safe能力\nredolog 和 binlog有什么区别？ Redolog 和 binlog有四个区别：\n适用对象不同：\nbinlog 是MySQL的Server层实现的日志，所有的引擎都可以使用\nredolog 是InnoDB存储引擎实现的日志\n文件格式不同：\nbinlog有3种格式类型，分别是STATEMENT、ROW、MIXED区别如下：\nSTATEMENT：每一条修改数据的SQL都会记录到binlog中（相当于记录了逻辑操作，所以针对这种格式，binlog可以称为逻辑日志）\nROW：\nMIXED：\nredolog是物理日志，记录的是在某个数据页做了什么修改。\n写入方式不同：\nbinlog是追加写，写满一个文件，就创建一个新文件继续写，不会覆盖以前的日志，保存的是全量的日志\nredolog是循环写，日志空间大小是固定的，全部写满从头开始，保存未被刷入磁盘的脏页日志\n用途不同：\nbinlog用于备份恢复，主从复制\nredolog用于掉电等故障恢复\n不小心整个数据库的数据删除了，能用redo log文件恢复数据吗？\n不可以使用redo log文件恢复，只能使用binlog文件恢复\n因为redo log文件是循环写，是会边写边擦日志的，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会被从redolog文件里擦除\nbinlog文件保存的是全量的日志，也就是保存了所有数据变更的情况，理论上只要记录在binlog上的数据，都可以恢复\n主从复制是怎么实现的？ MySQL的主从复制依赖于binlog，记录MySQL上的所有变化以二进制形式保存在磁盘上，复制的过程就是将binlog中的数据从主库传输到从库上\n这个过程一般是异步的\nMySQL集群的主从复制过程大致三阶段：\n写入binlog：主库写binlog日志，提交事务，并更新本地存储数据\n同步binlog：把binlog复制到所有从库上，每个从库把binlog写到暂存日志中\n回放binlog：回放binlog，并更新存储引擎中的数据\n具体详细过程如下：\nMySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。\n从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。\n从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。\n从库是不是越多越好\n不是，从库的数据增加，从库连接上来的I/O线程就越多，主库建立同样多的log dump线程来处理复制的请求，对主库资源消耗比较高，同时还限制于主库的网络带宽\n在实际使用中，一般一主跟2~3从库\nMySQL主从复制还有哪些模型\n同步复制\n异步复制\n半同步复制\nbinlog是什么时候刷盘？ 5.为什么需要两阶段提交？ 两阶段提交的过程是怎样的？ 重启异常会出现什么现象？ ","date":"2025-07-03","id":2,"permalink":"/notes/database/mysql/mysql-log/","summary":"MySQL 日志 - undo log | redo log | bin log","tags":"MySQL","title":"Mysql Log(bate)"},{"content":" MySQL 锁 - 全局锁|表级锁|行级锁\n锁的类型 Mysql的锁，根据加锁的范围可以分为全局锁、表级锁和行锁三类\n全局锁 要使用全局锁，执行下面这条命令：\nflush tables with read lock 执行之后，整个数据库就处于只读状态，这时其他线程执行以下操作，就会被阻塞\n对数据的增删改，比如insert、delete、update等\n对表结构的更改操作，比如alter table、drop table等\n要释放全局锁，执行下面的命令：\nunlock tables 全局锁的应用场景：\n全局锁主要用于做全库逻辑备份，这样在备份数据库期间，不会因为数据或者结构的更新，而出现备份文件的数据与预期的不一样\n加全局锁带来的缺点：会导致业务停滞，因为加全局锁之后，整个数据库都只是只读状态，不能更新数据\n可以通过开启事务，在可重复读的隔离级别下，即使其他事务更新了表的数据，也不会影响备份数据库时的Read View，\n备份数据库的工具是mysqldump ，在使用mysqldump时加上-single-transaction 参数的时候，就会在备份数据库之前开启事务\n表级锁 MySQL里面表级锁有以下几种：\n表锁\n元数据锁（MDL）\n意向锁\nAUTO-INC锁\n表锁 使用下面的命令对表加锁和释放锁\n// 加读锁 lock tables \u0026lt;table_name\u0026gt; read; // 写锁 lock tables \u0026lt;table_name\u0026gt; write; // 释放锁 unlock tables; 表锁会影响别的线程和本线程的读写操作\n元数据锁（MDL） 对于MDL，我们不需要显示使用，因为当我们在对数据库进行操作时，会自动给这个表上加MDL：\n对一张表进行CURD操作时，加的是MDL读锁\n对一张表做结构变更操作的时候，加的是MDL写锁\nMDL是为了保证当前用户对表执行CRUD操作时，防止其他线程对这个表结构做了变更\nMDL是在事务提交之后才会释放，这意味着事务执行期间，MDL是一直持有\n需要注意的是，在事务启用之后，如果事务A没有提交，此时如果有表结构的修改请求发起，就会发生阻塞，这个阻塞也会导致其他CURD的请求被阻塞住\n这是因为申请MDL锁的操作会形成一个队列，队列中写锁获取优先级大于读锁，一旦出现MDL写锁等待，会阻塞该表后续的CRUD操作\n意向锁 在使用InnoDB引擎的表里对某些记录加上共享锁之前，需要先在表级别加上一个意向共享锁\n在使用InnoDB引擎的表里对某些记录加上独占锁之前，需要先在表级别加上一个意向独占锁\n在执行insert、update、delete操作时，需要先对表上加 意向独占锁，然后对该记录加独占锁\n而普通的select是不会加行级锁，普通的select语句是利用MVCC实现一致性读，是无锁的\n// select也是可以对记录加共享锁和独占锁， // 先在表上加上意向共享锁，然后对读取的记录加共享锁 select ... lock in share mode; // 先表上加上意向锁，然后再读取记录加独占锁 select ... for update 意向锁的目的是为了快速判断表里是否有记录被加锁\nAUTO-INC锁 表里面的主键通常设置成自增的，在插入数据时，可以不指定主键的值，数据库会自动给主键赋值递增的值，这主要是通过AUTO-INC锁实现的\nAuto-Inc锁是特殊的表锁机制，不是在一个事务提交后才释放，而是再执行完插入语句后就会立即释放\n行级锁 InnoDB引擎是支持行级锁的，而MyISAM引擎并不支持行级锁\n行级锁的类型主要有三类：\nRecord Lock，记录锁，也就是仅仅一条记录锁上\nGap Lock，间隙锁，锁定一个范围，但不包含记录本身\nNext-key Lock，Rocord Lock + Gap Lock的组合，锁定一个范围，并且锁定记录本身\nRecord Lock 记录锁 Record Lock称为记录锁，锁住的是一条记录。而且记录锁也有s锁和x锁之分\nGap Lock 间隙锁 Gap Lock称为i而间隙锁，只存在于可重复隔离级别，目的是为了解决可重复读级别下幻读的现象\n间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不会存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出\nNext-key Next-key Lock成为临键锁，是Record Lock + Gap Lock的组合，锁定一个范围，并且锁定记录本身\nNext-key Lock是包含间隙锁+记录锁，如果一个事务获取了X型的next-key lock，那么另外一个事务在获取相同范围的X型的next-key lock时，是会被阻塞的\n插入意向锁 在一个事务插入一条记录的时候，需要判断插入的位置释放已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。\n如果有，插入操作就会阻塞，直到间隙锁被释放，在此期间会生成一个插入意向锁，表明有事务想在某区域插入新记录，但是处于等待状态\nMySQL加锁 InnoDB引擎是支持行级锁，而MyISAM是不支持行级锁，了解Mysql是怎么加行级锁，其实也是说InnoDB引擎是怎么加锁的。\n普通select语句是不会对记录加锁（除了串行化隔离级别），因为它属于快照读，是通过MVCC（多版本并发控制）实现的\n对查询时对记录加行级锁，可以使用下面两种方式，这两种查询会加锁的语句叫做锁定读\n// s lock select ... lock in share mode; // x lock select ... for update; 上面两个语句必须在事务中，因为当事务提交了，锁就释放。\n除了上面两条锁定读语句会加行级锁之外，update和delete操作都会加行级锁，且锁定类型都是独占锁(X)\nupdate table ... delete from table ... x型锁和s型锁之间的兼容型未读读共享，读写互斥\nX S X 不兼容 不兼容 S 不兼容 兼容 行级锁\n读已提交隔离级别下，行级锁的种类只有记录锁，也就是仅仅一条记录锁上\n可重复读隔离级别下，行级锁的种类除了记录锁，还有间隙锁（目前是为了避免幻读\n在执行commit后，事务过程中生成的锁都会被释放\nMySQL是怎么加行级锁的？ 行级锁加锁规则复杂，目前仅保留了解程度\nMySQL 是怎么加锁的？\n总结1：在能够使用记录锁或者间隙锁就能避免幻读的现象的场景下，next-key lock就会退化成为记录锁或间隙锁\nMysql死锁 使用引擎为InnoDB，隔离级别为可重复读（RR）\n死锁的发生 有表如下：\ncreate table `t_order` ( `id` int not null auto_increment, `order_no` int default null, `create_date` datetime default null, primary key(`id`), key `index_order` (`order_no`) using btree ) engine = InnoDB; 有两个事务，一个事务要插入订单1007，另外一个事务也要插入订单1008，因为需要对订单做幂等性校验，所以两个事务先要查询订单是否存在，不存在才插入记录\n这里两个事务都陷入阻塞（前提是没有打开死锁检测），也就是发生了死锁，都在互相等待对方释放锁\n死锁的产生 可重复隔离级别下，是存在幻读的问题\nInnoDB引擎为了解决可重复读隔离级别下的幻读问题，就引出了next-key锁，它是记录锁和间隙锁的组合\nRecord Lock，记录锁，锁的是记录本身\nGap Lock，间隙锁，锁的是两个值之间的空隙，以防止其他事务在这个空隙间插入新的数据，从而避免幻读\n普通的select是通过mvcc实现的快照读，不会对记录进行加锁，如果要在查询的时候加行锁，可以使用下面的两种方式\nbegin; // 对读取的记录加共享锁 select ... lock in share mode; commit; begin; // 对读取的记录加排他锁 select ... for update; commit; 行锁的释放时机是在事务提交（commit）后，锁才会释放，并不是在一条语句执行完毕之后释放锁\nselect * from performance_schema.data_lock\\G; 执行以上的语句，可以查看事务执行SQL过程中加了什么锁\nLOCK_TYPE 中的RECORD表示行级锁，通过LOCK_MODE 可以确认是next-key锁，间隙锁还是记录锁\nLOCK_MODE: X ，说明是X型的next-key锁；\nLOCK_MODE: X, REC_NOT_GAP ，说明是X型的记录锁；\nLOCK_MODE: X, GAP ，说明是X型的间隙锁；\n当事务B往事务A next-key锁的范围插入记录时，就会被锁住\n执行插入语句时，会在插入间隙上获取插入意向锁，而插入意向锁与间隙锁是冲突的，所以当其它事务持有该间隙的间隙锁时，需要等待其它事务释放间隙锁之后，才能获取到插入意向锁。而间隙锁与间隙锁之间是兼容的，所以两个事务中**select ... for update** 语句并不会相互影响。\n这样，事务A和事务B在执行完select ... for update 语句之后都持有了间隙锁，而接下来的insert 操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，导致死锁。\n为什么间隙锁和间隙锁之间是兼容的？\nMySQL官网上有描述：\nGap locks in InnoDB are “purely inhibitive”, which means that their only purpose is to prevent other transactions from Inserting to the gap. Gap locks can co-exist. A gap lock taken by one transaction does not prevent another transaction from taking a gap lock on the same gap. There is no difference between shared and exclusive gap locks. They do not conflict with each other, and they perform the same function.\n间隙锁的意义只在于阻止区间被插入，因此可以共存。**一个事务获取的间隙锁不会阻止另外一个事务获取同一个间隙范围的间隙锁，**共享和排他的间隙锁是没有区别的，它们相互不冲突，且功能相同，即两个事务可以共同持有包含共同间隙的间隙锁\n共同间隙包括两种场景：\n两个间隙锁的间隙区间完全一样\n一个间隙包含的间隙区间是另外一个间隙锁区间的子集\n注意：next-key lock是包含间隙锁+记录锁的，如果一个事务获取了X型的next-key lock，那么另外一个事务在获取相同范围的X型的next-key lock时，是会被阻塞的\n再注意：对于右区间为+∞的next-key lock，因为+∞并不是一个真实的记录，所以我不需要考虑X型和S型\n插入意向锁是什么？\nMySQL的描述：\nAn Insert intention lock is a type of gap lock set by Insert operations prior to row Insertion. This lock signals the intent to Insert in such a way that multiple transactions Inserting into the same index gap need not wait for each other if they are not Inserting at the same position within the gap. Suppose that there are index records with values of 4 and 7. Separate transactions that attempt to Insert values of 5 and 6, respectively, each lock the gap between 4 and 7 with Insert intention locks prior to obtaining the exclusive lock on the Inserted row, but do not block each other because the rows are nonconflicting.\n这段话表明尽管插入意向锁是一种特殊的间隙锁，但不同于间隙锁的是，该锁只用于并发插入操作。\n如果说间隙锁锁住的是一个区间，那么插入意向锁锁住的是一个点，因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁\n插入意向锁的生成时机：\n每插入一条新纪录，都需要看一下待插入记录的下一条记录上是否已经被加了间隙锁，如果已加间隙锁，此时会生成一个插入意向锁，如何锁的状态设置为等待状态，现象就是Insert语句会被阻塞（_PS：_MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁） Insert语句是怎么加行级锁的？ Insert语句在正常执行时是不会生成锁结构的，它是靠聚簇索引记录自待的trx_id 隐藏列来作为隐式锁来保护记录的\n什么是隐式锁？\n当事务需要加锁时，如果这个锁不可能发生冲突，InnoDB会跳过加锁环节，这种机制称为隐式锁\n隐式锁是InnoDB实现的一种延迟加锁机制\n如何避免死锁？ 死锁的四个必要条件：\n互斥\n占有且等待\n不可强占用\n循环等待\n只要发生死锁，这些条件必然成立，但是只要破环其中一个条件死锁就不会成立\n在数据库层面，有两种策略通过打破循环等待条件来解除死锁状态：\n设置事务等待锁的超时时间：当一个事务的等待时间超过该值后，就对这个事务进行混滚，于是锁就释放了，另外一个事务就可以继续执行了。在InnoDB中，参数innodb_lock_wait_timeout 是用来设置超时时间的，默认时间为50s\n开启主动死锁检测：主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将innodb_deadlock_detect 设置为on，表示开启这个逻辑，默认就开启。\n","date":"2025-07-03","id":3,"permalink":"/notes/database/mysql/mysql-lock/","summary":"MySQL 锁 - 全局锁|表级锁|行级锁","tags":"MySQL","title":"Mysql Lock(bate)"},{"content":" MySQL 索引\n1. B+树（索引数据结构） 什么是索引？ 为什么索引能加快查询？ 索引的数据结构是什么？ B+ 树 和（B 树 和 红黑树）有什么区别？ 为什么选择 B+树 作为索引数据结构？\n为什么Mysql InnoDB选择B+ Tree作为索引？ B+ 树 vs B 树 B+ 树只在叶子节点存储数据，B树的非叶子节点也要存储数据，所以B+ 树的单个节点的数据量更小 B+ 树 vs 二叉树 对于有N个叶子节点的B+ 树，搜索复制度为O（logdn） B+ 树 vs Hash 08 索引:排序的艺术\n为什么 MySQL 采用 B+ 树作为索引？\n2. 索引组织表（索引存储） 堆表和索引组织表有什么区别？\n分别应用场景是什么？\nMysql InnoDB存储引擎中数据存储方式：索引组织表\n数据存储有堆表和索引组织表两种。\n堆表中的数据是无序存放的，数据的排序完全依赖索引\n索引组织表，数据根据主键进行排序存放在索引中，主键索引也叫聚集索引（Clustered Index）\n在索引组织表中，数据即索引，索引即数据\n二级索引 InnoDB存储引擎的数据是根据主键索引排序存储的，除了主键索引外，其它的索引都称为二级索引（Secondeary Index），或者非聚集索引\n二级索引也是一颗B+树索引，但是它和主键索引不同的是叶子节点存放的是索引键值、主键值\n通过二级索引idx_name 只能定位主键值，需要额外再通过主键索引进行查询，才能得到最终结果。\n这种二级索引通过主键索引进行再一次查询的操作叫做“回表”\n这样的二级索引设计的好处：若记录发生了修改，则其它索引无须进行维护，除非记录的主键发生了修改\n在索引组织表中，万物皆索引，索引就是数据，数据就是索引。\n二级索引的性能评估 要比较顺序，对聚集索引性能友好\n尽可能紧凑，对二级索引的性能和存储友好\n函数索引（先了解） \u0026hellip;\n09 索引组织表:万物皆索引\n3.组合索引（联合索引） 联合索引的结构是什么？\n如果利用联合索引提升查询性能\n组合索引（Compound Index）是指由多个列所组合而成的B+树索引\n组合索引既可以是主键索引，也可以是二级索引，只是排序的键值从1个变成了多个，本质还是一棵B+树索引\n索引覆盖 目的是为了避免回表，由于二级组合索引的叶子节点，包含索引键值和主键值，若查询的字段在二级索引的叶子节点中，则可以直接返回结果，无需回表。\n这种组合索引避免回表的优化手段称为索引覆盖（Covering Index）\n10 组合索引:用好，性能提升 10 倍!\nMySQL夜市8月25日（联合索引）\n4.索引失效 有哪些索引失效的场景？\n为什么会失效？\n前提：索引可以提高语句查询速度，但是索引并不是万能的，建立了索引，并不意味着任何查询语句都能走索引扫描\n索引存储结构长什么样？ MySQL默认的存储引擎是InnoDB，采用的是B+树作为索引的数据结构。在建表的时候，InnoDB存储引擎默认会创建一个主键索引，也就是聚簇索引，其它索引都属于二级索引\n失效情况 A. 对索引使用左或者左右模糊匹配 索引B+树是按照索引值有序存储的，只能根据前缀进行比较\nB. 对索引使用函数 索引保存的是索引字段的原始值，而不是经过函数计算后的值\nC. 对索引进行表达式计算 原因与索引使用函数差不多，进行了表达式计算后得到的值不是原本的值，无法走索引\nD. 对索引隐式类型转换 Mysql的类型转换规则：\n字符串 \u0026ndash;\u0026gt; 数字，就相当于 数字比较\n数字 \u0026ndash;\u0026gt; 字符串，就是字符串比较\n小总结：在Mysql中，遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较\nE. 联合索引非最左匹配 F. Where 子句中的OR 在WHERE子句中，如果在OR前的条件列是索引列，而OR后面不是索引列，那么索引会失效\n索引失效有哪些？\nB+树里面的节点存放的是什么？查询数据的结果又是怎样的？\n5.索引选择 Mysql数据库中的优化器是怎么执行的？\n根据什么标准选择索引？\nMySQL是如何选择所索引的？ 在关系型数据库中，B+树索引只是存储的一种数据结构，具体使用还需要依赖数据库的优化器，优化器决定了具体某一索引的选择\n而优化器的选择是基于成本（cost），哪个索引的成本越低，优先选择哪个索引\nCost = Server Cost + Engine Cost = CPU Cost + IO Cost 先看MySQL数据库的结构，MySQL由Server层和Engine层组成：\nServer层有SQL分析器、SQL优化器、SQL执行器，用于负责SQL语句的具体执行过程\nEngine层负责存储具体的数据，常使用InnoDB存储引擎，还有用于内存中存储临时结果集的TempTable引擎\nMySQL索引出错：\n未使用创建的索引\n索引创建在有限状态上\n11 索引出错:请理解 CBO 的工作原理\n6.索引应用 建立索引有什么优点和缺点？\n如何正确使用索引？\n哪些场景下适合建立索引？\n哪些场景下不适合建立索引？\n总结 B+树索引\n索引的加快查询的一种数据结构，其原理是插入时对数据排序，缺点是会影响插入的性能\nMysql当前支持B+树索引、全文索引、R树索引\nB+树索引的高度通常为3~4层，高度为4的B+树可以存放50亿左右的数据\n由于B+树的高度不高，查询效率高，50亿的数据也只需插叙4次I/O\nMysql单表的索引没有个数限制，业务查询需要，创建即可\n可以通过表sys.schema_unused_indexes和索引不可见特性，删除无用的索引\nMysql采用B+树索引？从数据结构、磁盘I/O操作次数出发\n索引组织表\nMysql InnoDB存储引擎是索引组织表，以及索引组织表和堆表之间的区别：\n索引组织表主键是聚集索引，索引的叶子节点存放表中一整行完整记录\n除主键索引外的索引都是二级索引，索引的叶子节点存放的是（键值，主键值）\n由于二级索引不存放完整记录，因此需要通过主键值再进行一次回表才能定位到完整数据\n索引组织表对比堆表，在海量并发的OLTP业务中能有更好的性能表现\n每种不同数据，对二级索引的性能开销影响不一样\n有时通过函数索引可以更快解决线上SQL的性能问题\n虚拟列不占用实际存储空间，在虚拟类上创建索引本质就是函数索引\n组合索引 组合索引也是一颗B+树，只是索引的列由多个组成，组合索引既可以是主键索引，也可以是二级索引 组合索引的三大优势 3. 覆盖多个查询条件，如（a，b）索引可以覆盖查询 a = ? 或者 a = ? and b = ?\n避免SQL的额外排序，提高SQL性能，如WHERE a = ? OR ORDER BY b 这样的查询条件\n利用组合索引包含多个列的特性，可以利用索引覆盖技术，提高SQL的查询性能，用好索引覆盖技术，性能提升10倍不是难事\n索引失效\n6种会发生索引失效的情况：\n使用左或者左右模糊匹配的时候，也就是 like %xx 或者like %xx% 这两种方式，都会造成索引失效\n当我们查询条件中对所有列使用函数，会导致索引失效\n在查询条件中对所有列进行表达式运算，会导致索引失效\nMySQL遇到字符串和数字比较的时候，会自动把字符串转为数字，再进行比较。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么所有列会发生隐式类型转换，由于隐式类型转换是通过CAST函数实现的，等于对索引列使用了函数，所以导致索引失效\n联合索引要能正确使用遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则索引会失效\n在WHERE子句中，如果在OR前的条件列是索引列，而在OR后的条件列不是索引列，那么所有会失效\n索引选择\nMySQL优化器是CBO，是一种基于成本的优化器。会判断每个索引的执行成本，从中选择出最优的执行计划\nMySQL优化器是CBO（Cost-based Optimizer）的\nMySQL会选择成本最低的执行计划，可以通过explain命令查看每个SQL的成本\n一般只对高选择度的字段和字段组合起来建立索引，选择度低的字段如性别，不建议建立索引\n若数据存在倾斜，可以创建直方图，让优化器知道索引中的数据的分布，进一步校准执行计划\n面试题 1.为什么InnoDB选择B+Tree作为索引的数据结构？ B+树 vs B树\n存储相同数据量级下，B+树高比B树低，磁盘I/O次数更少\nB+树叶子节点用双向链表串起来，适合范围查询，B树无法做到这点\nB+树 vs 二叉树\n随着数据量的增加，二叉树的树高会越来越高，磁盘I/O次数也会更多，B+树在千万级别的数据量下，高度依然维持在3~4层左右 B+树 vs Hash\n虽然Hash的等值查询效率高，但是无法做到范围查询 2.什么时候适用索引？ 字段有唯一限制性\n经常用于WHERE查询条件\n经常用于GROUP BY 和 ORDER BY的字段\n3.什么时候不需要创建索引？ WHERE条件，GROUP BY，ORDER BY里用不到的字段\n字段中存在大量重复数据\n表数据太少\n经常需要更新的字段\n4.什么时候索引会失效？ 左或左右模糊匹配\n在查询条件中对索引列做了计算、函数、类型转换等操作\n联合索引要正确遵循最左匹配原则\n在WHRER子句中，如果在OR前的条件是索引列而OR后的条件列不是索引列\n为了更好使用索引，索引列要设置为NOT NULL\n5.有什么优化索引的方法？ 回答：\n前缀索引优化\n覆盖索引优化\n主键索引最好是自增的\n防止索引失效\n#MySQL\n","date":"2025-07-03","id":4,"permalink":"/notes/database/mysql/mysql-index/","summary":"MySQL 索引","tags":"MySQL","title":"Mysql Index(bate)"},{"content":" MySQL 缓存池\n为什么要有Buffer Pool MySQL的数据存储在磁盘的，如果每次都从磁盘里面读取数据，这样性能是很差的\n提高性能，就需要加入缓存。当数据从磁盘中取出来之后，缓存内存中，下次查询同样的数据，直接从内存中读取\n为此InnoDB存储引擎设计了一个缓存池（Buffer Pool），来提高数据库的读写性能\n有了缓冲池后：\n读取数据时，如果数据存在于Buffer Pool中，客户端就会直接读取Buffer Pool中的数据，否则再去磁盘中读取 当修改数据时，首先修改Buffer Pool中数据所在的数据页，然后将该页设置为脏页，最后由后台线程将脏页写入到磁盘 Buffer Pool有多大？ Buffer Pool在MySQL启动的时候，向操作系统申请的一片连续的内存空间，默认配置下Buffer Pool只有128MB\n可以通过调整innodb_buffer_pool_size 参数来设置Buffer Pool的大小，一般建议设置为可用物理内存的60%~80%\nBuffer Pool缓存什么？ InnoDB会把存储的数据分为若干个页，以页作为磁盘和内存交互的基本单位，一个页的默认大小为**16kb，**因此Buffer Pool同样需要按页来划分\n在MySQL启动的时候，**InnoDB会为Buffer Pool申请一片连续的内存空间，然后按照默认的16kb的大小划分出一个个的页，Buffer Pool中的页就叫做缓存页。**这些缓存页都是空的，之后随着程序的运行，才会有磁盘上的页被缓存到Buffer Pool中\n所以，MySQL刚启动的时候，其使用的虚拟内存空间很大，而使用到的物理内存空间很小，这时因为这些虚拟内存被访问后，操作系统才会触发缺页中断，接着将虚拟地址和物理地址建立映射关系\nBuffer Pool缓存了以下的：\n索引页 数据页 插入缓存页 Undo页 自适应哈希索引 锁信息 为了更好管理Buffer Pool中的缓存页，InnoDB为每一个缓存页都创建了一个**控制块，**控制块包括缓存页的表空间，页号，缓存页地址，链表节点等，控制块也占据内存空间，它是在Buffer Pool的最前面，接着才是缓存页\n暂时无法在飞书文档外展示此内容\n上面的控制块和缓存页之间的空白空间称为碎片空间\n碎片空间：每一个控制块对应一个缓存页，在分配足够多的控制块和缓存页后，可能剩余的空间不足够一个控制块和缓存页的大小，那么这块空间就不被使用，剩下的这块空间就被称为碎片\n当Buffer Pool的大小设置的刚刚好，就不会产生碎片\n查询一条记录时，InnoDB会把整个页的数据加载到Buffer Pool中，通过索引只能定位到磁盘中的页，而不能定位到页中一条记录。\nmp.weixin.qq.com(从数据页的角度看B+树——InnoDB存储引擎)\n记录是按照行来存储的，但是数据库的读取并不是以行为单位，否则一次读取（一次IO操作）只能处理一行数据，效率会非常低，因此，InnoDB的数据是按照数据页为单位来读写的\n数据页的结构分为7个部分\nFile Header(38) 文件头，表示页的信息 Page Header(56) 页头，表示页的状态信息 infimum+supermun(26) 两个虚拟伪记录，分别表示页中最小记录和最大记录 User Records(unclear) 存储行记录内容 Free Space(unclear) 页中还没被使用的 Page Directory(unclear) 页目录，存储用户记录的相对位置，对记录起索引作用 File Tailer(8) 校验页是否完整 其中，行记录由infimum+supremum 和 User Records构成\n在File Header 中有两个指针，分别指向上一个数据页和下一个数据页，连接起来的页相当于一个双向链表\n采用链表结构是让数据页之间不需要物理上的连续，而是逻辑上的连续\n数据页中User Records是怎么组织数据的？ **数据页中的记录按照主键顺序组成单向链表，**单向链表的特点是插入、删除非常方便，但是检索效率不高\n因此，在数据页中有一个页目录（Page Directory），起记录的索引作用，可以快速找到记录\n页目录创建过程如下：\n将所有记录划分为几个组，这些记录包括最小记录和最大记录，但不包括标记已删除的记录\n每个记录组的最后一条记录是组内最大的那条记录，并且最后一条记录的头信息都会存储该组一共多少条记录，作为n_owned字段\n页目录用来存储每组最后一条记录的地址偏移量，这些地址偏移量会按照先后顺序存储起来，每组的地址偏移量也被称为槽（slot），每个槽相当于指针指向了不同组的最后一个记录\n页目录就是由多个槽组成，槽相当于分组记录的索引。因为记录是按照主键值大小从小到大排序，所以通过槽查找记录时，可以使用二分查找法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，在遍历槽内的所有记录，找到对应的记录\nInnoDB里的B+树中的每个节点都是一个数据页\nInnoDB对每个分组中的记录条数是有规定的，槽内的记录就有几条：\n第一个分组中的记录只能由1条\n最后一个分组的记录条数范围只能在1-8条之间\n剩下的分组中记录条数范围只能在4-8条之间\n如何管理Buffer Pool？ 空闲页的管理 为了能够快速找到空闲的缓存页，可以使用链表结构，将空闲缓存页的控制块作为链表的节点，这个链表称为Free链表（空闲链表）\nFree链表上除了控制块，还有一个头结点，该头结点包含该链表的头结点地址，尾节点地址，以及当前链表中节点的数量等信息\nFree链表节点是一个个的控制块，而每个控制块包含着对应缓存页的地址，所以相当于Free链表节点都对应一个空闲缓存页\n有了Free链表后，每当需要从磁盘中加载一个页到Buffer Pool中，就从Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从Free链表中移除\n脏页的管理 Buffer Pool除了提高读性能，还能提高写性能，就是更新数据的时候，不需要每次都写入磁盘，而将Buffer Pool对应的缓存页标记为脏页，然后由后台线程将脏页写入到磁盘\ninnodb设计出了Flush链表，跟Free链表类似，链表的节点是控制块，区别是Flush链表的元素是脏页\n有了Flush链表，后台线程可以遍历Flush链表，将脏页写入磁盘\n如何提高缓存命中率 Buffer Pool的大小是有限的，所以需要使用一些策略，保证常用数据留在Buffer Pool，少用的数据在某个时机可以淘汰掉\n最常见的是LRU算法（Least recently used）\n这个算法的思路是，链表头部的节点是最近使用的，而链表末尾的节点是最久没有使用的，那么当空间不够时，就淘汰最久没有使用的节点\n简短的LRU算法实现思路如下：\n当访问的页在Buffer Pool中，就直接将该页对于的LRU链表节点移动到链表的头部\n当访问的页不在Buffer Pool中，除了把页放入到LRU链表的头部，还要淘汰LRU链表末尾的节点\n至此，Buffer Pool里有三种页和链表来管理数据：\nFree Page（空闲页）：表示此页未被使用，位于Free链表\nClean Page（干净页）：表示此页已经被使用，但是页面未发生修改，位于LRU链表\nDirty Page（脏页）：表示此页已经被修改，其数据和磁盘上的数据已经不一致。当脏页上的数据写入磁盘后，内存数据和磁盘数据一致，那么该页就变成干净页。脏页同时存在于LRU链表和FLUSH链表\n简短LRU算法没有被MySQL使用，因为简短LRU算法无法避免一些两个问题：\n预读失效\nBuffer Pool污染\n怎么解决预读失效而导致缓存命中率减低的问题？ 预读失效：\nMySQL的预读机制。程序有空间局部性，靠近当前被访问数据的数据，在未来大概率被访问\nMySQL在加载数据页的时候，会提前把相邻的数据页一并加载，减少磁盘IO\n但是这些被提前加载进来的数据页，并没有被访问，相当于预读是白做，这个就是预读失效\n如果使用简单的LRU算法，就会把预读页放到LRU链表头部，而当Buffer Pool空间不够，还需要淘汰末尾的页\n这里会出现一个奇怪的问题，预读页可能一直不会被访问到，却会占用LRU链表前排的位置，而末尾淘汰的页可能是频繁访问的页，这样就大大降低了缓存命中率\n避免预读失效带来的影响，最好就是让预读的页停留在Buffer Pool里时间尽可能的短，让真正被访问的页才移动到LRU链表的头部，从而保证真正被读取的热数据留在Buffer Pool里的时间尽可能长\nMySQL做了以下修改：将LRU划分了2个区域：old区域和young区域\nyoung区域在LRU链表的前半部分，old区域则是在后半部分，old区域占整个LRU链表长度比例可以通过innodb_old_blocks_pct 参数来设置，默认是37，代表整个LRU链表中young区域和old区域比例是63:37\n划分两个区域后，预读的页只需要加入到old区域的头部，当页被真正访问到时候，才将页插入到young区域。\nMySQL改进后的LRU算法，通过划分young区域和old区域避免了预读失效带来的影响，但是没有解决Buffer Pool污染的问题\n怎么解决出现Buffer Pool污染而导致缓存命中率减低的问题？ Buffer Pool污染：\n当某个SQL语句扫描了大量的数据，在Buffer Pool空间比较有限的情况下，可能会将Buffer Pool里的所有页都替换出去，导致大量热数据被淘汰，等这些热数据又再被访问的时候，由于缓存未命中，就会产生大量的磁盘IO，MySQL性能就会急剧下降，这个过程为Buffer Pool污染\n像全表扫描的查询，很多缓存页其实只会被访问一次，但是它却因为被访问一次而进入到young区域，从而导致热点数据被替换\n为了解决这个问题，MySQL提高了进入young区域的门槛，这样就能有效保障young区域里的热点数据不会被替换掉\n想要进去young区域条件增加了一个停留在old区域的时间判断\n具体过程如下，在对某个处在old区域的缓存页进行第一次访问时，就在它对应的控制块中记录下来这个访问时间：\n如果后续的访问时间与第一次访问的时间在某个时间间隔内，那么该缓存页就不会被从old区域移动到young区域的头部 如果后续的访问时间与第一次访问的时间不在某个时间间隔内，那么该缓存页移动到young区域的头部 这个间隔时间是由innodb_old_blocks_time 控制的，默认是1000ms\n也就是说，只有同时满足被访问与old区域停留时间超过1s两个条件，才会被插入到young区域的头部，这样就解决了Buffer Pool污染问题\n另外，MySQL针对young区域其实做了一个优化，为了防止young区域节点频繁移动到头部，young区域前面1/4被访问不会移动到链表头部，只有后面的3/4被访问了才会\n脏页什么时候会被刷入磁盘？ 引入Buffer Pool后，当修改数据时，首先修改Buffer Pool中数据所在的页，然后将其页设置为脏页，但是磁盘中还是原数据\n因此，脏页需要刷入磁盘，保证缓存和磁盘数据一致，但是若每次修改数据都刷入磁盘，则性能会变差，因此一般都会在一定时机进行批量刷盘\n但是如果脏页在还没来得急刷入磁盘时，MySQL宕机了，数据会丢失吗？\n不会，InnoDB的更新操作采用的是Write Ahead Log策略，即先写日志，在写入磁盘，通过redo log日志让MySQL拥有崩溃恢复能力\n下面几种情况会触发脏页的刷新：\n当redo log日志满了的情况下，会主动触发脏页刷新到磁盘 Buffer Pool空间不足时，需要将一部分数据页淘汰掉，如果淘汰的脏页，需要先将脏页同步到磁盘 MySQL认为空闲时，后台线程会定期将适量的脏页刷入到磁盘 MySQL正常关闭时，会把所有的脏页刷入磁盘 ","date":"2025-07-03","id":5,"permalink":"/notes/database/mysql/mysql-buffer-pool/","summary":"MySQL 缓存池","tags":"MySQL","title":"Mysql Buffer Pool(bate)"},{"content":" MySQL 架构- server \u0026amp;\u0026amp; storage-engine\n6.1 SQL执行过程 推荐阅读 小林coding/mysql\nMySQL架构分为两层：server层和存储引擎层\nServer层负责建立连接、分析和执行SQL MySQL大多数核心功能模块都在这里：连接器、查询缓存、解析器、预处理器、优化器、执行器等 还有所有的内置函数 所有跨存储引擎的功能 存储引擎层负责数据的存储和提取 支持InnoDB、MyISAM、Memory等多个存储引擎 6.1.1 连接器 MySQL是基于TCP协议进行传输的，所以在连接MySQL的时候需要先进行TCP三次握手，在命令行使用命令进行连接\nmysql -h $ip -u$user -p 用户通过用户密码成功连接后，连接器会获取用户的权限，然后保存起来，在后续的此连接的任何操作，都会基于连接开始的时候读取到的权限逻辑进行判断\n建立连接后，即使修改了该用户的权限，也不影响已连接的权限。只有新建的连接才会有新的权限设置\n6.1.1.1 查看MySQL服务的客户端连接 可以执行show processlist 命令进行查看\n6.1.1.2 空闲连接会一直占着 不会，MySQL定义了空闲连接的最大空闲时长，由wait_timeout 参数控制，默认值是8小时，超过这个时间，连接器就会把这个连接断开\n使用命令可以查看该值\nshow variables like \u0026#39;wait_timeout\u0026#39;; 可以手动断开空闲的连接，使用的是\nkill connection + id 当空闲的连接被服务端主动断开后，这个客户端并不会马上知道，等到客户端在发起下一个请求时，才会收到报错\n“ERROR 2013 (HY000): Lost connection to MySQL server during query”\n6.1.1.3 MySQL的连接限制 MySQL服务支持的最大连接数由max_connections 参数控制\nshow variables like \u0026#39;max_connections\u0026#39;; MySQL的连接跟HTTP一样，有短连接和长连接的概念\n// 短连接 连接 mysql 服务（TCP 三次握手） 执行sql 断开 mysql 服务（TCP 四次挥手） // 长连接 连接 mysql 服务（TCP 三次握手） 执行sql 执行sql 执行sql .... 断开 mysql 服务（TCP 四次挥手） 一般推荐长连接，但是使用长连接可能会占用内存增多，因为_MySQL在执行查询过程中临时使用内存管理连接对象__，_只有在连接断开的时候才会释放\n6.1.1.4 怎么解决长连接占用内存的问题 两个解决方案：\n定期断开长连接\n客户端主动重置连接\nMySQL在5.7版本实现了mysql_reset_connection()函数的接口，可以使得客户端执行一个很大的操作后，在代码里调用该函数，来进行重置连接，达到释放内存的效果\n与客户端进行 TCP 三次握手建立连接；\n校验客户端的用户名和密码，如果用户名或密码不对，则会报错；\n如果用户名和密码都对了，会读取该用户的权限，然后后面的权限逻辑判断都基于此时读取到的权限；\n6.1.2 查询缓存 连接器完成连接后，服务端收到SQL语句，就会解析出SQL语句是什么类型的语句\n如果是SELECT语句，MYSQL会先去查询缓存（Query Cache）查找缓存数据，这个查询缓存是以key-value 形式保存在内存中，key为SQL查询语句，value为SQL语句查询的结果\n如果缓存命中，就会直接发送value给客户端，否则就继续往下执行\n在MySQL8.0版本，这个查询缓存被删除了，因为这个查询缓存的命中率很低，因为只要有一个表有更新操作，那么这个表的查询缓存就会被清空，如果刚缓存了一个查询结果很大的数据，还没有使用，刚好这个表有更新操作，查询缓存就被清空了，相当于缓存浪费了\n这里说的查询缓存是 server 层的，也就是 MySQL 8.0 版本移除的是 server 层的查询缓存，并不是 Innodb 存储引擎中的 buffer pool\n6.1.3 解析SQL 解析器会做下面两件事\n词法解析：识别关键字\n语法解析：根据词法解析的结果，根据语法规则，构建出SQL语法树\n如果我们输入的SQL语句语法不对，就会在解析器这个阶段报错\n注意：表不存在或者字段不存在，并不在解析器里识别。解析器只负责检查语法和构建语法树，但不会去查表或者字段存不存在\n6.1.4 执行SQL 经过解析器后，进入执行SQL查询语法的流程，主要可分为下面三个阶段\nprepare阶段，预处理阶段\noptimize阶段，优化阶段\nexecute阶段，执行阶段\n6.1.4.1 预处理器 预处理阶段做以下的事：\n检查SQL查询语句中的表或者字段是否存在\n将*扩展为表上所有列\n6.1.4.2 优化器 预处理阶段后，需要为SQL语句制定一个执行计划，就交由优化器完成\n优化器主要负责将SQL查询语句的执行方案确定下来，决定使用哪个索引\n在查询语句前加个explain命令，就会输出这条SQL语句的执行计划\n6.1.4.3 执行器 执行器：开始真正执行语句。在执行过程中，执行器就会和存储引擎交互，过程如下\n主键索引查询\n全表扫描\n索引下推\n6.1.4.3.1 主键索引查询 在SQL语句中查询条件使用主键索引，访问类型为const，那么执行器与存储引擎执行流程大致如下\n执行器第一次查询，调用read_first_record函数指针指向函数，访问类型为const，指向InnoDB引擎索引查询的接口，让存储引擎定位符合条件的记录\n存储引擎通过主键索引的B+树结构定位到符合条件的记录，如果记录不存在，就会向执行器上报记录找不到的错误，查询结束；如果记录存在，则返回记录给执行器\n执行器从存储引擎读到记录后，接着判断记录是否符合查询条件，如果符合则发送给客户端，不符合则跳过该记录\n执行器查询的过程是一个while循环，所以会在查询一次，此时调用read_record函数指针指向的函数，因为优化器选择的访问类型是const，这个函数指针指向一个永远返回-1的函数，所以当调用函数的时候，执行器退出循环，查询结束\n6.1.4.3.2 全表扫描 全表查询是没有用到索引，所以优化器决定选用访问类型为ALL\n执行器第一次查询，调用read_first_record函数指针指向函数，访问类型为const，指向InnoDB引擎全扫描的接口，让存储引擎定位符合条件的记录\n执行器会判断读到的记录是不是符合条件，不是则跳过；是则将记录发送给客户（Server 层每从存储引擎读到一条记录就会发送给客户端，之所以客户端显示的时候是直接显示所有记录的，是因为客户端是等查询语句查询完成后，才会显示出所有的记录）\n执行器查询的过程是一个 while 循环，所以还会再查一次，会调用 read_record 函数指针指向的函数，因为优化器选择的访问类型为 all，read_record 函数指针指向的还是 InnoDB 引擎全扫描的接口，所以接着向存储引擎层要求继续读刚才那条记录的下一条记录，存储引擎把下一条记录取出后就将其返回给执行器（Server层），执行器继续判断条件，不符合查询条件即跳过该记录，否则发送到客户端；\n一直重复上述过程，直到存储引擎把表中的所有记录读完，然后向执行器（Server层） 返回了读取完毕的信息；\n执行器收到存储引擎报告的查询完毕的信息，退出循环，停止查询。\n6.1.4.3.3 索引下推 索引下推能够减少二级索引在查询时的回表操作，提高查询的效率（它是将server层部分负责的事，交由存储引擎层去处理）\n总结 执行一条 SQL 查询语句，期间发生了什么？\n连接器：建立连接，管理连接、校验用户身份；\n查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块；\n解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型；\n执行 SQL：执行 SQL 共有三个阶段：\n预处理阶段：检查表或字段是否存在；将 select * 中的 * 符号扩展为表上的所有列。\n优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划；\n执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端；\n6.2 MySQL存储一行记录 总结 MySQL的NULL值是怎么存放的？ MySQL的Compact行格式中会使用NULL值列表来标记NULL的列，NULL值并不会存储在行格式中的真实数据\nNULL值列表会占用1字节空间，当表中所有字段都定义成NOT NULL，行格式就不会有NULL值列表，可以节省1字节空间\n6.? 引擎分类 https://juejin.cn/post/7160557698642083847\n","date":"2025-07-03","id":6,"permalink":"/notes/database/mysql/mysql-arch/","summary":"MySQL 架构- server \u0026amp;\u0026amp; storage-engine","tags":"MySQL","title":"Mysql Arch(bate)"},{"content":" Git 仓库 README.md 规范\n# 项目名称 \u0026lt;!-- 写一段简短的话描述项目 --\u0026gt; ## 功能特性 \u0026lt;!-- 描述该项目的核心功能点 --\u0026gt; ## 软件架构(可选) \u0026lt;!-- 可以描述下项目的架构 --\u0026gt; ## 快速开始 ### 依赖检查 \u0026lt;!-- 描述该项目的依赖，比如依赖的包、工具或者其他任何依赖项 --\u0026gt; ### 构建 \u0026lt;!-- 描述如何构建该项目 --\u0026gt; ### 运行 \u0026lt;!-- 描述如何运行该项目 --\u0026gt; ## 使用指南 \u0026lt;!-- 描述如何使用该项目 --\u0026gt; ## 如何贡献 \u0026lt;!-- 告诉其他开发者如果给该项目贡献源码 --\u0026gt; ## 社区(可选) \u0026lt;!-- 如果有需要可以介绍一些社区相关的内容 --\u0026gt; ## 关于作者 \u0026lt;!-- 这里写上项目作者 --\u0026gt; ## 谁在用(可选) \u0026lt;!-- 可以列出使用本项目的其他有影响力的项目，算是给项目打个广告吧 --\u0026gt; ## 许可证 \u0026lt;!-- 这里链接上该项目的开源许可证 --\u0026gt; ","date":"2025-07-03","id":7,"permalink":"/notes/git/git-repo-readme/","summary":"Git 仓库 README.md 规范","tags":"Git","title":"Git Repo Readme(bate)"},{"content":" 写出符合Angular规范的Git Commit Message\ngit commit 规范 符合Angular规范的Commit Message \u0026lt;type\u0026gt;[(optional scope)]: \u0026lt;description\u0026gt; // 空行 [optional body] // 空行 [optional footers] 分为了Header、Body、footer三个部分\nHeader Header部分只有一行\u0026lt;type\u0026gt;[(optional scope)]: \u0026lt;description\u0026gt;，其中type必选，其它可选\ntype\u0026ndash;\u0026gt;归为两类：\nDevelopment(项目管理类变更，不影响用户和生产环境的代码) Production(影响用户和生产环境的代码) 类型 类别 说明 feat Production 新增功能 fix Production 修复缺陷 perf Production 提高代码性能的变更 style Development 代码格式类的变更，例如使用gofmt格式化代码 refactor Production 其他代码类的变更，例如 简化代码、重命名变量、删除冗余代码等等 test Development 新增测试用例或更新现有的测试用例 ci Development 持续基础和部署相关的改动，例如修改Jenkins、GitLab CI等Ci配置文件或者更新系统单元文件 docs Development 文档类的更新，包括修改用户文档、开发文档 chore Development 其他类型，例如构建流程、依赖管理或者复制工具的变动 scope\u0026ndash;\u0026gt;不设置太具体的值，说明commit的影响范围 description\u0026ndash;\u0026gt;对commit的简短描述，以动词开头\nBody Body对Commit Message的高度概况，方便查看具体做了什么变更\nFooter Footer部分不是必选，可根据需要选择，主要用来说什么本次commit导致的后果，通常用来说明不兼容的改动或者关闭的issue\nBREAKING CHANGE: \u0026lt;breaking change summary\u0026gt; // 空行 \u0026lt;breaking change description + migration instructions\u0026gt; // 空行 // 空行 Fixes(Closes) #\u0026lt;issue number\u0026gt; Revert Commit 特殊的Commit Message。还原了先前的commit，则以revert开头，后面跟还原的commit的Header， 在Body必须写This reverts commit \u0026lt;hash\u0026gt;，其中hash为要还原的commit的SHA标识\n使用git commit -a进入交互界面的Commit Message\n","date":"2025-07-03","id":8,"permalink":"/notes/git/git-commit/","summary":"写出符合Angular规范的Git Commit Message","tags":"Git","title":"Git Commit(bate)"},{"content":" git 命令\ngit rebase git rebase的最大作用是重写历史\n使用git rebase -i \u0026lt;commit ID\u0026gt;使用git rebase命令 修改某次 commit 的 message\n命令 目的 p,pick 不对该commit做任何处理 r,reword 保留该commit，但是修改提交信息 e,edit 保留该commit，但是rebase是会暂停，允许你修改这个commit s,squash 保留该commit，但是将当前commit与上一个commit合并 f,fixup 与squash相同，但不会保存当前commit的提交信息 x,exec 执行其他shell命令 d,drop 删除该commit git commit -amend git commit –amend：修改最近一次 commit 的 message\n","date":"2025-07-03","id":9,"permalink":"/notes/git/git-commands/","summary":"git 命令","tags":"Git","title":"Git Commands(bate)"},{"content":" 使用Docker 以及Docker Compose部署Go程序\n部署示例 1.准备代码 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { http.HandleFunc(\u0026#34;/\u0026#34;, hello) server := \u0026amp;http.Server{ Addr: \u0026#34;:8888\u0026#34;, } fmt.Println(\u0026#34;server startup...\u0026#34;) if err := server.ListenAndServe(); err != nil { fmt.Printf(\u0026#34;server startup failed, err:%v\\n\u0026#34;, err) } } func hello(w http.ResponseWriter, _ *http.Request) { w.Write([]byte(\u0026#34;hello liwenzhou.com!\u0026#34;)) } 这里是简单代码\n2.创建Docker镜像 镜像(image)包含运行应用程序所需的所有东西——代码/二进制文件、运行时、依赖项以及所需的任何其它人间系统对象\n简单讲，镜像是定义应用程序以及运行所需的一切\n3.编写Dockerfile 要创建Docker镜像(image)必须在配置文件中的指定步骤，这个文件默认称为Dockerfile\nFROM golang:alpine # 为我们的镜像设置必要的环境变量 ENV GO111MODULE=on \\ CGO_ENABLED=0 \\ GOOS=linux \\ GOARCH=amd64 # 移动到工作目录：/build WORKDIR /build # 将代码复制到容器中 COPY . . # 将我们的代码编译成二进制可执行文件app RUN go build -o app . # 移动到用于存放生成的二进制文件的 /dist 目录 WORKDIR /dist # 将二进制文件从 /build 目录复制到这里 RUN cp /build/app . # 声明服务端口 EXPOSE 8888 # 启动容器时运行的命令 CMD [\u0026#34;/dist/app\u0026#34;] 4.Dockerfile解析 From 使用了基础镜像 golang:alpine来创建镜像。这个镜像运行的是alpine Linux发行版，该发行版的大小很小并内置了Go。有大量公开可用的Docker镜像，请查看https://hub.docker.com/_/golang\nEnv 用来设置编译阶段需要的环境变量\nWORKDIR,COPY,RUN\nEXPORT,CMD\n声明服务端口，应用程序监听这个端口并通过这个端口对外提供服务。还定义了运行镜像执行的默认执行命令CMD [\u0026quot;/dist/app\u0026quot;]\n构建镜像 在项目目录下面，在终端输入下面的命令创建镜像，并指定镜像名称为go_app\ndocker build . -t go_app 等待构建结束，输出 Successfully\n等输出 Successfully后，此时镜像已经准备好了，但是目前什么项目都没有，需要运行下面的代码来运行镜像。注：运行中的镜像称为镜像\ndocker run -p 8888:8888 go_app 标志位-p来定义端口绑定，由于容器中的应用程序在端口8888上运行，这里绑定的主机端口也是8888。如果要绑定另一个端口，则可以使用 -p $HOST_PORT:8888\n到这里就可以测试我们的程序是否工作正常，打开 http://127.0.0.1:8888 查看事先定义的响应内容。\n分阶段构建示例 Go程序编译之后可得到一个可执行的二进制文件，在最终的镜像中不需要go编译器，也就是说我们只需要一个运行最终二进制文件的容器即可。\nDocker的最佳实践之一是通过仅保留二进制文件来减小镜像大小，为此，我们将使用一种称为多阶段构建的技术\nFROM golang:alpine AS builder # 为我们的镜像设置必要的环境变量 ENV GO111MODULE=on \\ CGO_ENABLED=0 \\ GOOS=linux \\ GOARCH=amd64 # 移动到工作目录：/build WORKDIR /build # 将代码复制到容器中 COPY . . # 将我们的代码编译成二进制可执行文件 app RUN go build -o app . ################### # 接下来创建一个小镜像 ################### FROM scratch # 从builder镜像中把/dist/app 拷贝到当前目录 COPY --from=builder /build/app / # 需要运行的命令 ENTRYPOINT [\u0026#34;/app\u0026#34;] 使用这种技术，我们剥离了使用golang:alpine作为编译镜像来编译得到二进制可执行文件的过程，并基于scratch生成一个简单的、非常小的新镜像。我们将二进制文件从命名为builder的第一个镜像中复制到新创建的scratch镜像中。有关scratch镜像的更多信息，请查看https://hub.docker.com/_/scratch\n附带其他文件的部署示例 web项目(前后端不分离)一般会有静态文件或者配置文件，需要拷贝到最终的镜像文件中\n例如 templates | static | conf 三个文件的内容拷贝到镜像文件中\nFROM golang:alpine AS builder # 为我们的镜像设置必要的环境变量 ENV GO111MODULE=on \\ CGO_ENABLED=0 \\ GOOS=linux \\ GOARCH=amd64 # 移动到工作目录：/build WORKDIR /build # 复制项目中的 go.mod 和 go.sum文件并下载依赖信息 COPY go.mod . COPY go.sum . RUN go mod download # 将代码复制到容器中 COPY . . # 将我们的代码编译成二进制可执行文件 bubble RUN go build -o bubble . ################### # 接下来创建一个小镜像 ################### FROM scratch COPY ./templates /templates COPY ./static /static COPY ./conf /conf # 从builder镜像中把/dist/app 拷贝到当前目录 COPY --from=builder /build/bubble / # 需要运行的命令 ENTRYPOINT [\u0026#34;/bubble\u0026#34;, \u0026#34;conf/config.ini\u0026#34;] Tips： 这里把COPY静态文件的步骤放在上层，把COPY二进制可执行文件放在下层，争取多使用缓存。\n关联其他容器 项目中使用了MySQL，可以选择使用如下命令启动一个MySQL容器，它的别名为mysql8019；root用户的密码为root1234；挂载容器中的/var/lib/mysql到本地的/Users/docker/mysql目录；内部服务端口为3306，映射到外部的13306端口。\ndocker run --name mysql8019 -p 13306:3306 -e MYSQL_ROOT_PASSWORD=root1234 -v /Users/q1mi/docker/mysql:/var/lib/mysql -d mysql:8.0.19 这里需要修改一下我们程序中配置的MySQL的host地址为容器别名，使它们在内部通过别名（此处为mysql8019）联通。\n[mysql] user = root password = root1234 host = mysql8019 port = 3306 db = bubble 修改后记得重新构建bubble_app镜像：\ndocker build . -t bubble_app 我们这里运行bubble_app容器的时候需要使用--link的方式与上面的mysql8019容器关联起来，具体命令如下：\ndocker run --link=mysql8019:mysql8019 -p 8888:8888 bubble_app Docker Compose模式 除了像上面一样使用--link的方式来关联两个容器之外，我们还可以使用Docker Compose来定义和运行多个容器。\nCompose是用于定义和运行多容器 Docker 应用程序的工具。通过 Compose，你可以使用 YML 文件来配置应用程序需要的所有服务。然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。\n使用Compose基本上是一个三步过程：\n使用Dockerfile定义你的应用环境以便可以在任何地方复制。\n定义组成应用程序的服务，docker-compose.yml 以便它们可以在隔离的环境中一起运行。\n执行 docker-compose up命令来启动并运行整个应用程序。\n我们的项目需要两个容器分别运行mysql和bubble_app，我们编写的docker-compose.yml文件内容如下：\n# yaml 配置 version: \u0026#34;3.7\u0026#34; services: mysql8019: image: \u0026#34;mysql:8.0.19\u0026#34; ports: - \u0026#34;33061:3306\u0026#34; command: \u0026#34;--default-authentication-plugin=mysql_native_password --init-file /data/application/init.sql\u0026#34; environment: MYSQL_ROOT_PASSWORD: \u0026#34;root1234\u0026#34; MYSQL_DATABASE: \u0026#34;bubble\u0026#34; MYSQL_PASSWORD: \u0026#34;root1234\u0026#34; volumes: - ./init.sql:/data/application/init.sql bubble_app: build: . command: sh -c \u0026#34;./wait-for.sh mysql8019:3306 -- ./bubble ./conf/config.ini\u0026#34; depends_on: - mysql8019 ports: - \u0026#34;8888:8888\u0026#34; 这个 Compose 文件定义了两个服务：bubble_app 和 mysql8019。其中：\nbubble_app 使用当前目录下的Dockerfile文件构建镜像，并通过depends_on指定依赖mysql8019服务，声明服务端口8888并绑定对外8888端口。\nmysql8019 mysql8019 服务使用 Docker Hub 的公共 mysql:8.0.19 镜像，内部端口3306，外部端口33061。\n这里需要注意一个问题就是，我们的bubble_app容器需要等待mysql8019容器正常启动之后再尝试启动，因为我们的web程序在启动的时候会初始化MySQL连接。这里共有两个地方要更改，第一个就是我们Dockerfile中要把最后一句注释掉：\n# Dockerfile ... # 需要运行的命令（注释掉这一句，因为需要等MySQL启动之后再启动我们的Web程序） # ENTRYPOINT [\u0026#34;/bubble\u0026#34;, \u0026#34;conf/config.ini\u0026#34;] 第二个地方是在bubble_app下面添加如下命令，使用提前编写的wait-for.sh脚本检测mysql8019:3306正常后再执行后续启动Web应用程序的命令：\ncommand: sh -c \u0026#34;./wait-for.sh mysql8019:3306 -- ./bubble ./conf/config.ini\u0026#34; 当然，因为我们现在要在bubble_app镜像中执行sh命令，所以不能在使用scratch镜像构建了，这里改为使用debian:stretch-slim，同时还要安装wait-for.sh脚本用到的netcat，最后不要忘了把wait-for.sh脚本文件COPY到最终的镜像中，并赋予可执行权限哦。更新后的Dockerfile内容如下：\nFROM golang:alpine AS builder # 为我们的镜像设置必要的环境变量 ENV GO111MODULE=on \\ CGO_ENABLED=0 \\ GOOS=linux \\ GOARCH=amd64 # 移动到工作目录：/build WORKDIR /build # 复制项目中的 go.mod 和 go.sum文件并下载依赖信息 COPY go.mod . COPY go.sum . RUN go mod download # 将代码复制到容器中 COPY . . # 将我们的代码编译成二进制可执行文件 bubble RUN go build -o bubble . ################### # 接下来创建一个小镜像 ################### FROM debian:stretch-slim COPY ./wait-for.sh / COPY ./templates /templates COPY ./static /static COPY ./conf /conf # 从builder镜像中把/dist/app 拷贝到当前目录 COPY --from=builder /build/bubble / RUN set -eux; \\ apt-get update; \\ apt-get install -y \\ --no-install-recommends \\ netcat; \\ chmod 755 wait-for.sh # 需要运行的命令 # ENTRYPOINT [\u0026#34;/bubble\u0026#34;, \u0026#34;conf/config.ini\u0026#34;] 所有的条件都准备就绪后，就可以执行下面的命令跑起来了：\ndocker-compose up ","date":"2025-07-03","id":10,"permalink":"/notes/docker/docker-deploy/","summary":"使用Docker 以及Docker Compose部署Go程序","tags":"docker","title":"Deploy Go applications using docker(bate)"},{"content":" Dockerfile 构建你自己的容器\n学习自\n一篇文章带你吃透 Dockerfile - 掘金 (juejin.cn) Dockerfile reference 全网最详细的Docker-Compose详细教程 - 掘金 (juejin.cn) docker compose 配置文件 .yml 全面指南 - 知乎 (zhihu.com) compose-spec/spec.md at master · compose-spec/compose-spec · GitHub 学习Dockers前期，通过Docker的官方镜像仓库拉取里面的镜像，根据这些镜像创建出容器并运行\n实际上，Docker官方镜像也是通过一定的方式构建出来的，只要弄清其中的逻辑，我们也可以仿照官方镜像的构建过程，构建出自己的镜像\nDockerfile就是这样一个用于描述Docker镜像构建过程的文本文件，dockerfile可以包含多条构建指令，以及相关的描述\n1.什么是容器 容器是计算机上的沙盒进程，与主机上的其它进程隔离，这种隔离利用了内核命名空间和cgroups。简而言之容器是：\n是image的可运行实例\n可以在本地计算机、虚拟机上运行或部署到云中\n是可移植的\n与其它容器隔离，并运行自己的软件，二进制文件和配置\n2.什么是容器映射 当容器运行时，它使用了隔离的文件系统。这个自定义的文件系统由容器映像container image提供。因为image包含了容器的问价系统，使用image必须包含所有的运行应用程序所必须的所有东西——依赖项、配置、脚本、二进制文件等等。\n沙盒进程是指在计算机系统中，为了保障安全和隔离性而采用的一种技术，将应用程序运行在一个受限制的环境中，限制它们能访问的资源和操作范围，从而避免恶意程序和授权程序对系统的破坏\n3.容器是怎么运行的 当一个容器运行时，它为其文件系统使用来image的各个层。每个容器都有自己的命名空间来创建/更新/删除文件。在另一个容器中不会看到任何更改，即使它们使用相同的image\n4.容器卷[container volumes] 每个容器启动时都是从容器的定义开始的。在容器中可以创建、更新和删除文件，但当容器被删除时，这些改变将回丢失，所有更变都被隔离在各个容器中\n卷：提供了将容器的特定文件系统路径链路到主机的能力。如果在主机上的某个文件被挂载，那么当容器中该文件路径下的文件发送更改时，我们在主机上同样也可以看到更改。同样的，启动另一个挂载了同一个文件目录的容器，它也可以访问到相同的文件\n镜像构建原理 1.Docker架构模式 docker使用了client/server的架构模式。构建镜像时，用户在dockers client输入构建命令。docker引擎以 REST API的形式，像 docker daemon发送构建请求，如何dockers daemon就根据构建请求的内容，开始镜像构建的工作，并向Client持续放回构建过程的信息。\n2.镜像分层模型 docker镜像是用于创建容器的只读模板，是通过 Dockerfile中定义的指令构建而成的，构建结束后，会在原有的镜像层上生成一个新的镜像层，如下所示\n在 tomcat 镜像创建一个容器后，会在tomcat镜像之上新创建一个可写的容器层，在容器中写文件时，会保存到这个容器层中\n3.基础镜像与父级镜像 用于构建基础镜像的 Dockerfile 不指定父级镜像，Docker约定使用如下形式基础镜像\nFROM scratch 这里的 scratch是一个空镜像，可以从零开始构建镜像，常用来构建最小镜像，如busybox，debian，alpine等镜像，省去很多linux命令，因此很小。一般，不需要自己去构建基础镜像。\n构建自定义镜像时，通过FROM指定使用说明父级镜像。例如，官方的tomcat命令没有yum，vim等命令，但是我们可以将tomcat镜像作为父级镜像，然后安装想要的命令，这样在容器中就可以使用了。\n4.构建上下文 / build context Client 向 Docker daemon 发送的构架请求包含两部分，第一部分是 Dockerfile文件，第二部分是构建上下文\n构建上下文是一些文件集合，这些文件可以是指定路径下的文件，也可以是远程资源中指定路径下的文件，在构建过程中，Docker daemon 可以访问这些文件，并执行相应的操作[理解：访问配置文件]\n路径上下文 构建命令中指定具体路径，该路径下的所有文件即为构建上下文，这些文件被打包送给Docker daemon中，然后被解压\n假使一个项目的文件结构如下\ndemo |--Dockerfile |--src |--test |--node_modules 在项目根目录执行下面的构建命令\ndocker build -t img-tag . 构建请求的第一部分是Dockerfile，这个文件在当前目录下，文件是默认名称，因此省略，\n相当于默认加上了 -f Dockerfile, 该Dockerfile内容如下\nFROM busybox WORKDIR /src COPY src . 构建请求的第二部分是 .这个点代表当前，此时当前目录就是此次的构建的上下文，Docker引擎会整理该目录下的所有文件，把不被 .dockerignore中的规则所的文件都发送到Docker daemon中，如下所示\n如果此时位于项目根目录的上一级目录，构建命令如下\ndocker build -t img-tag -f ./demo/Dockerfile ./demo/ URL上下文 Docker 还支持利用远程仓库URL构建镜像，此时指定的远程仓库目录就充当了构建上下文\ndocker build https://gitee.com:user/my-repo.git#master:docker 以上构建命令指定了一个 Gitee 项目的 master 分支，冒号（:）之前是 Git 检出的目标 URL, 冒号之后的 docker 是远程仓库根目录下的一个子目录，此时这个子目录就是构建上下文\nDocker client 执行构建命令时，Docker 引擎首先会将远程仓库的 master 分支拉取到本地的一个临时目录中，然后将其中的 docker 目录下的文件作为构建上下文发送到 Docker daemon 中。拉取远程文件之后，又回到了路径上下文的步骤，如下图所示\n省略上下文 如果 Dockerfile 中的指令不需要对任何文件进行操作，可以省略构建上下文，此时不会向 Docker daemon 发送额外的文件，这可以提高构建速度\ndocker build -t my-hello-world:latest -\u0026lt;\u0026lt;EOF FROM busybox RUN echo \u0026#34;hello world\u0026#34; EOF 5.构建缓存 迭代过程中，Dockerfile对于的资源会被经常修改，因此需要频繁重新构建镜像，Docker为了提高构建速度，设计了多种优化方案，其中最重要的是构建缓存\n示例：说明构建缓存是如何工作的，Dockerfile如下\n# syntax=docker/dockerfile:1 FROM ubuntu:latest RUN apt-get update \u0026amp;\u0026amp; apt-get install -y build-essentials COPY main.c Makefile /src/ WORKDIR /src/ RUN make build 镜像构建过中，dockerfile 中的指令会从上往下执行，每一个构建步骤的结果都会被缓存起来，例如\n此时再次构建，会直接使用缓存中的结果(Using cache)\n这里假设修改了main.c 中的代码，再次构建时，从 COPY main Makefile /src/这条指令开始，后续构建缓存都会失效，如下图所示\n如果不想使用构建缓存，执行构建命令时，可以传入 --no-cahe\n6.镜像构建过程 Docker Client 执行构建命令后，会经过以下步骤构建出最终镜像\n确定构建上下文，如果构建上下文中有 .dockerignore 文件，解析该文件的匹配规则，将构建上下文中被匹配的文件资源排除\n将 Dockerfile 和构建上下文发送给 Docker daemon\nDocker daemon 收到构建请求。以下的步骤都由 Docker daemon 完成，省略主语\n逐条校验 Dockerfile 中的指令是否合法，如果不合法，立即结束构建。这一步可以确定一共有多少个构建步骤，便于后续分步构建时显示当前步骤，如 Step 1/2\n逐条执行 Dockerfile 中的指令，每条指令都新创建一层。会生成临时 container 用于执行命令，该步骤结束后删除临时容器\n生成最终镜像\n.dockerignore 这个文件需要遵循一定的语法规则\n以 # 开头的行是备注，不会被解析为匹配规则\n支持 ? 通配符，匹配单个字符\n支持 * 通配符，匹配多个字符，只能匹配单级目录\n支持 ** 通配符，可匹配多级目录\n支持 ! 匹配符，声明某些文件资源不需要被排除\n可以用 .dockerignore 排除 Dockerfile 和 .dockerignore 文件。Docker Client 仍然会将这两个文件发送到 Docker daemon，因为 Docker 底层需要。但 ADD 和 COPY 指令就无法操作这两个文件了\n示例：\n# this is a .dockerignore demo */demo* */*/demo* demo? **/mydemo* Dockerfile Dockerfile时一个用于描述Docekr镜像构建过程的文本文件，包含多条构建指令，以及相关的描述\nDockerfile的构建指令需要遵循如下的语法\n# Comment INSTRUCTION arguments 以 #开头的行绝大部分是注释，还有一小部分是解析器指令\n构建指令分两个部分，第一部分是指令，第二部分是指令参数。\n1.解析器指令 / parse directive 解析器指令是以 #开始，用来提示解释器对 Dockerfile进行特殊处理，构建过程中它不会增加镜像层，也不会出现在构建过程\n解析器指令是可选的\n# directive=value # 解析器指令需要在空行，注释，构建指令之前 注意事项\n同一解析器指令不能重复\n不区分大小写，按照惯例，推荐小写\n空行、注释、构建指令之后，Docker 不再查找解析器指令，都当成注释\n按照惯例，解析器指令位于 Dockerfile 的第一行，在后面添加空行\n行内的空格被忽略，不支持跨行\nDocker 目前支持两种解析器指令\nsyntax\nescape\nsyntax 解析器指令，只有使用 BuildKit 作为构建器时才生效\nescape 解析器指令，用于指定在 Dockerfile 中使用转义字符\n在 Dockerfile 中，escape 默认为 \\\n# escape=\\ 复制代码 但 Windows 系统中的 \\ 是路径分隔符，推荐将 escape 替换为 `，这和 PowerShell 是一致的\n# escape=` 2.常见指令解析 序号 指令名 功能描述 1 FROM 指定基础镜像或者父级镜像 2 LABEL 为镜像添加元数据 3 ENV 设置环境变量 4 WORKDIR 指定后续指令的工作目录，类似于Linux中的cd命令 5 USER 指定当前构建阶段以及容器运行时的默认用户，以及可选的用户组 6 VOLUME 创建具有指定名称的挂载数据卷，用于数据持久化 7 ADD 将构建上下文中指定目录下的文件复制到镜像文件按系统的指定位置 8 COPY 功能与语法与ADD类似，但是不会自动解压文件，也不能访问网络资源 9 EXPOSE 约定容器运行时监听的端口，通常用于容器与外界之间的通信 10 RUN 用于构建镜像过程中执行目录 11 CMD 构建镜像成功后，所创建的容器启动时执行的命令，常与ENTRYPOINT结合使用 12 ENTRYPOINT 用于配置容器以可执行的方式运行，常与CMD结合使用 FROM\n指定基础镜像或父级镜像\nFORM [--platform=\u0026lt;platform\u0026gt;] \u0026lt;image\u0026gt; [AS \u0026lt;name\u0026gt;] FORM [--platform=\u0026lt;platform\u0026gt;] \u0026lt;image\u0026gt;[:\u0026lt;tag\u0026gt;] [AS \u0026lt;name\u0026gt;] FORM [--platform=\u0026lt;platform\u0026gt;] \u0026lt;image\u0026gt;[@\u0026lt;digest\u0026gt;] [AS \u0026lt;name\u0026gt;] tag或digest是可选项，默认为latest版本为基础镜像\n如果不以任何镜像为基础，使用：FORM scratch.scratch是一个空镜像，用于构建最小镜像\nLABEL\n为镜像添加元数据\nLABEL \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt;... 示例: LABEL auth=\u0026#34;ch\u0026#34; \\ version=\u0026#34;1.0.0\u0026#34; \\ decription=\u0026#34;Dockerfile\u0026#34; 使用LABEL定义键值对结构的元数据，一个LABEL可指定多个元数据\n定义元数据值时，尽量使用双引号\n当前镜像可以继承继承镜像或者父级镜像中的元数据时，可以覆盖\n可使用以下命令查看元数据\ndocker image inspect -f=\u0026#39;{{json .ContainerConfig.Labels}}\u0026#39; my-image ENV\n设置环境变量\nENV \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt;... ENV \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; 当前镜像可以继承基础镜像或者父级镜像中的环境变量，也可以覆盖\n使用ENV指定定义的环境变量，最终会持久化到容器中\n运行容器时，可以通过--env =或者-e =覆盖镜像定义中的环境变量\n对只使用在镜像构建过程中的变量，推荐使用ARG，或者内环境变量，这样不会被持久化到最终的镜像中\n内环境变量示例：RUN TEMP=\u0026quot;no persisit\u0026quot;\n查看最终镜像中的环境变量 docker image inspect -f=\u0026#39;{{json .ContainerConfig.Env}}\u0026#39; my-image WORKDIR\n指定后续指令的工作目录，类似linux中的cd命令\nWORKDIR /path/to/workdir 使用Dockerfile中设置的环境变量\nENV DIR_PATH=/demo WORKDIR $DIR_PATH/$DIR_NAME RUN pwd 构建镜像时，pwd 的输出结果是 /demo，因为 $DIR_NAME 未显示指定，直接忽略\n默认的工作目录是/\n可以使用Dockerfile中显示指定的环境变量，包括父级镜像中的环境变量\n父级镜像可能设置工作目录，最佳实践是显示设置当前镜像的工作目录\nUSER\n指定当前构建阶段以及容器运行时的默认用户，以及可选的用户组\nUSER \u0026lt;user\u0026gt;[:\u0026lt;group\u0026gt;] USER \u0026lt;user\u0026gt;[:\u0026lt;GID\u0026gt;] USER \u0026lt;UID\u0026gt;[:\u0026lt;group\u0026gt;] USER \u0026lt;UID\u0026gt;[:\u0026lt;GID\u0026gt;] 使用USER指定用户后，Dockerfile中构建镜像的RUN,CMD,ENTRYPOINT指令都会使用该用户，同时这个用户也是容器运行时的默认用户\n不指定用户组，使用默认用户组root\n运行容器时，可以使用-u参数覆盖Dockerfile中默认的用户\nVOLUME\n创建具有指定名称的挂载数据卷，用于数据持久化\nVOLUME [\u0026#34;volume1\u0026#34;,\u0026#34;volume2\u0026#34;,...] VOLUME volume1 volume2 ... 数据卷的特征以及作用：\n数据持久化，避免容器重启后丢失重要数据\n修改数据卷时不会对容器产生影响，防止容器不断膨胀\n有利于多个容器共享数据\nADD\n将构建上下文中指定目录下的文件**(src)复制到镜像文件系统的指定位置(dest)**\nADD [--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;][--checksum=\u0026lt;checksum\u0026gt;]\u0026lt;src\u0026gt;... \u0026lt;dest\u0026gt; ADD [--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;][\u0026#34;\u0026lt;src\u0026gt;\u0026#34;, ...\u0026#34;\u0026lt;dest\u0026gt;\u0026#34;] ADD \u0026lt;git ref\u0026gt; \u0026lt;dir\u0026gt; 如果ADD指令对应的src资源有变更，Dockerfile中这条指令后的构建缓存都会失效\nDockerfile中--chown特性只有在linux下才有效，windows是无效的\nsrc支持通配符\ndest必须是文件夹，用以存放文件\n如果src是压缩资源，将会被解压为一个文件\n如果 src 是远程 URL, 并且 dest 不以 / 结尾，Docker 从 URL 下载文件，存到 dest 中\n如果 src 是远程 URL，URL 中含有非空路径，并且 dest 以 / 结尾，Docker 会推断文件名，根据 URL 中的路径，在目标位置创建相同路径，将下载的文件放入其中\ndest 可以是镜像文件系统下的绝对路径，或者是 WORKDIR 下的相对路径\n如果 dest 不是以 / 结尾，Docker 会把它当成普通文件，src 中的内容会被写入这个文件中\n如果目标位置下的某些目录不存在，会自动创建\nADD 添加网络资源时不支持身份认证，可以使用 RUN wget 或者 RUN curl 实现这个功能\nCOPY\n功能与ADD类似，但是不会自动解压文件，也不能访问网络资源\nCOPY [--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;] \u0026lt;src\u0026gt;... \u0026lt;dest\u0026gt; COPY [--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;] [\u0026#34;\u0026lt;src\u0026gt;\u0026#34;,... \u0026#34;\u0026lt;dest\u0026gt;\u0026#34;] EXPOSE\n约定容器运行时监听的端口，通常用于容器与外界之间的通信\nEXPOSE \u0026lt;port\u0026gt; [\u0026lt;port\u0026gt;/\u0026lt;protocol\u0026gt;...] 支持 TCP 或者 UDP 协议，如果不显式指定协议，默认使用 TCP 协议\n需要同时以 TCP 和 UDP 协议的方式暴露同一个端口时，需要分别指定\nEXPOSE 并不会真正将端口发布到宿主机，而是作为一种约定，让镜像使用者在运行容器时，用 -p 分别发布约定端口，或者 -P 发布所有约定端口\n如果没有暴露端口，运行容器是也可以通过 -p 的方式映射端口\nRUN\n用于构建镜像过程中执行命令，有两种执行方式\n第一种，以shell方式运行\nRUN \u0026lt;command\u0026gt; RUN echo \u0026#34;Hello Dockerfile\u0026#34; 第二种，以exec的方式运行\nRUN [\u0026#34;executable\u0026#34;,\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;...] CMD\n构建镜像成功后，所创建的容器启动时执行的命令\nCMD command param1 param2 #shell CMD [\u0026#34;executable\u0026#34;,\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] #exec CMD [\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] #作为ENTRYPOINT的默认参数，是exec方式的特殊形式 Docker种只有一条CMD指令生效，在多条CMD指令存在的情况下，只有最后一条生效\n虽然Dockerfile中只有一条CMD生效，但每一条CMD指令会新增一个镜像层，所有推荐只定义一条CMD指令，使用\u0026amp;\u0026amp;连接多个指令\nexec方式是通过JSON数组的方式进行解析的，因此需要双引号\n与RUN指令不同，RUN指令是在构建指令的过程中执行，CMD命令是在容器启动时执行\ndocker run后的命令行参数会覆盖CMD中的命令\nENTRYPOINT\n用于配置容器以可执行的方式运行。有两种形式\nENTRYPOINT [\u0026#34;executable\u0026#34;,\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] #推荐 ENTRYPOINT command param1 param2 Dockerfile中只有最后一条ENTRYPOINT指令生效\n运行容器时，docker run \u0026ndash;entrypoint 覆盖该指令\nshell 形式的 ENTRYPOINT 会使 CMD 命令 和 docker run\n中的命令行参数失效。它有一个缺点，ENTRYPOINT 命令将作为 /bin/sh -c 的子命令，不会传递信号。比如，停止容器时，容器内接收不到 SIGTERM 信号，这并不是预期的效果，可以在命令前添加 exec 来解决，如 ENTRYPOINT exec top -b\n指定 ENTRYPOINT 后，CMD 的内容将作为默认参数传给 ENTRYPOINT 指令，形如\n如果 CMD 是在基础镜像中定义的，当前镜像定义的 ENTRYPOINT 会将 CMD 的值重置为空值，这种情况下，需要重新定义 CMD\nDocker-Compose docker-compose通过一个声明式的配置文件描述整个应用，从而使用一条命令即可完成部署\ndocker-compose同使用YAML文件来定义多级服务，在使用时默认使用文件名docker-compose.yml，也可以在docker compose运行时使用-f参数来指定具体文件\ncompose的优点\n在单主机上建立多个隔离环境，Compose使用项目名称将环境彼此隔离，可以在多个不同的上下文中使用此项目名称\n创建容器时保留卷数据\n仅重新创建以更改的容器，当服务没有更改时，Compose会使用现有的容器\n变量在环境之间组合重复使用\n多个配置文件\n可以为用一个项目配置多个compose文件，使用多个compose文件能够针对不同的环境或者不同的工作流自定义compose应用程序\n默认情况下，compose读取两个文件，docker-compose.yml和一个可选docker-compose.override.yml文件\n如果在两个文件中都定义了服务，compose会使用override进行合并配置\n当配置文件的名称非默认情况时，可以使用-f指定Compose文件\ndocker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d yaml文件级\nDocker compose的YAML文件包含有4个一级key:version,services,networks,volumes\nversion:指定版本信息，通常位于文件的第一行。其定义了Compose文件格式的版本。\nservices:用于定义不用的应用服务。Docker Compose会将每个服务部署在各种的容器中。\nnetworks:用于指引Docker创建新的网络。默认情况下，Docker Compose会创建bridge网络，这个是一个单主机网络，只能实现同一主机上容器的连接。可以使用driver属性指定不同的网络类型\nvolumes用于指引Docker来创建新的卷\ndocker-compose.yml的具体配置： 1.build 指定构建镜像的dockerfile的上下文路径，或者详细配置文件\nversion: \u0026#34;3.9\u0026#34; services: webapp: build: ./dir 或者更详细的写法\nversion: \u0026#34;3.9\u0026#34; services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 context 上下文路径，可以是文件路径，也可以是到链接到 git 仓库的 url。当是相对路径时，它被解释为相对于 Compose 文件的位置。\ndockerfile 指定构建镜像的 Dockerfile 文件名\nargs 构建参数，只能在构建过程中访问的环境变量\ncache_from 缓存解析镜像列表\nlabels 设置构建镜像的元数据\nnetwork 设置网络容器连接，none 表示在构建期间禁用网络\nshm_size 设置/dev/shm此构建容器的分区大小\ntarget 多阶段构建，可以指定构建哪一层\n2.network \u0026hellip;累了，下次再写\nversion: \u0026#39;3.9\u0026#39; services: mysql: build: context: ./mysql environment: MYSQL_ROOT_PASSWORD: admin restart: always container_name: mysql volumes: - /data/edu-bom/mysql/test:/var/lib/mysql image: mysql/mysql:5.7 ports: - 3306:3306 networks: net: eureka: build: context: ./edu-eureka-boot restart: always ports: - 8761:8761 container_name: edu-eureka-boot hostname: edu-eureka-boot image: edu/edu-eureka-boot:1.0 depends_on: - mysql networks: net: networks: net: volumes: vol: docker compose常用命令\n构建并启动服务——docker-compose up -d\n停止运行并删除服务——docker-compose down\n列出所有运行容器——docker-compose ps\n查看服务日志——docker-compose logs\n构建或重建——docker-compose build\n启动服务——docker-compose start\n停止运行中的服务——docker-compose stop\n重启服务——docker-compose restart\n","date":"2025-07-03","id":11,"permalink":"/notes/docker/dockerfile/","summary":"Dockerfile 构建你自己的容器","tags":"docker","title":"Dockerfile(bate)"},{"content":" Docker 一文\nhttps://yeasy.gitbook.io/docker_practice/\n一、基本概念 镜像(Image) 容器(Container) 仓库(Repository) 理解以上三个概念，就能理解docker的生命周期\n1.镜像 Docker镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件，以及一些运行时所需的配置参数。镜像不包含任何动态数据，其内容在插件之后也不会被改变\n分层存储，镜像采用了分层存储的架构，由一组文件系统组成的（多层文件系统联合组成）。在构建镜像时，会一层一层构建，后一层依赖于上一层，后一层上的任何改变都只会发生在本层，不会干涉到上一层。因此构建镜像的时候，需要对每层需要添加的东西尽量加最少最有必要的东西，减少额外的东西\n分层存储的特征还使得镜像的复用，定制更为容易\n2.容器 容器是镜像运行时的实体，可以被创建、启动、停止、删除暂停等\n镜像(Image)和容器(container)的关系，就像是面向对象程序设计中的类 和实例 一样\n容器的实质是进程，运行于属于自己的独立的命名空间。因此容器可以拥有自己的root 文件系统，网络配置、进程空间等，运行在一个隔离的环境。这样的隔离特性，使得容器封装的应用比直接在宿主运行更加安全\n容器也是分层存储，是以镜像为基础层，在其上创建一个当前容器的存储层，这个层是为容器运行时进行读写而准备的，称为容器存储层\n容器存储层的生命周期跟容器一样，当容器消亡时，容器存储层也随之消亡，因此任何保存于容器存储层的信息都会随着容器的删除而丢失\nDokcer最佳实践的要求，容器不应该向其存储层写入任何数据，容器存储层保存无状态化，所有的文件写入操作，都应该使用数据卷、或者绑定宿主目录\n数据卷独立于容器，使用容器卷，容器的删除或者重写运行之后，数据都不会丢失\n3.仓库 Docker Register：提供一个集中的存储、分发镜像的服务\n一个Docker Register可以包含多个**仓库（Repository）;每个仓库可以包含多个标签（Tag）,**每个标签对应一个镜像\n可以通过\u0026lt;Repository Name\u0026gt;:\u0026lt;Tag Name\u0026gt; 的格式来指定具体的软件是那个版本的镜像\n仓库名以两段路径形式出现，比如jwilder/nginx-proxy 前者是Docker Registry多用户环境下的用户名，后者是对应的软件名\nDocker Registry 公开服务 Docker Registry公开服务是开放给用户使用、允许用户管理镜像的Registry服务。\n最常见的是Docker Registry公开服务是官方的hub.docker.com，也是默认的Registry\n也可以使用国内的镜像网站\n私有Docker Registry 用户可以在本地搭建私有的Docker Registry。Docker提供了Docker Registry镜像，可以直接使用搭建私有Registry服务\n二、镜像 1.获取镜像 从Docker镜像仓库获取镜像的命令是 docker pull\ndocker pull [选项] [Docker Registry 地址[:端口号]/] 仓库名[:标签] 具体选项可以从docker pull --help 命令查看，\nDocker镜像仓库地址：地址格式一般为 \u0026lt;域名/IP\u0026gt;[:端口号]。默认地址是 Docker Hub\n仓库名：仓库名是两段式，即\u0026lt;用户名\u0026gt;/\u0026lt;软件名\u0026gt;.对于Docker Hub，如果不给出用户名，默认为 library，也就是官方镜像\ndocker pull ubuntu:18.04 上面命令没有给出Docker镜像仓库地址，默认从Docker Hub获取镜像。而镜像名称是ubuntun:18.04,因此会获取官方镜像 library/ubuntun仓库中标签为18.04的镜像\n2.运行 有了镜像后，我们就能够以这个镜像为基础启动并运行一个容器。以上面的ubuntu:18.04为例，如果我们打算启动ubuntu\u0026gt;\u0026gt;bash并且进行交互式操作的话，可以执行下面命令\n$ docker run -it --rm \\ ubuntu:18.04 \\ bash docker run就是运行容器的命令\n-it：是两个参数，一个是-i：交互式操作、一个是-t：终端。这里打算进入bash执行命令并查看返回结果， --rm：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 docker rm。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 --rm 可以避免浪费空间。 ubuntu:18.04：这是指用 ubuntu:18.04 镜像为基础来启动容器。 bash：放在镜像名后的是 命令，这里我们希望有个交互式 Shell，因此用的是 bash。 通过 exit 退出了这个容器。 列出镜像 使用docker image ls命令，可以列出已经下载下来的镜像\n$ docker image ls Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/library/ubuntu 18.04 e28a50f651f9 3 weeks ago 65.5 MB 列表包含了仓库名、标签、镜像ID、创建时间、所占用的空间\n镜像 ID 则是镜像的唯一标识，一个镜像可以对应多个 标签。\n1.镜像体积 docker image ls 列表中的镜像体积总和并非是所有镜像实际硬盘消耗。由于 Docker 镜像是多层存储结构，并且可以继承、复用，因此不同镜像可能会因为使用相同的基础镜像，从而拥有共同的层。由于 Docker 使用 Union FS，相同的层只需要保存一份即可，因此实际镜像硬盘占用空间很可能要比这个列表镜像大小的总和要小的多。\n可以使用 docker system df命令来查看镜像、容器、数据卷所占用的空间\n2.虚悬镜像 一个特殊的镜像，这个镜像既没有仓库名，也没有标签，均为 \u0026lt;none\u0026gt;。：\n\u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 00285df0df87 5 days ago 342 MB 这个镜像原本是有镜像名和标签的，原来为 mongo:3.2，随着官方镜像维护，发布了新版本后，重新 docker pull mongo:3.2 时，mongo:3.2 这个镜像名被转移到了新下载的镜像身上，而旧的镜像上的这个名称则被取消，从而成为了 \u0026lt;none\u0026gt;。除了 docker pull 可能导致这种情况，docker build 也同样可以导致这种现象。由于新旧镜像同名，旧镜像名称被取消，从而出现仓库名、标签均为 \u0026lt;none\u0026gt; 的镜像。这类无标签镜像也被称为 虚悬镜像(dangling image) ，可以用下面的命令专门显示这类镜像：\n$ docker image ls -f dangling=true REPOSITORY TAG IMAGE ID CREATED SIZE \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 00285df0df87 5 days ago 342 MB 一般来说，虚悬镜像已经失去了存在的价值，是可以随意删除的，可以用下面的命令删除。\ndocker image prune 3.中间层镜像 为了加速镜像构建、重复利用资源，Docker会利用中间层镜像。使用在使用一段时间过后，可能会看到一些依赖的中间层镜像。默认的 docker image ls列表中只会显示顶层镜像，如果希望显示包括中间层镜像所在内的所有镜像的话，需要加-a参数\ndocker image ls -a 4.列出部分镜像 不加任何参数的情况下，docker image ls 会列出所有顶层镜像，但是有时候我们只希望列出部分镜像。docker image ls 有好几个参数可以帮助做到这个事情。\n根据仓库名列出镜像\n$ docker image ls ubuntu REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu 18.04 f753707788c5 4 weeks ago 127 MB ubuntu latest f753707788c5 4 weeks ago 127 MB 列出特定的某个镜像，也就是说指定仓库名和标签\n$ docker image ls ubuntu:18.04 REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu 18.04 f753707788c5 4 weeks ago 127 MB 除此以外，docker image ls 还支持强大的过滤器参数 --filter，或者简写 -f。之前我们已经看到了使用过滤器来列出虚悬镜像的用法，它还有更多的用法。比如，我们希望看到在 mongo:3.2 之后建立的镜像，可以用下面的命令：\n$ docker image ls -f since=mongo:3.2 REPOSITORY TAG IMAGE ID CREATED SIZE redis latest 5f515359c7f8 5 days ago 183 MB nginx latest 05a60462f8ba 5 days ago 181 MB 想查看某个位置之前的镜像也可以，只需要把 since 换成 before 即可。\n此外，如果镜像构建时，定义了 LABEL，还可以通过 LABEL 来过滤。\n$ docker image ls -f label=com.example.version=0.1 ... 5.以特定格式显示 默认情况下，docker image ls 会输出一个完整的表格，但是我们并非所有时候都会需要这些内容。比如，刚才删除虚悬镜像的时候，我们需要利用 docker image ls 把所有的虚悬镜像的 ID 列出来，然后才可以交给 docker image rm 命令作为参数来删除指定的这些镜像，这个时候就用到了 -q 参数。\n","date":"2025-07-03","id":12,"permalink":"/notes/docker/docker/","summary":"Docker 一文","tags":"docker","title":"Docker(bate)"},{"content":" Redis代办事项\nRedis 数据结构 字符串 String 链表 LinkList 集合 Set 有序集合 ZSet 哈希表 Hash 跳表 SkipList Redis 架构 单线程模型 Reactor 多线程 过期淘汰算法 Redis 持久化 AOF RDB 混合持久 Redis 缓存应用 缓存击穿 缓存穿透 缓存雪崩 缓存一致性 Redis 集群 主从模式 哨兵模式 集群模式 一致性hash Redis 应用场景 分布式锁 查询缓存 ","date":"2025-07-03","id":13,"permalink":"/notes/database/redis/todo/","summary":"Redis代办事项","tags":"Redis","title":"Redis - Todo"},{"content":" MySQL 内容代办事项\nSQL基础语法 MySQL架构 client层 server层 连接器 查询缓存 解析器 优化器 执行器 存储引擎 InnoDB 表空间 数据页结构 行记录存储 Buffer Pool MyISAM Memory MySQL索引 数据结构 B+树索引 Hash索引 Full-text 索引类型 聚簇索引 非聚簇索引 索引优化 主键索引 唯一索引 普通索引 联合索引 前缀索引 索引失效 索引覆盖 索引下推 索引选择 MySQL事务 ACID 原子性 隔离性 持久性 一致性 事务并发 脏读 不可重复读 幻读 事务隔离级别 读未提交 读已提交 可重复读 串行化 隔离级别实现 MVCC 锁 MySQL锁 全局锁 表级锁 表锁 MDL锁 意向锁 自增锁 局部锁 记录锁 间隙锁 临键锁 插入意见锁 死锁 MySQL日志 undo log redo log WAL 两阶段提交 bin log MySQL调优 explain 解释计划 查询性能调优 分页调优 连接池 MySQL高可用 读写分离 分库分表 分布式ID 分布式锁 数据迁移 分布式事务 高可用 分布式数据库 数据库设计 设计规范(三范式) 设计原则 反范式设计 ","date":"2025-07-02","id":14,"permalink":"/notes/database/mysql/todo/","summary":"MySQL 内容代办事项","tags":"MySQL","title":"MySQL - Todo"},{"content":"Redis\u0026lt; enc-HashTable \u0026gt; HASHTABLE可以使用O(1)时间复杂度能够快速找到field对应的value，简单理解，HASHTABLE是一个目录，可以帮助我们快速找到需要内容\nHASHTABLE的结构:\ntypedef struct dictht { dictEntry **table; unsigned long size; unsigned long sizemask; unsigned long used; } dictht; 最外层封装一个dictht结构，字段含义如下：\nTable: 指向实际hash存储。存储可以看做一个数组 Size: 哈希表大小，实际就是dictEntry有多少元素空间 Sizemask: 哈希表大小的掩码表示，总是等于size-1. 这个属性和哈希值一起决定一个键应该放到table数组的那个索引上面，规则 Index = hash \u0026amp; sizemask. Used: 表示已经使用的节点数量。通过这个字段可以查询目前HASHTABLE元素总量 dictEntry结构如下：\ntypedef struct dictEntry { void *key; union { void *val; uint64_t u64; int64_t s64; double d; } v; struct dictEntry *next; void *metadata[]; } dictEntry; Hash 渐进式扩容/缩容 扩容 渐进式扩容就是一点一点扩大HASHTABLE的容量，默认值为4 (#define DICT_HT_INTTIAL_SIZE 4) 为了实现渐进式扩容，Redis没有直接把dictht暴露给上层，而是再封装了一层\ntypedef struct dict { dictType *type; void *privdata; dictht ht[2]; long rehashidx; unsigned long iterators; } dict; dict结构里面，包含了2个dictht结构，也就是2个HASHTABLE结构。\ndictEntry是链表结构，用拉链法解决Hash冲突，用的是头插法\n实际上，平时使用的时候就是一个HASHTABLE，在触发扩容之后，就会有两个HASHTABLE同时使用，详细过程如下： 当向字典添加元素时，需要扩容时会进行rehash\n::: info Rehash流程分以下三步：\n为新Hash表ht[1]分配空间，新表大小为第一个大于等于原表ht[0]的2倍used的2次幂。例如，原表used=500，2*used=1000，第一个大于1000的2次幂为1024，因此新表的大小为1024. 此时，字典同时持有ht[0]和ht[1]两个哈希表，字典的偏移索引rehashidx从静默状态-1，设置为0，表示Rehash正式开始工作。 迁移ht[0]数据到ht[1]在Rehash进行期间，每次对字典执行增删改查操作，程序会顺带迁移当前rehashidx在ht[0]上的对应数据，并更新偏移索引(rehashidx)。 随着字典操作的不断执行，最终在某个节点，ht[0]的所有键值对会被Rehash到ht[1]，此时再将ht[1]和ht[0]两个指针对象互换，同时把偏移索引的值设置为-1，表示Rehash操作已经完成。 小总结：渐进式扩容的核心是操作时顺带迁移 ::: 扩容时机 redis提出一个负载因子的概念，负载因子表示目前Redis HASHTABLE的负载情况\n用k表示负载因子：k=ht[0].used/ht[0].size，也就是使用空间和总空间大小的比例，redis会根据负载因子的情况来扩容：\n负载因子 k大于1 时，说明此时空间非常紧张，新数据在链表上叠加，越来越多的数据导致查询无法在O(1)时间复杂度找到，还要遍历链表，如果此时服务器没有执行BGSAVE或BGREWRITEAOF两个命令，就会发生扩容。 负载因子 k大于5 时，说明HASHTABLE已经不堪重负，此时即使有复制命令在，也要进行扩容 缩容 当有了多余的空间，如果不释放，就会导致多余的空间被浪费\n缩容过程和扩容是相似的，也是渐进式缩容，同样缩容时机也是用负载因子来控制的\n当负载因子小于0.1，此时进行缩容，新表的大小为第一个大于等于used的2次幂\n使用BGSAVE或BGREWRITEAOF两个复制命令，缩容也会受影响，不会进行\n","date":"2025-06-10","id":15,"permalink":"/notes/database/redis/datatypes/encoding/hashtable/","summary":"HASHTABLE可以使用O(1)时间复杂度能够快速找到field对应的value，简单理解，HASHTABLE是一个目录，可以帮助我们快速找到需要内容","tags":"Redis","title":"Redis - Encoding\u003cHashTable\u003e"},{"content":"Redis\u0026lt; enc-SDS \u0026gt; sds(Simple Synamic String)，简单动态字符串，是redis内部作为基石的字符串封装（很重要）\nsds是redis封装字符串结构，用以解决字符串追加和长度计算操作来带的性能瓶颈问题\nredis中SDS分为sdshdr8、sdshdr16、sdshdr32、sdshdr64，字段属性一致，区别再对应不同大小的字符串\nstruct __attribute__((__packed__)) sdshdr8 { uint8_t len; // 使用了多少内部 uint8_t alloc; // 分配了多少内存 unsigned char flags; // 标记是什么分类 例如： #define SDS_TYPE_8 1 char buf[]; } 从上面的结构可以看出SDS是怎么解决问题的：\n增加len字段，快速返回长度 增加空余空间(alloc - len)，为后续追加数据留余地 不要以\u0026rsquo;\\0\u0026rsquo;作为判断标准，二进制安全 SDS预留空间大小的规则：alloc = min(len, 1M) + len：\nlen小于1M的情况下，alloc=2*len, 预留len大小的空间 len大于1M的情况下，alloc=1M+lne, 预留1M大小的空间 ","date":"2025-06-10","id":16,"permalink":"/notes/database/redis/datatypes/encoding/sds/","summary":"sds(Simple Synamic String)，简单动态字符串，是redis内部作为基石的字符串封装（很重要）","tags":"Redis","title":"Redis - Encoding\u003csds\u003e"},{"content":"Redis\u0026lt; enc-SkipList \u0026gt; 跳表是Redis有序集合ZSet底层的数据结构\nredis中跳表的两处应用：\n1. 实现有序集合键 2. 在集群节点中作为内部数据结构 从本质上看是链表，这种结构虽然简单清晰，但是查询某个节点的效率比较低，而在有序集合场景，无论是查找还是添加删除元素，我们是需要快速通过score定位到具体位置，如果是链表的话时间复杂度是O(N)\n为了提高查找的性能，Redis引入跳表，跳表在链表的基础上，给链表增加了多级的索引，通过索引可以一次实现多个节点的跳跃，提高性能\nSKIPLIST 结构 Redis SKIPLIST 单节点的结构:\ntypedef struct zskiplistNode { sds ele; double score; struct zskiplistNode *backward; struct zskiplistLevel { struct zskiplistNode *forward; unsigned long span; } level[]; } zskiplistNode; 字段的定义：\nEle: SDS结构，用来存储数据 Score: 节点的分数，浮点型数据 Backward: 指向上一个节点的回退指针，支持从表尾向表头遍历，也就是ZREVRANGE这个命令 level: 是个zskiplistLevel结构体数组，包含两个字段，一个是forward，指向该层下个能跳到的节点，span记录距离下个节点的步数，数组结构表示每个节点可能是多层结构 在标准的跳表中，score值是不可重复的，但是在Redis ZIPLIST中，score值是可重复的，增加了回退指针\nSKIPLIST 细节 Redis跳表单个节点有几层？ 层次的决定，需要比较随机，才能在各个场景表现出较平均的性能，这里Redis使用概率均衡的思路来确定插入节点的层数：\nRedis跳表决定每一个节点，是否能增加一层的概率为25%，而最大层数限制在Redis 5.0是64层，在Redis 7.0是32层\nRedis跳表的性能优化了多少？ 平均时间复杂度为O(log(n))，跳表的最坏平均时间复杂度是O(N)，当然实际的生产过程中，体现出来的基本是跳表的平均时间复杂度\n","date":"2025-06-10","id":17,"permalink":"/notes/database/redis/datatypes/encoding/skiplist/","summary":"跳表是Redis有序集合ZSet底层的数据结构","tags":"Redis","title":"Redis - Encoding\u003cSkipList\u003e"},{"content":"Redis\u0026lt; enc-ZipList \u0026gt; ZIPLIST压缩列表，是排列紧凑的列表，为Redis供紧凑型的数据存储方式，能节约内存（节省链表指针的开销），数据量小的时候遍历访问性能好（连续+缓存命中率友好）\n关于LISTPACK是Redis 5.0引入，Redis 7.0完全替代ZIPLIST.\nZIPLSIT 整体结构 // redis代码注释，描述了ZIPLIST的结构 \u0026lt;zlbytes\u0026gt; \u0026lt;zltail\u0026gt; \u0026lt;zllen\u0026gt; \u0026lt;entry\u0026gt; \u0026lt;entry\u0026gt; ... \u0026lt;entry\u0026gt; \u0026lt;zlend\u0026gt; 各字段定义：\nzlbytes: 表示该ZIPLIST一共占了多少字节，这个数字是包含zlbytes本身占据的字节的 zltail: ZIPLIST尾巴节点，相对于ZIPLIST的开头，偏移的字节数 zllen: 表示有多少个数据节点 entry: 表示压缩列表的数据节点 zlend: 一个特殊的entry节点，为1个字节11111111即255占据，表示ZIPLIST的结束 ZIPLIST 节点结构 - entrys 其定义如下\n* \u0026lt;prevlen\u0026gt; \u0026lt;encoding\u0026gt; \u0026lt;entry-data\u0026gt; 各字段含义：\nprevlen: 表示前一个节点的长度。通过该节点定位到前一个节点的起始地址，如果前一个节点是压缩列表的开头，那么这个字段的值为0，通过该字段，可以实现往前操作，即ZIPLIST可以从后往前遍历.\n有关上一个entry的长度，从prevlen字段可以获得，根据entry的大小，prevlen所占字节也会有所变化:\nentry \u0026lt; 254 : prevlen为1字节，(值得注意的是255在entry中是个特殊数字，被zlend使用，表示ZIPLIST的结束) entry \u0026gt;= 254 : prevlen为5字节，在这5个字节中，第一个字节作为标志位，固定为11111110，表示prevlen是5个字节，后面4个字节才是prevlen记录的上一个节点长度. encoding: 编码类型，包含了entry的长度信息，用于正序遍历.\nencoding是一个整型数据，其二进制数据由entry-data的类型和字节长度组成\n如果是string类型，那么encoding由两部分，前几位为标识位、后几位标识长度 如果是int类型，整体1字节编码，那么仅标识类型，根据不同的int类型，确定其长度，例如int32就是32位，4字节 entry-data: 实际的数据\nZIPLIST 查询数据 获取节点数量 ZIPLIST可以在O(1)时间复杂度返回节点数量，因为其header定义了记录节点数量的zllen，但是zllen仅占2字节长度，最大记录65534，当节点数量超过65535时，就需要通过遍历节点获取节点数量. 之所以zllen是2个字节，原因是redis中应用ZIPLIST是为了节点个数少的场景，所以将zllen设计得比较小，节约内存空间\n查询指定数据的节点 在ZIPLIST中查询指定数据的节点，需要遍历压缩列表，平均时间复杂度为O(N)\nZIPLIST 更新数据 ZIPLIST的更新就是增加、删除数据，ZIPLIST提供头尾增减的能力，平均时间复杂度O(N)，因为在头部增加一个节点会导致后面节点都往后移动，所以更新平均时间复杂度O(N).\n更新操作可能带来连锁更新，连锁更新是指节点后移发生不止一次，而是多次\n连锁更新的触发条件是：插入一个大于254字节的元素时，如果记录新元素的长度的下一节点的prevlen原本为1字节，但是因为新元素的长度大于254字节，导致prevlen需要变成5字节，导致后面节点的prevlen可能需要跟着变化，这就是ZIPLIST的连锁更新.\n尽管连锁更新可能导致性能问题，但实际上这种情况发生的概率较低。因为要发生连锁更新，需要ZipList中有连续多个长度刚好为250到253字节的节点，这种情况在实际应用中并不常见.\nLISTPACK 优化 LISTPACK是为了解决ZIPLIST最大的痛点——连锁更新\nZIPLIST需要支持LIST，LIST是一种双端访问的结构，所以需要能从后往前遍历 ZIPLIST的数据节点：prevlen encoding entry-data 其中，prevlen表示上个节点的数据长度，通过这个字段可以定位上一个节点的数据 连锁更新的问题，就是因为prevlen导致的\nLISTPACK以一种不记录prevlen，并且还能找到上一个节点的起始位置的节点结构，解决ZIPLIST存在的连锁更新问题\n\u0026lt;encoding-type\u0026gt; \u0026lt;element-data\u0026gt; \u0026lt;element-tot-len\u0026gt; encoding-type是编码类型，element-data是数据内容，element-tot-len存储整个节点除了它自身之外的长度即element-type和element-data的长度之和 element-tot-len所占用的每个字节的第一个bit用于标识是否结束，第一个bit 0 是结束 1 是继续，剩下7个bit来存储数据大小 ","date":"2025-06-10","id":18,"permalink":"/notes/database/redis/datatypes/encoding/ziplist/","summary":"ZIPLIST压缩列表，是排列紧凑的列表，为Redis供紧凑型的数据存储方式，能节约内存（节省链表指针的开销），数据量小的时候遍历访问性能好（连续+缓存命中率友好）","tags":"Redis","title":"Redis - Encoding\u003cZipList\u003e"},{"content":"Redis \u0026lt; Hash \u0026gt; Redis Hash 是结构化为字段值(field)-\u0026gt;值(value)集合的记录类型. 可以使用Hash来表示基础对象并存储计数器分组.\n创建的Hash数量没有实际限制，除了受到可用内存的限制， 但是每个Hash最多可以存储 4,294,967,295 (2^32 - 1) 个字段值对\nHash可以很方便的表示对象\nHash 命令 Hash常用命令：\n创建：HSET, HSETNX HSET key field value # 为集合对于field设置value，可以一次设置多个field-value HSETNX key field value # 如果field不存在，则为集合对应field设置value数据 查询：HGETALL, HGET, HLEN, HSCAN HGETALL key # 查找全部数据 HGET key field # 查找某个key（field） HLEN key # 查找Hash中元素总数 HSCAN key cursor [MATCH pattern] [COUNT count] # 从指定位置查询一定数量的数据，这里注意如果是小数据量下，处于ZIPLIST时，COUNT不管填多少，都是返回全部，因为ZIPLIST本身就用于小集合，没必要切分几段返回 更新：HSET, HSETNX, HDEL HDEL key field [field ...] # 删除指定field，可以一次删除多个 删除：DEL DEL key [key ...] # 删除Hash对象 Hash 编码(底层实现) Hash底层有两个编码方式：ZIPLIST, HASHTABLE\nZIPLIT编码需要满足以下条件: Hash对象保存的所有值和键的长度都小于64字节 Hash对象保存元素对象小于512个 当Hash的底层编码为ZIPLIST时，即数量较少时将数据紧凑排列，对应到Hash，就是将field-value当作entry存放进ZIPLIST.\n如果Hash的底层编码为HASHTABLE时，与上面的Set（无序列表）使用HASHTABLE，区别在于在Set中Value始终为null，但是在Hash中，具有对应的值.\n[!NOTE] 编码详解 🔗 查看HASHTABLE编码\n","date":"2025-06-10","id":19,"permalink":"/notes/database/redis/datatypes/hash/","summary":"Redis Hash 是结构化为字段值(field)-\u0026gt;值(value)集合的记录类型. 可以使用Hash来表示基础对象并存储计数器分组.","tags":"Redis","title":"Redis - Hash"},{"content":"Redis \u0026lt; List \u0026gt; Redis List是一组连续的字符串值链表，这意味着向List的头部或者尾部中添加新元素的操作会在恒定的时间内完成， 无论其已经存储了多少元素，但是缺点是访问元素的操作则需要遍历List，时间复杂度为O(N)\nRedis List经常用于:\n实现堆栈和队列 为后台系统构建队列管理 List 命令 常用命令:\n创建 \u0026ndash;\u0026gt; LPUSH, RPUSH LPUSH key value [value ...] # 从头部增加元素，返回List中元素总数 RPUSH key value [value ...] # 从尾部增加元素，返回List中元素总数 查询 \u0026ndash;\u0026gt; LLEN, LRANGE LLEN # 查看List的长度，即List中元素的总数 LRANGE key start stop # 查看start到stop为角标的元素 更新 \u0026ndash;\u0026gt; LPUSH, RPUSH, LPOP, RPOP, LREM LPOP key # 移除并获取列表的第一个元素 RPOP key # 移除并获取列表的第一个元素 LREM key count value # 移除值等于value的元素 count = 0 ，则移除所有等于value的元素； count \u0026gt; 0 ，则从左到右开始移除count个value元素； count \u0026lt; 0，则从右往左移除count个元素 删除 \u0026ndash;\u0026gt; DEL, UNLINK DEL key [key ...] # 删除对象，返回值为删除成功了几个键 UNLIKN key [key ...] # 删除对象，返回值为删除成功了几个键 del命令与unlink命令均为删除对象，不同的是del命令是同步删除目录，会阻塞客户端，直到删除完成； unlink命令是异步删除命令，只是取消key在键空间的关联，让其不在能查到，删除是异步进行，所以不会阻塞客户端.\nList还支持多个阻塞命令：BLPOP, BLMOVE\u0026hellip;\nBLPOP # 从列表头部删除并返回一个元素。如果列表为空，则该命令将阻塞，直到有元素可用或达到指定的超时为止. BMOVE # 以原子方式将元素从源列表移动到目标列表。如果源列表为空，该命令将阻塞，直到有新元素可用. ::: tip 详细List命令 🔗 List命令列表 :::\nList 编码(底层实现) 在Redis.Version \u0026lt; 3.2时，List的编码为ZIPLIST或LINKEDLIST，在Redis.Version \u0026gt;= 3.2时，List的编码为QUICKLIST，当Redis.Version \u0026gt;= 7.0后，ZIPLIST优化为LISTPACK，其本质也是一种压缩列表.\nList对象保存的所有字符串长度都小于64字节，且对象元素个数少于512个时，使用ZIPLIST编码，否则使用LINKEDLIST编码.\nZIPLIST的底层使用压缩列表实现，内存排序紧凑，可以有效节省内存空间.\n[!NOTE] 编码详解 🔗 查看ZIPLIST编码\n如果使用LINKEDLIST编码，是以链表的形式连接，在内存上不如ZIPLIST紧凑，所以只有在List元素个数或者节点长度比较大的时候，才会使用LINKEDLIST编码.\nLINKEDLIST是以牺牲内存换取更快的处理性能.\ntypedef struct list { listNode *head; listNode *tail; void *(*dup)(void *ptr); void (*free)(void *ptr); int (*match)(void *ptr, void *key); unsigned long len; } list; 在Redis 3.2版本只会，引入了QUICKLIST编码. QUICKLIST编码是ZIPLIST和LINKEDLIST的结合体，LINKEDLIST原先的节点存放数据，现在单个节点存放的是一个ZIPLIST.\n当数据较少时，QUICKLIST的节点只有一个，相当于一个ZIPLIST. 当数据较多时，则同时利用ZIPLIST和LINKEDLIST的优点. ","date":"2025-06-10","id":20,"permalink":"/notes/database/redis/datatypes/list/","summary":"Redis List经常用于:","tags":"Redis","title":"Redis - List"},{"content":" Redis 多线程持久化 | IO复用\nRedis 多线程持久化 Redis多线程模型\nredis一开始就是基于单线程模型，Redis里所有的数据结构都是非线程安全，规避了数据竞争问题，使得Redis对各种数据结构的操作非常简单\nredis选择单线程的核心原因是Redis都是内存操作，CPU处理都非常快，瓶颈更容易出现在I/O而不是CPU，所以选择了单线程模型\n随着数据量的增大，redis的瓶颈更容易出现在I/O而不是CPU\n因为上述情况，Redis选择了引入多线程来处理网络I/O，这样即保持了Redis核心的单线程处理价格，又引入了多线程解决提高网络I/O的性能\n","date":"2025-06-10","id":21,"permalink":"/notes/database/redis/arch/multi-thread/","summary":"Redis 多线程持久化 | IO复用","tags":"Redis","title":"Redis - Multi Thread"},{"content":" Redis是一个基于内存的数据库，数据存储在内存中，以键值对的形式存储.\nRedis 数据库结构 Redis的数据库结构：\n// redisDb 结构 type struct redisDb { dict *dict; //字典 dict *expires; // 过期键 dict *blocking_keys; dict *ready_keys; dict *watched_keys; int id; long long avg_ttl; list *defrag_later; } redisDb; // dict 结构 typedef struct dict { dictType *type; void *privdata; dictht ht[2]; long rehashidx; unsigned long iterators; } dict; redisDb 代表Redis数据库结构，各种操作对象，都存储在dict数据结构里.\ndict 是Redis的字典结构，存储键值对. expires 是Redis的过期键字典结构，存储过期键. 操作Redis在内存中的表现 添加数据 # 即添加键值对，添加到dict结构字典中，Key必须为String对象，value为任何类型的对象，添加数据后，会在redisDb里字段dict上添加dict对象 查询数据 # 直接在dict找到对应的key，即完成查询 更新数据 # 对已经Key对象的任何变更操作，都是更新 删除数据 # 删除即把key和value从dict结构里删除 关于过期键 expiresKey Redis可以设置过期键，到达一定时间，这些对象会被自动过期并回收\n过期键存储在expires字典上，expires字典中，value就是过期时间\n在redisDb中，dict和expires中Key对象，实际都是存储String对象指针，两个的key都会指向内存相应的字符串地址\n:::tip 链接\n过期键清除策略 ::: ","date":"2025-06-10","id":22,"permalink":"/notes/database/redis/arch/redisdb/","summary":"Redis是一个基于内存的数据库，数据存储在内存中，以键值对的形式存储.","tags":"Redis","title":"Redis - redisDB"},{"content":"Redis\u0026lt; Set \u0026gt; Redis Set是一个唯一字符串的集合\n适用于：\n跟踪唯一目标(e.g., 跟踪访问给定博客的所有唯一IP地址) 表示关系(e.g., 具有给定角色的所有用户集合) 执行常见的集合运算(e.g., 根据集合运算能力获取不同用户的共同信息) Redis Set的最大大小为2^32-1(4294967295)\nSet 命令 Set的基本操作有：\n创建：SADD SADD key member [member ...] # 添加元素，返回值为成功添加了几个元素 查询：SISMEMBR, SCARD, SMEMBERS, SSCAN, SINTER, SUNION, SDIFF SISMEMBER key member # 查询元素是否存在 SCARD key # 查询集合元素个数 SMEMBERS key # 查看集合的所有元素 SSCAN key cursor[MATCH pattern][COUNT count] # 查看集合元素，可以理解为指定游标进行查询，可以指定个数，默认为10 SINTER key [key ...] # 返回在第一个集合，同时在后面所有集合都存在元素 SUNION key [key ...] # 返回所有集合的并集，集合个数大于等于2 SDIFF key [key ...] # 返回第一个集合有，且后续集合中不存在的元素，结合个数大于等于2，注意 更新：SADD, SREM SADD \u0026ndash; \u0026gt; 参考上文 SREM key member [member ...] # 删除元素，返回值为成功删除几个元素 删除：DEL DEL key 删除元素 ::: tip 详细Set命令 🔗 Set命令列表 :::\nSet 编码(底层实现) Redis Set的底层编码是: INTSET, HASHTABLE\nINTSET：存储元素为整数，且元素数量不超过52个，其结构如下 \u0026lt;encoding\u0026gt; \u0026lt;length\u0026gt; \u0026lt;contents\u0026gt; \u0026lt;contents\u0026gt; --\u0026gt; \u0026lt;value1\u0026gt;\u0026lt;value2\u0026gt;... 可以看到INTSET的结构排列紧凑，内存占用少，查询的时候使用二分查找，之所以使用二分查找是因为INTSET存储的元素是排序的，且元素个数不多，但是对于Redis Set来说，应该将INTSET编码下的元素视为无序，不应该依赖其有序性，整体上应该当初无序来使用\nHASHTABLE：是一个哈希表，查询一个元素的性能很高，在O(1)时间复杂度情况下返回元素. 值得注意的是Redis Hash使用的底层编码也有HASHTABLE\nSet 使用HASHTABLE编码时，只存储键，不存储值，因而其key永远指向NULL [!NOTE] 编码详解 🔗 查看HASHTABLE编码\n","date":"2025-06-10","id":23,"permalink":"/notes/database/redis/datatypes/set/","summary":"Redis Set是一个唯一字符串的集合","tags":"Redis","title":"Redis - Set"},{"content":" Redis的单线程模型\nRedis 单线程模型 redis是一个能高效处理请求的组件\n核心处理逻辑：Redis一直都是单线程，其他辅助模块会有一些多线程、多进程的功能，例如：复制模块用的多进程；某些异步流程从4.0开始用多线程；网络I/O解包从6.0开始用多线程；\nRedis在处理客户端的请求时，包括获取（socket写）、解析、执行、内容返回等都是由一个顺序串行的主线程处理，这就是所谓的单线程\nRedis 单线程的选择 Redis的定位是内存k-v存储，是做短平快的热点数据处理，一般来说执行会很快，执行本身不会成为瓶颈，瓶颈通常在网络I/O，处理逻辑多线程并不会有太大收益\n同时Redis本身秉持简洁高效的理念，代码的简单性、可维护性是redis一直依赖的追求，执行本身不应该成为瓶颈，而且多线程本身也会引起额外成本\n引入多线程带来复杂度和额外成本 多线程引入的复杂度是极大的\n多线程引入后，redis原来的顺序执行特性就不复存在，为了事务的原子性、隔离性，redis就不得不引入一些很复杂的实现 redis的数据结构是极其高效，在单线程模式下做了很多特性的优化，如果引入多线程，那么所有底层数据都要改为线性安全，这很复杂 多线程模式使得程序调试更加复杂和麻烦，会带来额外的开发成本及运营成本 多线程带来额外的成本\n上下文切换成本，多线程调度需要切换线程上下文，这个操作先存储当前线程的本地数据，程序指针，然后载入另一个线程数据，这种内核操作的成本不可忽略 同步机制的开销，一些公共资源，在单线程模式下直接访问就行，多线程需要通过加锁等方式进行同步 一个线程本身也占据内存大小，对redis这种内存数据库来说，内存非常珍贵，多线程本身带来的内存使用的成本也需要谨慎决策 Redis 单线程的高性能 Redis 核心的请求处理是单线程，但是Redis却能使用单线程模型达到每秒数万级别的处理能力，这是Redis多方面极致设计的一个综合结果.\nRedis的大部分操作在内存上完成，内存操作本身就特别快 Redis选择了很多高效的数据结构，并做了很多优化，比如ziplist，hash，skiplist等，有时候一种对象底层有几种实现以应对不同场景 Redis采用了多路复用机制，使其在网络IO操作中能并发处理大量的客户端请求，实现高吞并量 Redis I/O多路复用 Redis在内存中处理数据，其性能瓶颈更多是在I/O\nRedis的I/O多路复用机制，是指Redis在处理客户端请求时，通过使用操作系统提供的I/O多路复用功能，实现同时处理多个客户端的请求，而不是阻塞等待每个请求的处理完成\nRedis做了一层包装，叫Reactor模型，本质就是监听各种事件，当事件发生时，将事件分发给不同的处理器\nI/O多路复用让redis单线程有了较大的并发度，这里是并发，不是并行，这种模式下，Redis单核的性能可以是被充分利用\n","date":"2025-06-10","id":24,"permalink":"/notes/database/redis/arch/single-thread/","summary":"Redis的单线程模型","tags":"Redis","title":"Redis - Single Thread"},{"content":"Redis\u0026lt; Stream \u0026gt; Redis Stream是一种数据结构，其作用类似于仅追加日志，但也实现了多种操作克服典型的仅追加日志的限制. 包括O(1)时间内的随机访问和复杂的消费策略\nStream的使用示例：\n1. 事件溯源(追踪用户操作、点击)； 2. 传感器健康; 3. 通知(将每个用户的通知存储在单独的流中) Redis为每个流条目生成一个唯一ID，可以使用这些ID检索其关联条目或读取并处理流中的所有后续条目\nRedis支持多种修剪策略和多种消费策略\nStream 命令 XADD # 将新条目添加到流中 XREAD # 读取一个或多个条目，从给定位置开始并及时向前移动 XRANGE # 返回两个提供的条目ID之间的条目范围 XLEN # 返回流的长度 Redis Stream 详细请阅读 Redis Stream\n","date":"2025-06-10","id":25,"permalink":"/notes/database/redis/datatypes/stream/","summary":"Redis Stream是一种数据结构，其作用类似于仅追加日志，但也实现了多种操作克服典型的仅追加日志的限制. 包括O(1)时间内的随机访问和复杂的消费策略","tags":"Redis","title":"Redis - Stream"},{"content":"Redis\u0026lt; String \u0026gt; Redis String 类型，存储字节，包括文本，序列化对象和二进制数组，因此 String是Redis最基本的数据结构. 通常用于缓存，而且Redis支持其他功能，允许实现计数器并执行按位运算.\n由于Redis中key是一个字符串，因此Redis使用String数据结构作为key的值.\n在默认情况下，Stirng最大为512MB，可以通过配置项proto-max-bulk-len进行修改.\nString 适用场景 使用场景：一般用来存放字节数据、文本数据、序列化后的对象数据.\n缓存场景：Value存Json字符串等信息. 计数场景：因为Redis处理命令是单线程，所以执行命令的过程是原子的，因此String数据结构适合计数场景. String 命令 常用命令:\n创建 \u0026ndash;\u0026gt; set, setnx, getset SET key value # 设置一个key值为特定的value set命令扩展参数： EX（键过期时间秒）、PX（键过期时间毫秒）、NX（只有键不存在时才对键进行操作，基本替代下面的SETNX操作）、XX（键存在时才对键进行操作）\nSETNX key value # 用于在指定的key不存在时，为key设置指定的值，对于实现锁很有用 GETSET key value # 设置一个key的值，并返回原来的值 查询 \u0026ndash;\u0026gt; get, mget Get key # 查询某个key，存在就返回对应的value，不存在返回nil Mget key [key ...] # 一次查询多个key，如果某个key不存在，对应位置返回nil 更新 \u0026ndash;\u0026gt; set 见上面的set命令 删除 \u0026ndash;\u0026gt; del DEL key [key ...] # 删除对象，返回值为删除成功了几行 其他命令：incr, incrby, incrbyfloat\nINCR key [increment] # 以原子方式将给定键中存储的计数器加 1 INCRBY key increment # 以原子方式将给定键中存储的计数器加上指定的增量值 INCRBYFLOAT key increment # 以原子方式将给定键中存储的计数器加上指定的浮点数增量值 ::: info 🔗 String命令列表 :::\nString 编码(底层实现) Redis String类型，底层实现是使用C语言的SDS字符串类型，sds类型是Redis自己实现的一种动态字符串类型，它比C语言的String类型多了一个指针，指向字符串的结尾，方便在字符串末尾追加数据。\nString的三种编码方式: INT: 存放整形，可以用long表示的整数以该编码存储； EMBSTR: 如果字符串 \u0026lt;= 阈值字节(redis.version \u0026gt; 3.2 ? 44 : 39)，使用EMBSTR编码 RAW: 字符串大于 \u0026gt; 阈值字节(redis.version \u0026gt; 3.2 ? 44 : 39)，使用RAW编码 ::: details 点击查看EMBSTR的阈值为什么是44？\n阈值字节: 在源码中使用OBJ_ENCODING_EMBSTR_SIZE_LIMIT宏定义，默认为44字节，在Redis 3.2版本中，该阈值是39字节.\nRedis默认使用jemalloc作为内存分配器 jemalloc是以64字节作为内存单元做内存分配，如果超出了64个字节就超过了一个内存单元. 在内存分配时，RedisObject会尽量在一个内存单元，是为了减少内存寻址，又不会消耗分配过多没用到的内存， 围绕64字节的关键分界分析版本变化，Redis的字符串对象是由一个RedisObject+sdshdr两部分组成， RedisObject大小为4+4+24+32+64 = 128bits = 16bytes，其中的ptr是64，是为了方便各种编译器和目标平台上使用 sdshdr8占用内存大小: 1byte + 1byte + 1byte + 内联数组的大小，由于内联数组中还有一个\u0026rsquo;\\0\u0026rsquo;占位一个字符，所以能用的大小为64-16(redisObject)-3(sdshdr非内容属性)-1(\u0026rsquo;\\0\u0026rsquo;)=44 RedisObject Struct:\n#define LRU_BITS 24 typedef struct reidsObject { unsigned type:4; // 4 bit unsigned encoding:4; // 4 bit unsigned lru:LRU_BITS; // 24 bit int refcount; // 32 bit void *ptr; // 64 bit } robj; // 128 bit == 16 bytes sdshdr Struct:\nstruct __attribute__((__packed__)) sdshdr8 { uint8_t len; // 1 byte uint8_t alloc; // 1 byte unsigned char flags; // 1 byte char buf[]; // \u0026#39;\\0\u0026#39; 占位符 1 byte } EMBSTR和RAW是由redisObject和SDS两个结构组成，两者差异在于EMBSTR编码下redisObject和SDS是连续的内存，RAW编码下redisObject和SDS的内存是分开的.\nEMBSTR的优缺点：\n优点：一次性分配内存，redisObject和SDS两个结构一次性分配内存 缺点：重新分配空间时，整体需要重新再分配 EMBSTR设计为只读，任何写操作之后EMBSTR都会变成RAW 编码转化的可能：\nINT -\u0026gt; RAW: 当内存不再是整形，或者大小超过了long EMBSTR -\u0026gt; RAW: 任何写操作之后EMBSTR都会变成RAW 🔗 查看SDS\n","date":"2025-06-10","id":26,"permalink":"/notes/database/redis/datatypes/string/","summary":"Redis String 类型，存储字节，包括文本，序列化对象和二进制数组，因此 String是Redis最基本的数据结构. 通常用于缓存，而且Redis支持其他功能，允许实现计数器并执行按位运算.","tags":"Redis","title":"Redis - String"},{"content":"Redis\u0026lt; ZSet \u0026gt; Redis ZSet 是一个关联分数排序的唯一字符串集合. 当多个字符串具有相同分数时，字符串会按照字典顺序排列。\nZSet可以适用于:\n排行榜. 使用ZSet维护大型游戏中最高分数的有序列表. 速率限制器. 使用ZSet构建滑动窗口速率限制器，以防止过多的API请求. ZSet可以视为是集合和哈希的混合，一方面，其与集合类似，由唯一的、不重复的字符串元素组成；另一方面，集合内元素没有排序，但是排序集合中每个元素都和一个浮点值相关联，也就是类似于哈希，每个元素映射一个值\n此外，排序集中的元素是按顺序获取的，这个顺序遵守以下规则：\n如果 B 和 A 是具有不同分数的两个元素，则如果 A.score 是 \u0026gt; B.score，则 A \u0026gt; B. 如果 B 和 A 的分数完全相同，则如果 A 字符串按字典顺序大于 B 字符串，则 A \u0026gt; B。 B 和 A 字符串不能相等，因为排序集仅具有唯一元素 ZSet 命令 ZSet常见命令：\n创建：ZADD ZADD key score member [score member] # 向Sorted Set增加数据，如果key已经存在的Key，则更新对应的数据 扩展参数：XX, NX, LT, GT 查询：ZRANGE, ZCOUNT, ZRANK, ZCARD, ZSCORE ZCARD key # 查看ZSet中的成员 ZRANGE key start stop [WITHSCORES] # 查询从start到stop范围的ZSet数据，WITHSCORES选填，不写输出里只有key，没有score值 ZREVRANGE key start stop [WITHSCORES] # 即reverse range，从大到小遍历，WITHSCORES选项，不写不会输出score ZCOUNT key min max # 计算min-max积分范围的成员 ZRANK key member # 查看ZSet中member的排名索引，索引从0开始，所以排名是第一，索引就是0 ZSCORE key member # 查询ZSet成员的分数 更新：ZADD, ZREM ZREM key member [member ...] # 删除ZSet中的元素 删除：DEL, UNLINK ::: tip 详细ZSet命令 🔗 ZSets命令列表 :::\nZSet 编码(底层实现) ZSet底层编码有两种：ZIPLIST， SKIPLIST+HASHTABLE\nZIPLIST 列表对象保存的所有字符串对象长度都小于64字节，且列表对象元素个数少于128个 使用ZIPLIST的目的是在数据量小的时候节省内存，在紧凑的结构中以value+score的形式存放进ziplist.entry 当上述条件不符合的时候，编码使用SKIPLIST+HASHTABLE\nSKIPLIST是一种可以快速查找的多级链表结构，通过SKIPLIST可以快速定位到数据所在，它的排名操作、范围查询性能都很高\n🔗 查看SKIPLIST编码\n","date":"2025-06-10","id":27,"permalink":"/notes/database/redis/datatypes/zset/","summary":"Redis ZSet 是一个关联分数排序的唯一字符串集合. 当多个字符串具有相同分数时，字符串会按照字典顺序排列。","tags":"Redis","title":"Redis - ZSet"},{"content":" Redis 中使用的过期淘汰算法 LRU \u0026amp;\u0026amp; LFU\nRedis 过期淘汰算法 ","date":"2025-06-10","id":28,"permalink":"/notes/database/redis/arch/lru-lfu/","summary":"Redis 中使用的过期淘汰算法 LRU \u0026amp;\u0026amp; LFU","tags":"Redis","title":"Redis - 过期淘汰算法"},{"content":" 一文详解 Redis 核心内容\n1. Redis 简介 1.1 Redis 安装 1.2 Redis 命令 1.3 Redis 高级 2. Redis 数据结构 2.1 Redis Object 2.2 Redis \u0026lt; String \u0026gt; 2.3 Redis \u0026lt; List \u0026gt; 2.4 Redis \u0026lt; Set \u0026gt; 2.5 Redis \u0026lt; Hash \u0026gt; 2.6 Redis \u0026lt; ZSet \u0026gt; 2.7 Redis \u0026lt; Stream \u0026gt; 2.8 Redis - Geospatial| Hyperloglog | Bitmap 3. Redis 架构设计 3.1 Redis 单线程 | 多线程 3.2 Redis 过期策略算法 4. Redis 持久化策略 4.1 Redis AOF 4.2 Redis RDB 4.3 Redis 混合持久化 5. Redis 缓存应用 5.1 Redis 缓存 5.2 Redis 缓存一致性 6. Redis 高可用 6.1 Redis 主从复制 6.2 Redis 哨兵 6.3 Redis 集群 Redis相关资料 redis/Docs 小林coding/redis redis中文网 菜鸟教程/redis zhihu/【超级详细】一文搞懂redis的所有知识点 ","date":"2025-06-10","id":29,"permalink":"/notes/database/redis/redis-core/","summary":"一文详解 Redis 核心内容","tags":"Redis","title":"Redis-core"},{"content":" Hugo 是最受欢迎的开源静态网站生成器之一. 凭借其惊人的速度和灵活性，Hugo 让网站建设再次变得有趣.\n本篇内容将全部基于Hugo 官方文档以及个人的实际操作. 实际上Hugo 的官方文档非常加十分的详细，我也超级推荐直接阅读官方的文档. 但是官方文档的内容太多，这对新手来说第一时间很难上手，包括我，所以我想将整个文档进行阅读记录，以方便入门.\n于此同时，本站点也是使用了Hugo 进行搭建，所以进行这样一份学习记录也许有助于我改进网站.\nHugo Hugo是一个用Go语言编写的静态网站生成器，针对速度进行优化，并且灵活设计. 它凭借先进的模板系统和快速的资产管道，Hugo可以在几秒钟内渲染出完整的站点.\n其灵活的框架设计、多语言支持和强大的分类系统，Hugo很适合搭建文档站点，博客站点，以及各种静态网站.\n安装 - Installation 这里仅演示linux 下的安装过程\n在按照Hugo前，你需要先了解Hugo提供的三个版本：标准版、扩展版和扩展/部署版.\n标准版：仅包含核心功能，适合于开发者和普通用户使用. 扩展版：包含标准版所有功能，并且提供了许多扩展功能，如图片WebP格式处理, 使用嵌入的LibSass转化CSS, 使用Dart Sass转换器等. 扩展/部署版：包含扩展版所有功能，并且提供了许多部署功能，如Google Cloud Storage、AWS S3或者Azure存储容器等. Hugo官方推荐使用扩展版, 下面的安装过程也展示扩展版的安装.\n环境准备 使用Hugo时，Git, Go和Dart Sass是经常使用的. 其中Git是必须的，Go和Dart Sass如果不选择安装仅影响部分功能的使用.\n安装Git(必要) 安装Go(可选) 安装Dart Sass(可选) 直接下载 源码构建 仓库软件包 Configuration CLI ","date":"2025-04-08","id":30,"permalink":"/notes/hugo/hugo-docs/","summary":"Hugo 是最受欢迎的开源静态网站生成器之一. 凭借其惊人的速度和灵活性，Hugo 让网站建设再次变得有趣.","tags":"hugo","title":"Hugo Docs (Continuous Updates)"},{"content":" Bitcask是一个高性能的键值存储系统，设计之初的目的是提供高写入吞吐量和高效读取性能。采用了日志化结构哈希表(Log-Structured Hash Table)，核心是写前日志(WAL)、内存哈希表和定期merge.\n具体细节均在官方的设计论文 Bitcask Design Paper 中可以查看。\n官方论文中提到的bitcask应该具备的特性\nlow latency per item read or written high throughput, especially when writing an incoming stream of random items ability to handle datasets much larger than RAM w/o degradation crash friendliness, both in terms of fast recovery and not losing data ease of backup and restore a relatively simple, understandable (and thus supportable) code structure and data format predictable behavior under heavy access load or large volume a license that allowed for easy default use in Riak 目前已经有优秀的开源实现：\nprologic/bitcask ahmeducf/bitcask rosedblabs/mini-bitcask Bitcask 核心 目录结构(bitcask)：作为一个目录，存储数据文件，仅允许一个进程同时写入 数据文件(datafile)： activefile: 当前用于写入的文件，达到阈值（1GB）时关闭，变成仅读文件 readonlyfile: 仅读文件，存储旧数据条目 dataentry: 写入数据文件的数据条目 =\u0026gt; { crc | tstamp | key_sz | value_sz | key | value } 内存结构(keydir): 映射键值到数据文件中的位置，每次写入时原子更新 index: [key] -\u0026gt; { file_id | value_sz | value_pos | tstamp } 合并(merge): 定期或者主动触发合并操作，遍历不可变文件，创建新的包含最新现有键的数据文件，同时生成提示文件(hint) 提示文件(hint): 包含数据文件中值的位置和大小信息，即保存keydir，加速启动流程 恢复崩溃(recover): 由于数据文件的不可变且作为提交日志，恢复简单，扫描提示文件进行恢复 在bitcask论文中提到，允许处理比内存大得多的数据集，且不显著降低性能，是因为其采用了将键和元数据存储在内存中，而将数据值存储在磁盘上，通过键值分离的设计，使其能够处理比内存大得多的数据集。但是因此bitcask将所有的键存储在内存中，这可能在键数量极多的时候成为瓶颈。\n","date":"2025-04-05","id":31,"permalink":"/blogs/2025/0405.bitcask-core/","summary":"Bitcask是一个高性能的键值存储系统，设计之初的目的是提供高写入吞吐量和高效读取性能。采用了日志化结构哈希表(Log-Structured Hash Table)，核心是写前日志(WAL)、内存哈希表和定期merge.","tags":"bitcask","title":"Bitcask"},{"content":"关于本站 本站由 Hugo 搭建，使用math-queiroz/Rusty-Typewriter 扩展主题.\n计划在这里记录自己的学习笔记，包括但不限于 Golang, Java, Cangjie, cs_base, Git, Docker, Kubernetes, Message Queue, MySQL, Redis, HTML, CSS, JavaScript, TypeScript, Vue, React以及一些 开源项目 等\u0026hellip;\n文章结构 this is a example of directory structure content/ ├── archive │ ├── _index.md │ └── projects │ ├── bitcask.md │ └── _index.md ├── blogs │ ├── 2025-04-08.goose.md │ ├── bitcask │ │ ├── 2025-04-05.bitcask-core.md │ │ └── 2025-04-08.build-your-own-bitcask.md │ └── _index.md ├── hugoes │ ├── build-my-hugo-site.md │ └── hugo-docs.md ├── about.md └── search.md 在content/blogs 目录下，将以 date.title.md 的markdown文件列表. content/archive/**/* 将存在目录层级，以方便查找想要阅读的博客，\n计划未来支持 更加灵活的i18n支持 更多元的markdown支持 更加丰富的icon支持 更多丰富的组件支持 更详细的TODO列表 提供ctl+k打开搜索功能 修复不同语言下details_read_time错误 ==\u0026gt; 支持中文 修复归档文章的shortcode无法正常显示toc以及details_read_time 修复search搜索时查找错误 + 搜索失效问题 修复白天黑夜主题不点击主题按钮却发生主题切换的bug 添加归档详细页面 ","date":"2025-04-05","id":32,"permalink":"/about/","summary":"本站由 Hugo 搭建，使用math-queiroz/Rusty-Typewriter 扩展主题.","tags":"","title":"About"},{"content":" Go项目开发中比较常用的设计模式介绍\n创建型模式 单例模式 工厂模式 结构型模式 策略模式 模板模式 行为型模式 代理模式 选项模式 创建型模式 单例模式 package singleton import \u0026#34;sync\u0026#34; type singleton struct {} var ins *singleton var once sync.Once func GetInsOr() *singleton{ once.Do(func(){ ins = \u0026amp;singleton{} }) return nil } 使用once.Do可以确保ins实例全局被创建一次\n单例模式实际上有饿汉方式和懒汉方式，这里只介绍在Go项目中单例模式最优雅的实现方式\n工厂模式 工厂模式是面向对象编程中的常用模式。可以通过不同的工厂模式来带得Go项目变得简洁\n简单工厂模式 package factory type Person struct{ Name string Age string } func (p Person) Greet() { fmt.Printf(\u0026#34;name := %s, age := %s\u0026#34;, p.Name, p.Age) } func NewPerson(name string, age int) *Person { return \u0026amp;Person{ Name: name, Age: age, } } 通过NewPerson创建实例，可以确保实例的Name和Age属性被设置\n抽象工厂模式 抽象工厂模式和简单工厂模式的唯一区别，返回的是接口而不是结构体\n通过返回接口，可以在不公开内部实现的情况下，让调用者使用提供的各种功能\npackage factory type PersonIntf interface { Greet() } type person struct { name string age int } func (p person) Greet() { fmt.Printf(\u0026#34;Hi! My name is %s\u0026#34;, p.name) } // Here, NewPerson returns an interface, and not the person struct itself func NewPerson(name string, age int) PersonIntf { return person{ name: name, age: age, } } 工厂方式模式 在工厂方法模式，依赖工厂函数，通过实现工厂函数来创建多种工厂，将对象创建从由一个对象辅助所有具体类的实例化，变成由一群子类来负责具体类的实例化\npackage factory type Person struct { name string age int } func NewPersonFactory(age int) func(name string) Person { return func(name string) Person { return Person{ name: name, age: age, } } } 结构型模式 结构型模式特点：关注类和对象的组合\n策略模式 策略模式定义一个组算法，将每个算法都封装起来，并且使它们之间可以切换，根据不同的场景，采用不同的措施，即是不同的策略。\n通过策略模式，定义一些独立的类来封装不同的算法，每个类封装一个具体的算法（策略）\npackage strategy type IStrategy interface { do(int, int) int } // 策略实现：加 type add struct{} func (*add) do(a, b int) int { return a + b } // 策略实现：减 type reduce struct{} func (*reduce) do(a, b int) int { return a - b } // 具体策略的执行者 type Operator struct { strategy IStrategy } // 设置策略 func (operator *Operator) setStrategy(strategy IStrategy) { operator.strategy = strategy } // 调用策略中的方法 func (operator *Operator) calculate(a, b int) int { return operator.strategy.do(a, b) } 模板模式 模板模式定义一个操作中算法的骨架，而将一些步骤延迟到子类中\npackage template import \u0026#34;fmt\u0026#34; type Cooker interface { fire() cooke() outfire() } // 类似于一个抽象类 type CookMenu struct { } func (CookMenu) fire() { fmt.Println(\u0026#34;开火\u0026#34;) } // 做菜，交给具体的子类实现 func (CookMenu) cooke() { } func (CookMenu) outfire() { fmt.Println(\u0026#34;关火\u0026#34;) } // 封装具体步骤 func doCook(cook Cooker) { cook.fire() cook.cooke() cook.outfire() } type XiHongShi struct { CookMenu } func (*XiHongShi) cooke() { fmt.Println(\u0026#34;做西红柿\u0026#34;) } type ChaoJiDan struct { CookMenu } func (ChaoJiDan) cooke() { fmt.Println(\u0026#34;做炒鸡蛋\u0026#34;) } 行为型模式 行为型模式，特点是关注对象之间的通信\n代理模式 代理模式为另一个对象提供一个替身或者占位符号，以控制对像的访问\npackage proxy import \u0026#34;fmt\u0026#34; type Seller interface { sell(name string) } // 火车站 type Station struct { stock int //库存 } func (station *Station) sell(name string) { if station.stock \u0026gt; 0 { station.stock-- fmt.Printf(\u0026#34;代理点中：%s买了一张票,剩余：%d \\n\u0026#34;, name, station.stock) } else { fmt.Println(\u0026#34;票已售空\u0026#34;) } } // 火车代理点 type StationProxy struct { station *Station // 持有一个火车站对象 } func (proxy *StationProxy) sell(name string) { if proxy.station.stock \u0026gt; 0 { proxy.station.stock-- fmt.Printf(\u0026#34;代理点中：%s买了一张票,剩余：%d \\n\u0026#34;, name, proxy.station.stock) } else { fmt.Println(\u0026#34;票已售空\u0026#34;) } } StationProxy代理了Station\n选项模式 选择模式是Go项目开发中经常使用到的模式。使用选项模式，可以创建一个带有默认值的struct变量，并选择地修改其中某一些参数的值\npackage options import ( \u0026#34;time\u0026#34; ) type Connection struct { addr string cache bool timeout time.Duration } const ( defaultTimeout = 10 defaultCaching = false ) type options struct { timeout time.Duration caching bool } // Option overrides behavior of Connect. type Option interface { apply(*options) } type optionFunc func(*options) func (f optionFunc) apply(o *options) { f(o) } func WithTimeout(t time.Duration) Option { return optionFunc(func(o *options) { o.timeout = t }) } func WithCaching(cache bool) Option { return optionFunc(func(o *options) { o.caching = cache }) } // Connect creates a connection. func NewConnect(addr string, opts ...Option) (*Connection, error) { options := options{ timeout: defaultTimeout, caching: defaultCaching, } for _, o := range opts { o.apply(\u0026amp;options) } return \u0026amp;Connection{ addr: addr, cache: options.caching, timeout: options.timeout, }, nil } 选项模式通常适用于以下场景：\n结构体参数很多，创建结构体时，我们期望创建一个携带默认值的结构体变量，并选择性修改其中一些参数的值。 结构体参数经常变动，变动时我们又不想修改创建实例的函数。例如：结构体新增一个retry参数，但是又不想在NewConnect入参列表中添加retry int这样的参数声明。 ","date":"2024-11-19","id":33,"permalink":"/notes/langs/golang/go-design-pattern/","summary":"Go项目开发中比较常用的设计模式介绍","tags":"golang","title":"Go-常见设计模式"},{"content":"接下来将从以下6个方面，逐渐学习和了解HTTP\nHTTP基本概念 Get与Post HTTP特征 HTTP缓存 HTTPS与HTTP HTTP/1.1、HTTP/2、HTTP/3演变 HTTP基本概念 1.HTTP是什么？ HTTP是超文本传输协议，也就是HyperText Transfer Protocol\nHTTP的名字【超文本传输协议】，可以拆成三个部分：\n超文本\n传输\n协议\n针对 HTTP 协议，我们可以这么理解。\n「协议」 HTTP 是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（两个以上的参与者），以及相关的各种控制和错误处理方式（行为约定和规范）。\n「传输」 HTTP 协议是一个双向协议。\n针对传输，我们可以进一步理解了 HTTP。\nHTTP 是一个在计算机世界里专门用来在两点之间传输数据的约定和规范。\n「超文本」 HTTP 传输的内容是「超文本」。\n理解「超文本」，它就是超越了普通文本的文本，它是文字、图片、视频等的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本。\nHTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。\nHTTP是用于从互联网服务器传输超文本到本地浏览器的协议，这个说法是错误的，因为HTTP也可以服务于【服务器\u0026lt;\u0026mdash;\u0026gt;服务器】，所有采用两点之间的描述比较准确\n2.HTTP常见的状态码 1xx 类状态码属于提示信息，是协议处理中的一种中间状态，实际用到的比较少。\n2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。\n「200 OK」是最常见的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头都会有 body 数据。\n「204 No Content」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。\n「206 Partial Content」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。\n3xx 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。\n「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。\n「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。\n301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。\n「304 Not Modified」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。 4xx 类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义。\n「400 Bad Request」表示客户端请求的报文有错误，但只是个笼统的错误。\n「403 Forbidden」表示服务器禁止访问资源，并不是客户端的请求出错。\n「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。\n5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。\n「500 Internal Server Error」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。\n「501 Not Implemented」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。\n「502 Bad Gateway」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。\n「503 Service Unavailable」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。\n3.HTTP 常见字段有哪些？ ","date":"2024-10-31","id":34,"permalink":"/notes/cs/net/http/","summary":"接下来将从以下6个方面，逐渐学习和了解HTTP","tags":"计算机网络","title":"[计网] HTTP"},{"content":"当键入网址后，到网页显示，期间发生了什么？ HTTP 浏览器做的第一步工作是解析****URL\n首先浏览器做的第一步工作就是要对URL进行解析，从而生成发生给Web服务器的请求信息\n在一条长长的URL里的各个元素的代表是什么\n这里的URL实际上是请求服务器里的文件资源\n当上图的蓝色部分URL元素都省略了，那么请求的是哪个文件呢？\n当没有路径名时，就代表访问根目录下事先设置的默认文件，也就是/index.html或者/default.html这些文件，这样就不好发生混乱\n生产HTTP请求信息\n对URL进行解析之后，浏览器确定了Web服务器和文件名，接下来就是根据这些信息来生产HTTP请求信息\n真实地址查询——DNS 通过浏览器解析URL并生成HTTP消息后，需要委托操作系统将消息发送给Web服务器\n但是在发送之前，还需要查询服务器域名对应的IP地址，因为委托操作系统发送消息时，必须提供通信对象的IP地址\n这里，有一种服务器就专门保存了Web服务器域名与IP的对应关系——DNS服务器\n域名的层级关系\nDNS中的域名都是用句点来分隔的，比如www.server.com，这里的句点带不了不同层次之间的界限\n在域名中，越靠右的位置表示其层级越高\n实际上域名最后还有一个点，比如www``.server.com.，这个最后一个点代表根域名\n也就是说，.根域是最顶层，它的下一层是.com顶级域,再下面是server.com\n所以，域名的层级关系类似一个树状结构\n根DNS服务器.\n顶级域DNS服务器.com\n权威DNS服务器server.com\n根域的DNS服务器信息保存在互联网中所有的DNS服务器中，这样一来任何DNS服务器都可以找到并访问根域DNS服务器\n因此，客户端只要能够找到任意一台 DNS 服务器，就可以通过它找到根域 DNS 服务器，然后再一路顺藤摸瓜找到位于下层的某台目标 DNS 服务器。\n域名解析的工作流程\n客户端首先会发出一个DNS请求，问www.server.com的IP是啥，并发给本地DNS服务器（也就是客户端的TCP/IP设置中填写的DNS服务器地址）\n本地域名服务器收到客户端的请求后，如果缓存里的表格能找到www.server.com，则直接返回IP地址，如果没有，本地DNS会去问它的根域名服务器， 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。\n根DNS收到本地DNS的请求后，根据www.server.com的后置是.com，这个域名归于.com区域管理，返回.com顶级域名服务器地址给本地\n本地DNS收到顶级域名服务器地址后，向顶级域名服务器请求负责www.server.com的权威DNS服务器的地址，\n本地DNS最后向权威DNS服务器请求www.server.com的IP地址，该server.com的权威服务器就是域名解析结果的出处。\n权威DNS服务器查询结后将对应的IP地址X.X.X.X返回到本地DNS\n本地DNS再将IP地址返回客户端，客户端和目标建立连接\n至此，DNS的解析过程完成了，其过程可见下图\n域名解析并不是每次都需要经过这么多步骤\n还有缓存的存在。\n浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回，如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回，如果没有，再去 hosts 文件看，也没有，才会去问「本地 DNS 服务器」。\n协议栈 通过DNS获取IP后，就可以把HTTP的传输工具交给操作系统中的协议栈\n协议栈的内部分为几个部分，分别承担不同的工作。上下关系是有一定的规则的，上面的部分会向下面的部分委托工作，下面的部分收到委托的工作并执行。\n应用程序（浏览器）通过调用 Socket 库，来委托协议栈工作。协议栈的上半部分有两块，分别是负责收发数据的 TCP 和 UDP 协议，这两个传输协议会接受应用层的委托执行收发数据的操作。\n协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。\n此外 IP 中还包括 ICMP 协议和 ARP 协议。\nICMP 用于告知网络包传送过程中产生的错误以及各种控制信息。\nARP 用于根据 IP 地址查询相应的以太网 MAC 地址。\nIP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。\n可靠传输——TCP HTTP是基于TCP协议传输的，\nTCP包头格式\nTCP 报文头部的格式：\n首先，源端口号和目标端口号是必不可少的，如果没有这两个端口号，数据不知道发送给哪些应用\n接下来有包的序号，这个是为了解决包乱序的问题\n还有确认号，目的是确认发出去对方是否有收到。如果没有收到就重新发送直到送达，这是是为了解决丢包问题\n还有一些状态位。例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。\n还有一个重要的就是窗口大小。TCP要做流量控制，通信双方各声明一个窗口（缓存大小），标识自己当前能够提供的处理能力，以控制流量发送的快慢\n除了流量控制以外，TCP还做了拥塞控制，能够控制数据发送的速度\nTCP传输数据之前，要先三次握手建立连接\n在HTTP传输数据之前，首先需要TCP建立连接，TCP连接的建立，通常称为三次握手\n这个所谓的「连接」，只是双方计算机里维护一个状态机，在连接建立的过程中，双方的状态变化时序图就像这样。\n一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。\n然后客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。\n服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。\n客户端收到服务端发送的 SYN 和 ACK 之后，发送对 SYN 确认的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。\n服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。\n所以三次握手目的是保证双方都有发送和接收的能力。\n如何查看TCP的连接状态\nTCP 的连接状态查看，在 Linux 可以通过 netstat -napt 命令查看。\nTCP分割数据\n如果 HTTP 请求消息比较长，超过了 MSS 的长度，这时 TCP 就需要把 HTTP 的数据拆解成一块块的数据发送，而不是一次性发送所有数据。\nMTU：一个网络包的最大长度，以太网中一般为 1500 字节。\nMSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度。\n数据会被以 MSS 的长度为单位进行拆分，拆分出来的每一块数据都会被放进单独的网络包中。也就是在每个被拆分的数据加上 TCP 头信息，然后交给 IP 模块来发送数据。\nTCP报文生成\nTCP协议里面会有两个端口，一个是浏览器监听的端口（通常为随机生成），一个是Web服务器监听的端口（HTTP默认是80，HTTPS默认是443）\n双方建立连接后，TCP报文中的数据部分就是存放了HTTP头部+数据，组装好TCP报文之后，就需要交给下面的网络层处理\n至此，网络包的报文如下图。\n远程定位——IP TCP模块在执行连接、收发、断开等阶段操作时，都需要委托IP模块将数据封装成网络包发送给通信对象\nIP包头格式\n在IP协议中，需要有源地址IP和目标地址IP：\n源地址IP：客户端输出的IP地址\n目标地址：通过DNS域名解析得到的Web服务器IP\n因为HTTP是经过TCP传输的，所有在IP包头的协议号，要填写06（十六进制），表示协议为TCP协议\n假设客户端有多个网卡，就会有多个IP地址，那么IP头部的源地址应该选择哪个地址？\n这个判断相当于在多块网卡中，判断应该使用哪个网卡来发送包\n这时候就需要根据路由表规则，来判断哪一个网卡作为源地址IP\n在 Linux 操作系统，我们可以使用 route -n 命令查看当前系统的路由表。\n举个例子，根据上面的路由表，我们假设 Web 服务器的目标地址是 192.168.10.200。\n首先先和第一条目的子网掩码（Genmask）进行 与运算，得到结果为 192.168.10.0，但是第一个条目的 Destination 是 192.168.3.0，两者不一致所以匹配失败。\n再与第二条目的子网掩码进行 与运算，得到的结果为 192.168.10.0，与第二条目的 Destination 192.168.10.0 匹配成功，所以将使用 eth1 网卡的 IP 地址作为 IP 包头的源地址。\n那么假设 Web 服务器的目标地址是 10.100.20.100，那么依然依照上面的路由表规则判断，判断后的结果是和第三条目匹配。\n第三条目比较特殊，它目标地址和子网掩码都是 0.0.0.0，这表示默认网关，如果其他所有条目都无法匹配，就会自动匹配这一行。并且后续就把包发给路由器，Gateway 即是路由器的 IP 地址。\nIP报文生成\n两点传输——MAC 生成了IP头部之后，接下来网络包还需要在IP头部的前面加上MAC头部\nMAC包头格式\n在MAC包头里需要发送方的MAC地址和接收方目标MAC地址，用于两点之间的传输\n一般在TCP/IP通信里，MAC包头的协议类型只使用：\n0800：IP协议\n0806：ARP协议\nMAC发送方和接收方如何确认？\n发送方的MAC地址获取简单，MAC地址在网卡生产时写入到ROM里面，只要将这个值读取出来写入到MAC头部就行\n接收方的MAC地址就有点复杂，只要告诉以太网对方的MAC地址，以太网就会把包发送过去，那么对方的MAC地址哪里来呢？\n这是得先清楚应该把包发给谁，需要查询一下路由表，在路由表中找到匹配的条目，然后把包发送给Gateway列中的IP地址\n如何获取对方的MAC地址？\n这里需要ARP协议帮我们找到路由器的MAC地址\nARP协议会在以太网中以广播的形式，对以太网所有的设备进行广播，如果对方和自己处在同一张子网中，那么上面操作就可可以得到对方的MAC地址，那么将这个MAC地址写入MAC头部后，MAC头部就完成了\nARP缓存\n在得到对方的MAC地址后，操作系统会将本次的查询结果放到一块ARP缓存的内存空间，不过缓存保存的时间就几分钟\n也就是说，在发包时：\n先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。\n而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。\n查看 ARP 缓存内容\n在 Linux 系统中，我们可以使用 arp -a 命令来查看 ARP 缓存的内容。\nMAC 报文生成\n至此，网络包的报文如下图。\n出口——网卡 网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将数字信息转换为电信号，才能在网线上传输，也就是说，这才是真正的数据发送过程。\n负责执行这一操作的是网卡，要控制网卡还需要靠网卡驱动程序。\n网卡驱动获取网络包之后，会将其复制到网卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列。\n起始帧分界符是一个用来表示包起始位置的标记\n末尾的 FCS（帧校验序列）用来检查包传输过程是否有损坏\n最后网卡会将包转为电信号，通过网线发送出去。\n交换机 下面来看一下包是如何通过交换机的。交换机的设计是将网络包原样转发到目的地。交换机工作在 MAC 层，也称为二层网络设备。\n交换机的包接收操作\n……\n服务器 与 客户端 数据包抵达服务器后，服务器会先扒开数据包的 MAC 头部，查看是否和服务器自己的 MAC 地址符合，符合就将包收起来。\n接着继续扒开数据包的 IP 头，发现 IP 地址符合，根据 IP 头中协议项，知道自己上层是 TCP 协议。\n于是，扒开 TCP 的头，里面有序列号，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。TCP头部里面还有端口号， HTTP 的服务器正在监听这个端口号。\n于是，服务器自然就知道是 HTTP 进程想要这个包，于是就将包发给 HTTP 进程。\n服务器的 HTTP 进程看到，原来这个请求是要访问一个页面，于是就把这个网页封装在 HTTP 响应报文里。\nHTTP 响应报文也需要穿上 TCP、IP、MAC 头部，不过这次是源地址是服务器 IP 地址，目的地址是客户端 IP 地址。\n","date":"2024-10-31","id":35,"permalink":"/notes/cs/net/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E7%9A%84%E8%BF%87%E7%A8%8B/","summary":"浏览器做的第一步工作是解析****URL","tags":"计算机网络","title":"[计网] 键入网址的过程"},{"content":"0. SQL语法 0.1 count主键和count非主键结果会不同吗？ 分析：count()函数是返回表中某个列的非NULL值数量\n主键不能存储NULL值，所以count(主键)返回的结果，可以表示数据库中所有行数据的量 非主键可以保存NULL值，所以count(非主键)返回表中非主键列的非NULL值的数量 回答： 主键不能存NULL值，所以count主键代表统计表中所有行数据的数量 而非主键可以存储NULL值，所以count非主键返回的是表中这个列的非NULL值的数量\n一、索引面试题 1.1 MySQL有哪些索引？ 分析：索引是由存储引擎来实现的，不同存储引擎支持的索引类型也是不同的，大多数存储引擎都是支持\nB+树索引，哈希索引，全文索引的区别：\nB+树索引：InnoDB引擎默认的索引，支持排序，分组，模糊查询等，并且性能稳定 哈希索引：多用于等值查询，时间复杂度为O(1)，效率非常高，但不支持排序，范围查询以及模糊查询 全文索引：一般用于查询文本中的关键字，而不是直接比较是否相等等，主要用来解决 WHERE name LIKE \u0026ldquo;%aaaa%\u0026rdquo; dev.mysql.com\n回答：我了解到Mysql支持B+树索引，哈希索引，全文索引这三种索引类型，比较常用的是B+树索引，因为它是InnoDB引擎默认使用的索引类型，支持排序，分组，范围查询，模糊查询等\n1.2 InnoDB引擎的索引数据结构是什么？ 回答：InnoDB引擎是采用B+树作为索引的数据结构\n1.3.0 mysql为什么使用B+树？ 分析：这里要回答对平衡树、红黑树，跳表，B树等的对比\n回答：\nB+树是多叉树，平衡二叉树、红黑树是二叉树，在同等数据量下，平衡二叉树、红黑树高度更高，磁盘IO次数更多，性能更差，而且它们会频繁执行在平衡过程，来保证树形结构平衡 和B+树相比，跳表在极端情况下会退化为链表，平衡性差，而数据库查询需要一个可预期的查询时间，并且跳表需要更多的内存 和B+树相比，B树的数据结构存储在全部节点，对范围查询不友好，非叶子节点存储了数据，导致内存中难以放下全部非叶子节点，如果内存放不下非叶子节点，那么意味着查询非叶子节点的时候都需要磁盘IO 学习：10｜数据库索引：为什么MySQL用B+树而不用B树？ | JUST DO IT\n1.3 为什么索引用B+树？而不用红黑树？ 分析：InnoDB引擎的数据是存储在磁盘上的，所以选择数据结构的第一优先级是考虑从磁盘查询数据的成本，如果树的高度越高，意味着磁盘I/O就越多，这样会影响查询性能\n对于N个叶子节点的B+树，其搜索复杂度为O(logdN) ，其中d表示节点允许的最大子节点个数为d\n在实际的应用中，即使数据达到了千万级别，B+树的高度依旧维持在34层，也就是说一次数据查询操作只需要做34次的磁盘I/O操作\n而红黑树本质上是二叉树，二叉树的每个父节点的儿子节点只能是2个，意味着其搜索复杂度为O(logN) ，这已经比B+Tree高出不少，因此二叉树搜索到目标数据所经历的磁盘I/O次数要更多\n回答：主要原因是随着数据量的增多，红黑树的树高会比B+树高 ，这样查询数据的时候会面临更多的磁盘I/O，查询性能没那么好。\n因为红黑树本质是二叉树，而b+树是多叉树，存储相同数量的数据量下，红黑树的树高会比B+树的树高，由于InnoDB引擎的数据都是存储在磁盘上的，如果树的高度过高，意味着磁盘I/O就越多，会影响到查询性能，所以InnoDB引擎的索引选择了B+树\n1.4 为什么索引用B+树？而不是B树？ 分析：考察对B+树 和 B 树的理解，可以从三个角度分析\n磁盘I/O角度\n范围查询角度\n增删改查角度\n回答：我觉得主要有三个原因：\nB+树的磁盘读写代价更低：B+树只有叶子节点存储索引和数据，非叶子节点只存放索引，而B树所有节点都会存放索引和数据，因此存储相同数据量的情况下，B+树可以比B树更矮胖，查询叶子节点的磁盘I/O次数也少\nB+树便于范围查询：MySQL经常需要使用范围查询，B+树所有叶子节点间都有链表进行连接，这种设计对范围查询查询非常有帮助，B树没有将所有叶子节点用链表串联起来的结构，只能用中序遍历来完成范围查询，这会比B+树范围查询涉及多个节点的磁盘I/O操作，一次范围查询的效率不如B+树\nB+树增删改查效率更加稳定：B+树有大量冗余节点，这些冗余数据可以让B+树在插入、删除的效率都更高，比如删除根节点的时候，不会像B树那样会发生复杂的树的变化。另外，B+树把所有指向数据的指针都放在叶子节点，因此查询、插入、删除数据都需要走到最后一层，这不同于B树可能在任意一层找到数据，所以B+树更为稳定\n1.5 为什么索引用B+树？而不用哈希表？ 分析：\n哈希表的数据是散列分布的，不具有序性，无法进行范围和排序\n哈希表存在哈希冲突，哈希冲突严重，也会降低查询效率\n回答：MySQL会有会多范围和排序的场景，虽然哈希表的搜索时间复杂度是O(1)，但是由于哈希表的数据都是通过哈希函数计算后散列分布的，所以哈希表索引不支持范围和排序操作，不支持联合索引最左匹配原则，如果重复键比较多，还容易操作哈希碰撞导致效率进一步降低。而B+树可以满足这些应用\n1.6聚簇索引和非聚簇索引有什么区别？ 分析：先说聚簇索引和非聚簇索引B+树叶子节点存放内容的区别，然后再引出回表查询和覆盖索引查询\n回答：聚簇索引和非聚簇索引（二级索引）的最主要区别是B+树叶子节点存放的内容：\n聚簇索引的B+树叶子节点存放的是主键值+完整的记录\n非聚簇索引的B+树叶子节点存放的是索引值+主键值\n如果查询条件用了二级索引，但查询的数据不是主键值，也不是二级索引值，这时在二级索引找到主键后，需要回表才能查找到数据，需要扫描两次B+树。如果查询的数据是主键值，因为在二级索引就能查询到，这时就会用到覆盖索引，不需要回表，只需要扫描一个B+树\n1.7insert操作对B+树结构的改变是怎么样的？ 分析：回答说出页分裂问题，以及指出主键id要是顺序递增，如果是随机值（比如uuid），就可能会频繁出现页分裂现象，会严重影响性能\n如果使用非自增主键，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会插入到现有的数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为页分裂。页分裂还可能造成大量的内存碎片，导致所有结构不紧凑，从而影响查询效率\n回答：B+树的数据是有序的，所以：\n如果我们使用主键是顺序递增，那么每次插入新数据就会顺序插入到叶子节点最右边的节点里，如果页面满了，就会自动开辟一个新页面，将新数据插入到新页面。因为每次插入一条新记录，都是追加操作，不需要重新移动数据，因此这种插入数据的方法效率非常高\n如果使用主键不是顺序递增，由于每次插入主键的索引值都是随机的，因此每次插入新数据时，就可能插入到现有数据页中间的某个位置，这时候为了保证B+树的有序性，要移动其它数据来满足新数据的插入。如果该页面满了，就发生页分裂，这时候要从一个页面复制数据到另外一个页面，目的是保证后一个数据页的所有行主键值比前一个数据页中主键值大，页分裂可能会造成大量的内存碎片，导致所有结构不紧凑，从而影响查询效率\n所以，我们在设计主键的时候，最好采用自增的方式，或者顺序递增主键值\n1.8假如一张表有两千万的数据，B+树的高度是多少？怎么算？ 分析：假设\n非叶子节点内指向其它页的数量为x\n叶子节点内能容纳的数据行数为y\nB+树的层高为z\n表总数等于x的z-1次方与y的乘积：\n回答：具体看数据库表的字段多不多，以及字段类型，假设一行数据的大小是1kb，那么2000万的数据库，B+树的大概是三层高度\nMySQL 单表不要超过 2000W 行，靠谱吗？\n1.11 MySQL有哪些索引？ 分析：主键索引，唯一索引，普通索引，前缀索引，联合索引\n主键索引：主键索引是建立在主键字段上的索引，通常在创建表的时候一起创建，一张表最多只有一个主键，索引值不允许NULL值\n唯一索引：唯一索引建立在UNIQUE字段上的索引，一张表可以有多个唯一索引，索引列的值必须唯一，但是允许NULL值\n普通索引：普通索引是建立在普通字段上的索引，既不要求字段为主键，也不要求字段为UNIQUE\n前缀索引：前缀索引是指对字符串类型字段的前几个字符创建的索引，而不是在整个字段上建立的索引，前缀索引可以建在字段类型为char、varchar、binary、varbinary的列上，使用前缀索引的目的是为了减少索引占用的存储空间，提高查询效率\n联合索引：通过多个字段组合成一个索引，该索引被称为联合索引\n回答：MySQL有主键索引、唯一索引、前缀索引、普通索引和联合索引，InnoDB引擎要求每一张数据库表都必须有一个主键索引，比如表里的Id字段就是主键索引\n然后针对查询比较频繁的字段，我们可以对这个字段建立普通索引，如果是多个字段，可以考虑建立联合索引，利用索引覆盖的特性提高查询效率\n对长文本、字符串的字段，可以对这些字段的前缀部分建立索引，也就是建立前缀索引，可以减少索引的存储空间\n1.12 普通索引和唯一索引有什么区别？哪个更新性能更好？ 分析：从InnoDB的change buffer的角度分析\n回答：普通索引列的值是可以重复的，而唯一索引列的值是必须唯一的，当我们对唯一索引插入一条重复的值，会因为唯一性约束而报错\n我认为普通索引的更新性能更好，因为普通索引在更新的时候，如果更新的数据也不在内存的话，可以直接把更新操作缓存在change buffer中，更新就结束了；但是，唯一索引因为需要唯一性约束，如果更新的数据页不再内存的话，需要从磁盘读取对应的数据页到内存，判断有没有冲突，这涉及到磁盘随机IO的访问\n普通索引因为能使用change buffer特性，普通索引的更新比唯一索引，减少了随机磁盘访问，更新性能更好\n1.13 主键怎么设置？假如你不会设置会怎样？ 分析：在创建表的时候，指定某一列为主键（PRIMARY KEY）\nCREATE TABLE table_name ( ID INT PRIMARY KEY, ... ); InnoDB在创建聚簇索引的时候，会根据不同的场景选择不同的列作为索引：\n如果有主键，默认使用主键作为聚簇索引的索引值\n如果没有主键，就选择第一个唯一索引且不为NULL值的列作为聚簇索引的值\n在上面都没有的情况下，InnoDB将自动生成一个隐式自增id列作为聚簇索引的索引值\n回答：\n在创建表的时候，将id值设置为primary key，那么id列就是主键索引\n如果没有主键，那就选择第一个不包含NULL值的唯一索引作为聚簇索引的索引键，如果这个条件页没有，那么InnoDB将自动生成以一个隐式rowid列作为聚簇索引的索引键\n1.14 为什么要建立索引？ 分析：三个优点：\n索引大大减少了MySQL需要扫描的数据量\n索引可以帮助MySQL避免外部排序和使用临时表\n索引可以将随机I/O变成顺序I/O\n回答：如果没有建立索引，查询数据的话时间复杂度是O(n)，这样查询效率还是比较低，为了提高查询效率，可以建立索引\n建立索引后，数据都会按照顺序存储，这时候我们可以按照类似二分查找的方式快速查找数据，B+树索引是多叉树，搜索时间复杂度是O(logdN)，提高了查询效率，除此之外，可以避免外部排序和使用临时表问题，以及将随机I/O变成顺序I/O\n1.15 我们一般选择什么样的字段来建立索引？ 分析：\n适用索引的场景：\n字段具有唯一限制\n经常用于where 查询条件的字段，这样可以提高整个表的查询速度，有多条件还可以创建联合索引\n经常用于group by 和order by 的字段，这样查询的适合就不用再去做一次排序了，因为建立了索引之后在B+树中的记录都是排好序的\n不适合索引的场景：\nwhere 条件，group by 和order by 里用不到的字段，索引的价值是快速定位，起不到定位作用的字段通常不需要创建索引，因为索引是会占用空间\n字段中存在大量重复数据，不需要参加索引，例如性别字段\n经常更新的字段不用创建索引，比如不要对余额字段创建索引，因为要维护B+树的有序性，那么就需要频繁的重建索引，这个过程会影响数据库的性能\n回答：对于频繁用于where 查询条件的字段建立索引，可以提高整张表的查询速度，如果查询条件不是一个字段，可以考虑建立联合索引，还有对于经常用于排序、分组的字段建立索引\n对于一些区分度不高的字段，比如性别不建议建立索引，如果数据库中，数据的记录分布均匀，那么无论搜索的值是哪个都可能得到一半的数据，在这种情况下，MySQL的优化器发现某个值在表中出现的比例很高，它一般会忽略索引，进行全表扫描，这时候建立索引没有起到作用，而且所有还占用了存储空间\n1.16 索引越多越好吗？ 分析：考虑索引的缺点，索引的最大好处是提高查询效率，索引也有缺点\n空间代价：需要占用物理空间，数量越大，占用空间越大；\n时间代价：会降低表的增删改查的效率，每次删改索引，B+树为了维护索引有序性，都需要进行动态维护\n创建索引和维护索引要消耗时间，这种时间随着数据量的增大而增大\n回答：不是的。索引虽然能提高查询效率，但是多建立一个索引，就意味着新生成一个B+树索引，需要占据存储空间，特别是在表数据非常大的时候，索引占用的空间越大\n还有，索引越多数据库的写入性能会下降，因为每次对表进行增删改查的时候，都需要去维护各个B+树索引的有序性\n1.17 什么时候不用索引更好？ 回答：建立了索引，虽然可以提高查询效率，但是带来了两个代价，一个是空间代价，创建索引需要多构建一个b+树，会占用磁盘空间。第二个是时间代价，每次增删改查，都需要动态维护b+树，以满足b+树的有序性\n所以，在一张表经常增删改查的话，即读多写少的场景下，不建立索引会比较好，因为这时候维护的开销可能超过索引带来的性能提升\n还有一点，如果表中某个列的值高度重复，那么建立了索引页没有用，优化器会选择全表扫描，这样建立的索引会占用存储空间，也会影响增删改查的效率，选择不用索引更好\n1.18 索引怎么优化？ 回答：-\n对于只需要查询几个字段数据的sql来说，我们可以对这些字段建立联合索引，这样查询方式就变成了覆盖索引，避免回表，减少了大量的I/O操作\n主键值最好是递增的值，因为我们索引是按照顺序存储数据的，如果主键的值是随机的值，可能会引起页分裂的现象，页分裂会导致大量的内存碎片，这样索引结构不紧凑了，会影响查询效率\n避免出现索引失效的sql语句，比如不要对索引进行计算、函数、类型转发操作，联合索引要正确使用需要遵循最左匹配原则\n对于一些大字符串的索引，考虑用前缀索引只对索引列的前缀部分建立索引，节省索引的存储空间，提高查询效率\n1.19 建立了索引，查询的时候一定会用到索引吗？ 分析：两个方向：\n索引失效的场景\n优化器是基于成本考虑，即使查询条件用了索引，如果走索引的查询成本太高，也不会走索引\n回答：\n不是的\n了解到即使查询使用到了索引，也可能不走索引，比如\n当查询语句对索引字段进行左模糊匹配，表达式计算，函数，隐式类型转发操作，这时候查询语句就无法走索引了，查询方式变成了全表扫描，还有我们使用联合索引查询的时候，如果没有遵循最左匹配原则，也是会发生索引失效\n优化器是基于成本考虑来选择查询的方式，在使用二级索引进行查询的时候，优化器会计算回表的成本和全表扫描的成本，如果回表的代价太高，优化器会选择不走索引，而是走全表扫描\n11 索引出错:请理解 CBO 的工作原理\n1.20 定义了一个varchar类型的日期字段，并且有一个数据是'20230922\u0026rsquo;, 如果这个日期字段上有索引，那如果我查询的where条件是where time = 20230922不加单引号，还会命中索引吗？为什么？ 回答：不会命中索引，因为mysql在遇到字符串和数字时，会发生隐式类型转换，会将字符串转化为数字，这个转换的过程会涉及到函数，这个查询，日期字段是字符串，会发生隐式类型转换的时候，就会作用在日期这个索引字段上，对索引进行函数计算，发生索引失效\n1.21 MySQL最新版本解决了索引失效的哪些情况了吗？ 回答：mysql 8.0可以给字段增加函数索引，可以解决对索引使用函数的时候，索引失效的问题\n还有一个索引跳跃式扫描，即使没有遵循最左匹配原则，依然可以使用联合索引\n1.22 什么是最左匹配原则？ 回答：假设一个(a, b, c) 联合索引，它的存储顺序是先按照a排序，在a相同的情况下排b，在b相同的情况下排c，由于这个特性，在使用联合索引时，存在最左匹配原则，具体的规则是：\nmysql会从联合索引从最左的索引列开始匹配条件，然后依次从左到右顺序匹配，如果查询条件没有用到某个列，那么该列右边的索引列都无法使用走索引\n当查询条件中使用某个列，但是该列的值包含范围查询，范围查询的字段可以用到联合索引，但是范围查询字段后面的字段无法用到联合索引\nhttps://xiaolincoding.com/mysql/index/index_interview.html\n二、事务面试题 2.1 MySQL事务有什么特性？ 分析：考察事务的ACID特性\n原子性：一个事务中的所有操作，要么全部完成，要么全部不完成\n一致性：是指事务操作前后，数据满足完整性约束，数据库保持一致性状态\n隔离性：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以使得多个事务并发执行时不会相互干扰\n持久性：事务处理结束后，对数据的修改就是永久的，即便系统故障不会丢失\n回答：MySQL事务由ACID四大特性，分别是原子性、一致性、隔离性、持久性\n原子性就是事务中所有操作要么全部完成，要么全部不完成，不会结束在中间某个环节，原子性是由undo log日志保证的；\n一致性意思是事务执行前后，数据库的状态必须保持一致性，一致性是通过持久性+原子性+隔离性这三个共同保证；\n隔离性的意思是允许多个事务并发读写数据库，可以防止多个事务并发读写同一个数据库，导致数据不一致问题发生，隔离性是由mvcc和锁保证；\n持久性的意思是保证事务完成后对数据的修改是永久的，不会因为系统故障而丢失，持久性是由redo log日志来保证的；\n2.2 事务的隔离性如何保证？ 分析：先说由MVCC和锁实现，再说为什么用MVCC和锁能实现隔离性\n回答：事务的隔离性是由MVCC和锁来实现的\n可重复读隔离级别下的快照读（普通select），是通过MVCC来保证事务隔离性的，\n当前读（update、select \u0026hellip; for update）是通过行级锁来保证事务隔离性的\n2.3 事务的持久性如何保证？ 分析：先说由redo log实现的，再说为什么用redo log能实现持久性\n回答：事务的持久性是由redo log保证的，因为MySQL通过WAL（先写日志再写数据）机制，在修改数据时，会将本次对数据页的修改以redo log的形式记录下来，这时候更新操作就完成了，Buffer pool的脏页会通过后台线程刷盘，即使在脏页还没有刷盘的时候发生了数据库重启，由于修改操作记录到redo log，之前提交的记录都不会丢失，重启后在通过redo log，恢复脏页数据，从而保证事务的持久性\n2.4 事务的原子性如何保证？ 分析：先说由undo log实现的，再说为什么用undo log能实现原子性\n回答：事务的原子性是通过undo log实现的，在事务还没提交前，历史数据记录在undo log中，如果事务在执行过程中，出现了错误或者用户执行了ROLLBACK语句，MySQL可以利用undo log中的历史数据，将数据恢复到事务开始之前的状态，从而保证了事务的原子性\n2.5 MySQL事务和Redis事务有什么区别？ 分析：Redis事务没有保证原子性和持久性\n原子性：Redis事务没有回滚功能，没办法实现跟Mysql一样的原子性，如果在Redsi事务执行过程中，中间有命令出错，不会停止执行和回滚，这时候事务的执行会出现半成功的状态\n持久性：\nRDB模式：在一个事务执行后，而下一次的RDB快照还未执行前，如果发生了宕机，这种情况下，事务修改的数据也是不能保证持久的\nAOF模式：其三种选项no、everysec和always都会存在数据丢失，所以事务的持久性属性也还是得不到保证。\n回答：MySQL事务能够实现ACID四大特性，而Redis事务没保证原子性和持久性\nRedis事务没有回滚功能，没办法实现跟MySQL事务一样的原子性，就没办法保证事务执行期间，要不全部成功，要不全部成功，Redis事务执行过程中，如果中途有命令执行出错，不会停止和回滚，而是继续执行，那么就可能出现半成功的状态。\nRedis不管是AOF模式，还是RDB快照，都没办法保证数据不丢失，所以Redis事务不具有持久性\n2.6 MySQL事务隔离级别有哪些？分别解决哪些问题？ 分析：MySQL共有四个隔离级别如下：\n读未提交：指一个事务还没提交时，它做的变更就能被其他事务看到\n读提交：指一个事务提交之后，它做的变更才能被其他事务看到\n可重复读：指一个事务执行过程中看到的数据，一直跟着这个事务启动时看到的数据是一致的，MySQL InnoDB引擎的默认隔离级别\n串行化：会对记录加上锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行\n回答：MySQL默认隔离级别是可重复读。除此之外，MySQL的事务隔离级别有读未提交，读提交，可重复读，串行化\n事务并发问题存在脏读、不可重复读、幻读这三种，\n读未提交没有解决什么问题\n读提交解决了脏读，但是还存在不可重复读和幻读这两个问题\n可重复读解决了脏读，不可重复读的问题，不过对幻读问题上是很大程度避免了，没有完全避免\n串行化解决了脏读，不可重复读，幻读，但是事务的并发性是最差的\n2.7 脏读和幻读有什么区别？ 分析：考察脏读和幻读的基础\n回答：\n脏读是一个事务读取到了另一个未提交事务修改过的数据，如果另一个事务回滚了，刚才读到的数据就与数据库的数据不一致了\n幻读，是前后两次查询的结果集的数量是不同的，比如select执行了两次，但是第二次返回了第一次没有返回的行数据\n2.8 MySQL默认的隔离级别是什么？怎么实现？ 分析：考察可重复读的实现实现原理（MVCC和锁）\n回答：MySQL默认的隔离级别是可重复读\nselect查询是通过MVCC实现的，在MVCC实现中，每条记录都会保持多个版本，每个版本都有一个版本号，事务在读取数据时，会根据事务开始时的版本号来读取数据，从而保证了事务的隔离性。可重复读隔离级别是在开启事务后，执行一条select语句的时候，会生成一个Read View，后续事务查询数据的时候会复用Read View，所以保证了事务期间多次读取到的数据都是一致的。\n可重复读有间隙锁，针对当前读，会加间隙锁和记录锁，可以防止其他事务插入新记录，也可以防止删除和更新记录\n2.9 介绍以下MVCC？ 分析：从MVCC是什么？解决了什么问题？实现原理？三方面回答\n回答：MVCC是多版本并发控制，是通过记录历史版本数据，解决读写并发冲突问题，避免了读数据时加锁，提高了事务的并发性能\nMySQL将历史数据存储在undo log中，结构逻辑上类似链表，MySQL数据行上有两个隐藏列，一个是事务ID，另一个是指向undo log的指针\n事务开启后，执行第一个select语句的时候，会创建Read View，Read View记录了当前未提交的事务列表，通过与历史数据的事务ID比较，就可以根据可见性进行判断，判断这条记录是否可见，如果可见就直接将这个数据返回给客户端，如果不可见就继续往undo log版本链查找第一个可见的版本数据\n（扩展，讲可见性规则——\u0026gt; 2.10 MVCC如何判断行记录对某个事务是否可见？）\n2.10 MVCC如何判断行记录对某个事务是否可见？ 分析：Read View有四个重要的字段\nm_ids:指的是在创建Read View时，数据库中活跃事务的事务id列表，注意是一个列表\nmin_trx_id:指的是在创建Read View的时候，当前数据库中活跃的事务中id最小的事务\nmax_trx_id:知道是创建Read View时当前数据库中应该给下一个事务的id值，也就是当前全局事务中最大的事务id值+1；\ncreator_trx_id:指的是创建该Read View的事务的事务id\n记录中的两个隐藏列\ntrx_id:当前事务对记录进行改动后，会将该事务的id记录在trx_id\nroll_pointer:是一个指针，指向每一个旧版本记录（undo log）\n回答：每一条记录都有两个隐藏列，一个是事务id，另一个是指向历史数据undo log的指针，然后Read View有四个字段，分别是创建Read View的事务id，活跃事务id列表，活跃事务id列表中最小的id，下一个事务id\n当记录的事务id小于活跃事务id列表中最小的id，说明该记录是在创建Read View前提交好了，所以该记录是当前事务可见的\n当记录的事务id大于下一个事务的id，就说明该记录是在创建Read View后才生成的，所以该记录是当前事务是不可见的\n如果记录的事务id在最小的id和下一个事务id之间，这时候就需要判断记录的事务id是否在活跃的事务id列表中：\n如果该记录的事务id在活跃事务id列表中，说明该记录的事务还没提交，所以记录是不可见的\n不在活跃事务id列表中，说明该记录的事务已经提交，那么该记录是可见的\n2.11 读已提交和可重复读隔离级别实现 MVCC的区别？ 分析：生成readView的时机不同\n回答：读已提交和可重复读隔离级别都是由MVCC实现的，它们的区别在于创建Read View的时机不同\n读已提交隔离级别在事务开启后，每次执行select都会生成一个新的Read View，所以每次select都能看到其他事务最近提交的数据\n可重复读隔离级别在事务开启后，执行第一条select是生成一个Read View，然后整个事务期间都在复用这个Read View，所以一个事务执行过程中看到的数据，一直跟事务启动的时候看到的数据是一致的\n2.12 为什么互联网公司用读已提交隔离级别？ 分析：读已提交并发性能更高，因为读已提交没有间隙锁，只有记录锁，而可重复读是会有记录锁和间隙锁，所以读已提交隔离级别发生死锁的概率比较小\n回答：读已提交的并发性能更好，因为读已提交没有间隙锁，只有记录锁，发生死锁的概率比较低，然后互联网业务对于幻读和不可重复读的问题都能接受，所以为了降低死锁的概率，提高事务的并发性能，都会选择使用读已提交隔离级别\n2.13 可重复读级别是如何解决不可重复读的？ 分析：分两种查询来回答\n快照读，靠MVCC解决不可重复读\n当前读，靠行级锁中的记录锁解决不可重复读\n回答：MySQL提供了两种查询方式，一种是快照读，就是普通select语句，另外一种是当前读，比如 select for update语句。不同的查询方式，解决不可重复读问题方式不一样\n针对快照读：是通过MVCC实现的，在可重复读的隔离级别下，第一次select查询的时候，生成Read View，在第二次执行select的时候，会复用这个ReadView，这样前后两次查询的记录是一样的，不会读到其他事务更新的操作\n针对当前读：是靠行级锁中的记录锁来实现的，在可重复读隔离级别下，第一次select for update语句查询的时候，会对记录加next-key锁，这个锁包含记录锁，这个时候如果其他事务更新了加了锁的记录，都会被阻塞，这样就不会发生不可重复读\n2.14 可重复读隔离级别是如何解决幻读的？ 分析：分两种查询来回答\n快照读，靠MVCC解决幻读\n当前读，靠行级锁中的间隙锁解决幻读\n回答：MySQL提供了两种查询方式，一种是快照读，就是普通select语句，另外一种是当前读，比如select for update语句。不同的查询方式，解决不可重复读问题的方式不同\n快照读，是通过MVCC来解决的，在可重复读的隔离级别下，第一次执行select语句，会生成ReadView，在第二次执行select的时候，复用该ReadView，这样前后两次查询的结果集都是一样的，不会读到其他事务新插入的记录，这样就不会发生幻读\n当前读，看靠行级锁中的间隙锁来实现的，在可重复读隔离级别下，第一次select for update语句查询的时候，会对记录加next-key锁，这个锁包含间隙锁，这个时候如果其他事务往这个间隙插入新记录的化，都会被阻塞，这样就不会发生幻读\n2.15 可重复读隔离级别解决了什么问题？有没有完全解决幻读？ 分析；强调可重复读隔离级别是很大程度上解决了幻读，但是没有完全解决\n回答：可重复读解决了脏读，不可重复读问题，幻读在很大程度上避免了，但是并没有完全解决幻读，在一些特殊的场景，还是会发生幻读的问题。\n2.16 可重复读为什么不能完全避免幻读？什么情况下出现幻读？ 分析：可重复读隔离级别场景下：\n发生幻读的场景一：事务A中存在一条更新一条不存在的记录的语句，事务B在事务A更新之前insert这条不存在的记录并提交事务，事务A执行更新，能够正常执行且查询到这个记录\n发生幻读的场景二：范围查询\n回答：在可重复读隔离级别下，当先快照读后当前读的场景下可能会出现幻读的问题。\n比如这个场景，事务A通过快照读的方式查询了id=5的记录，此时数据库没有该记录，然后事务B向这张表新插入一条id=5的记录并提交了事务。接着，事务A对id=5的记录进行了更新操作，这个时刻，这条新纪录隐藏列中的事务id就变成了事务A的id，这时候事务A再使用select语句去查询这条记录时候就可以看到这条记录了，这里事务A前后两次查询的结果集合数不一样，于是就发生了幻读\n以上发生幻读的场景是可以避免的，就是尽量再开启事务后，马上执行select \u0026hellip; for update语句\n2.17 可重复读隔离级别，MVCC完全解决了不可重复读的问题吗？ 分析：不可重复读，代表前后两次查询的记录的值不一样\n比如表里面有 id = 1, value =1 的记录\n事务a, 先执行select，查询到 id =1的value = 1\n事务b，更新id =1的value =2 ，然后提交事务\n事务a，执行select for update，当前读，然后就读到 id= 1，value的记录，意味着发生了不可重复读\n回答：如果前后两次查询都是普通select，就不会产生不可重复读的问题。但是如果第一次查询是快照读，第二次查询是当前读，那么就可能会发生不可重复读\n三、锁面试题 3.1 细说一下MySQL数据库中锁的分类 分析：全局锁，表级锁，行级锁，强调InnoDB引擎实现了行级锁\n回答：根据颗粒度的不同，MySQL的锁可以分为全局锁，表级锁，行级锁。\n比较了解的是表级锁和行级锁，比如对一张表结构进行修改的时候，MySQL会对该表加一个元数据锁，元数据锁是属于表级锁\n行级锁目前只有InnoDB存储引擎实现了，MyISAM存储引擎是不支持行级锁，只有表锁。\nInnoDB存储引擎实现的是行级锁主要有记录锁，间隙锁，临键锁，插入意向锁这些\n3.2 在线上修改表结构，会发生什么？ 分析：表级锁\n回答：线上环境可能存在很多事务在读取这个表，如果这张表进行表结构的修改，会发生阻塞，原因是有事务对这张表进行读写操作，会发生元数据锁，而修改表结构的时候，会生成元数据写锁，这时候就发生了读写冲突，所以修改表结构的操作就会发生阻塞，并且后续事务的增删改查操作都会阻塞\n3.3 InnoDB存储引擎中的行级锁有哪些？ 分析：记录锁、间隙锁、临键锁、插入意向锁\n回答：InnoDB实现的行级锁有记录锁、间隙锁、临键锁和插入意向锁，在我们增删改或者锁定读语句的时候，都会对记录加行级锁\n3.4 一条Update语句没有带Where条件，加的是什么锁？ 分析：InnoDB加锁是索引加锁，可重复读级别下，加锁的基本单位是next-key锁，读已提交隔离级别下，加锁的级别单位是记录锁\n更新没有带where条件，会全表扫描，会对每天记录都加锁\n回答：\n可重复读的情况下：更新没有带where条件，会按照全表扫描，对每一条记录都加next-key锁，相当于锁住了全表\n读已提交隔离级别下，没有间隙锁，更新没有带where条件，是全表扫描，那么会对每条记录都加记录锁\n3.5 带了Where条件没有命中索引，加的是什么锁？ 同上\n3.6 两条更新语句更新同一条记录，加的是什么锁？ 分析：在可重复读的情况下，加锁的基本单位是next-key锁，但是在一些场景下会退化为记录锁或者间隙锁\n3.7 两条更新语句更新同一个跳记录的不同字段，加的是什么锁？ 分析：InnoDB加锁是加在行记录索引，不是针对更新字段的加锁\n3.8 MySQL怎么实现乐观锁？ 分析：可以基于版本号实现乐观锁，修改数据的时候带上版本号（时间戳）\nupdate student set name = \u0026#39;xiaochen\u0026#39;, version = 2 where id = 100 and version = 1 回答：可以在数据库表增加一个版本号字段，利用这个版本号字段实现乐观锁\n具体的实现，每次更新数据的时候，带上版本号，同时将版本+1，如果版本号和表记录中的版本号一致的话，就能更新成功，不相等就更新失败，然后重新获取该记录的最新版本号，然后再尝试更新数据\n3.9 了解过MySQL怎么排查死锁问题？ 回答：在并发事务中，当两个事务出现循环资源依赖，这两个事务都在等待别的事务释放资源，就会导致这两个事务进入无限等待的状态，这时就发生了死锁\n3.10 MySQL 怎么避免死锁？ 回答：\n在遇到线上死锁的问题，应该第一时间获取相关的死锁日志。使用show engine innodb status 命令获取死锁信息\n然后就分析死锁日志，\n通过阅读死锁日志，可以清楚知道两个事务形成了怎么样的循环等待，然后根据当前各个事务执行的sql分析出加锁类型以及顺序，逆向推断出如何形成循环等待\n解决死锁之路(终结篇) - 再见死锁 - aneasystone\u0026rsquo;s blog\nMySQL 5.7 排查死锁\nMySQL 死锁了，怎么办？\n四、日志面试题 4.1 redo log和 binlog 的区别和应用场景 分析：redo log和 binlog 有四个区别的地方\n适用的对象不同\nbinlog是MySQL的Server层实现的日志，所有的引擎都可以使用\nRedo log是InnoDB存储引擎实现的日志\n文件格式不同\nbinlog有3种格式类型，分别是STATEMENT、ROW、MIXED\nSTATEMENT：每一条修改过的SQL都会记录到binlog中， redo log是物理日志，记录的是在某个数据页做了什么修改，\n写入方式不同\nbinlog是追加写，写满一个文件，就创建一个文件继续写，不会覆盖以前的日志，保存的是全量的日志\nRedo log是循环写，日志空间大小是固定的，全部写满就从头开始，保存未被刷入磁盘的脏页日志\n用途不同：\nbinlog用于备份恢复，主从复制\nRedo log用于掉电等故障\n回答：\nredo log是InnoDB引擎实现的日志，属于物理日志，记录了InnoDB存储引擎对数据页所做的修改操作，主要用于崩溃恢复，例如某个事物提交了，脏页数据还可能没进行刷盘，如果mysql机器断电了，脏页的数据就丢失了，mysql重启后可以通过redo log将已提交事物的数据恢复过来\nbinlog是Server层实现的日志，保存了所有对数据库的增删改操作，binlog有三种日志格式，日志的内存可能是sql语句，数据本身或者两者混合，主要用于数据库的备份和归档，也用于主从复制\n4.2 redo log和binlog在恢复数据库有什么区别？ 分析：应用区别\n回答：\nbinlog是追加日志，写满一个日志，就创建一个文件继续写，不会覆盖以前的日志，保存了所有对数据库的更新操作，可以用来恢复某个时刻的数据或者全量恢复数据库数据\nRedo log是循环写，日志空间大小是固定的，全部写满就从头开始，保存的是InnoDB存储引擎对数据页所做的修改操作，用来恢复因中途MySQL断电丢失的脏页数据\n4.3 redo log是怎么实现持久化？ 回答：事务执行过程更新的数据，并不是在事务提交的时候，就把修改的数据刷入磁盘，而是修改buffer pool中数据页，并标记为脏页，然后在后台找到合适的时机进行刷盘\n如果事务提交了，脏页数据没有刷盘的时候，数据库发生宕机，就会导致事务修改的数据丢失\n所以MySQL引入了redo log，redo log保存的是物理日志，主要是记录InnoDB对某个数据页的修改操作，当事务提交的时候，redo log就先刷入磁盘，因为redo log保存了数据页的修改操作，即使脏数据没有刷盘时数据库发生了宕机，重启后MySQL通过重放redo log，就能恢复未刷盘的脏页，保证了数据的持久性\n4.4 redo log除了崩溃恢复还有什么其它作用 分析：\n回答：\n写redolog的方式是追加的形式，所以redolog写磁盘是一个顺序写的过程，而数据页是一个随机写的过程，顺序写的性能比随机写的性能高，事务在提交的时候，是先写日志在写数据的机制（WAL），相当于把mysql写入磁盘的操作从磁盘随机写变成了顺序写，所以redolog还可以提高MySQL写入磁盘的性能\n4.5 为什么需要两阶段提交 回答：\n两阶段提交是为了保证redolog和binlog逻辑一致，从而保证主从复制的时候不会出现数据不一致的问题。\n4.6 两阶段提交的过程？ 分析：\n回答：\n两个阶段，prepare阶段和commit阶段\nMySQL 日志：undo log、redo log、binlog 有什么用？\n六、存储引擎 6.1 执行一条查询sql的全过程 回答：Mysql执行一条查询语句的时候，会经过连接器、查询缓存、解析器、优化器、执行器和存储引擎这些模块\n首先，mysql的连接器会负责建立连接、校验用户权限，接收客户端的sql语句\n第二步，mysql会在查询缓存中查找数据，如果命中直接返回数据给客户端，否则就继续往下查询，不过这个查询缓存在mysql8.0版本就删除了，原因是只要对这张表进行了写操作，这张表的查询缓存就会失效，所以在实际场景中，查询缓存的命中率不高\n第三步、mysql的解析器会对sql语句进行词法分析和语法分析，构建语法树，方便后续模块读取表名，字段，语句类型\n第四步，mysql的优化器会基于查询成本的考虑，判断每个索引的执行成本，从中选择查询成本最小的执行计划\n第五步，mysql的执行器会根据执行计划来执行查询语句，从存储引擎读取记录，返回客户端\n6.2 mysql存储引擎有哪些？ 分析：mysql整体上分server层和存储引擎层\nServer层负责的部分是连接器、查询缓存、解析器、优化器、执行器\n存储引擎负责数据的读取和存储，存储引擎有InnoDB、MyISAM、Memory等\n回答：mysql常见的存储引擎有InnoDB、MyISAM、Memory\n比较熟悉的是InnoDB，它是MySQL默认的存储引擎，支持事物和行级锁，具有事物提交、回滚和崩溃恢复功能\nMyISAM不支持事物和行级锁，而且由于只支持表锁，锁的颗粒度大，更新性能比较差，比较适合读多写少的场景\nMemory了解较少，它是将数据存储在内存中，所以数据的读写比较快，但是数据不具备持久性，比较适用于临时存储数据的场景\n6.3 MyISAM和InnoDB存储引擎有什么区别 分析：从数据存储、B+树结构、锁粒度、事务四个角度分析\n数据存储：InnoDB引擎数据存储的方式采用的是索引组织表，在索引组织表中，数据即所有，索引即数据，因此表数据和索引数据都存储在同一个文件。MyISAM引擎数据存储的方式是采用堆表，在堆表的组织结构中，索引和数据是分开存储，因此表数据和索引数据分别放在两个不同的文件中存储\nB+树结构：InnoDB引擎B+树叶子节点存储索引+数据；MyISAM引擎B+树叶子节点存储索引+数据地址\n锁粒度：InnoDB引擎支持行级锁；而MyISAM不支持行级锁，仅支持表锁\n事务：InnoDB支持事务；MyISAM不支持事务\n回答：InnoDB引擎和MyISAM引擎在数据存储上不同，InnoDB引擎将表数据和索引数据存放在同一个文件，而MyISAM引擎将表数据和索引数据分开存储；所以，InnoDB引擎和B+树索引中的叶子节点存储的是索引和数据，MyISAM引擎B+树结构中的叶子节点存储的是索引和数据地。还有就是InnoDB引擎支持行级锁，MyISAM不支持行级锁，仅支持表锁\n6.4 用count(*)哪个存储引擎会更快？ 分析：InnoDB引擎执行count函数的时候，通过遍历的方式来统计记录个数，而MyISAM引擎执行count函数只需要O(1)复杂度，因为每张MyISAM的数据表都有一个meta信息存储了row_count值，由表级锁保证一致性，所以直接读取row_count的值就行\n而InnoDB存储引擎是支持事务的，同一时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB应该返回多少数据不确定，无法维护一个row_count变量\n回答：如果查询语句里面没有where查询条件，MyISAM引擎会比较快，因为MyISAM引擎的每张表会用一个变量存储表的总记录个数，执行count函数，直接返回这个变量就行。而InnoDB引擎执行count函数，需要遍历的方式来统计记录个数\n如果查询语句与where查询条件，MyISAM和InnoDB引擎执行count函数的时候，性能差不多\n6.5 NULL值是如何存储的？ 分析：MySQL 一行记录是怎么存储的？\n回答：MySQL行格式中会用NULL值列表来标记值为NULL的列，每个列对应一个二进制位，如果列的值为NULL，就会标记二进制位为1，否则为0，所以NULL值并不会存储在行格式中的真实数据部分\nNULL值表最少会占用1字节空间，当表中所有列都定义为NOT NULL，行格式中就不会有NULL值列表，这样可以省1字节空间\n6.6 char和varchar有什么区别？ 分析：MySQL中char与varchar的区别：存储机制、性能差异\n回答：\nChar 是固定长度的字符串类型，它在数据库中占用固定存储空间，无论实际存储的数据长度是多少，如果实际存储的字符串长度小于定义的长度，系统会自动使用空格填充。\nVarchar 是可变长度的字符串类型，实际存储时只占用实际字符串长度的空间，不会进行空格填充。\n设计数据库表的时候，大多数的时候是使用varchar可变长度的字符串类型，因为char会填充空格导致浪费存储空间，导致性能下降。因为char会多存储一些空格，意味着需要从磁盘多读写数据，会消耗更多的内存，还有查找数据时需要删除空格可能消耗一些cpu性能\n6.7 假如说一个字段是varchar(10)，但它其实只有6个字节，那么他在内存中的存储空间是多少？在文件中的存储空间是多少？ 分析：MySQL中varchar(10)和varchar(100)的优缺点 - 海布里Simple - 博客园\nvarchar是可变长字符串，保存到文件的时候，只会存储实际使用的字符串大小，但是内存会按照varchar最大值来固定分配大小\n回答：内存会占用10字节，文件存储空间会占用6字节，并且会额外使用1-2字节存储[可变长字符串长度]的空间\n6.8 如果硬件内存特别大，mysql缓存能否替代redis？ 分析：这里的mysql缓存代表用于缓存数据页的buffer pool，所以这个问题是，如果这个buffer pool无限大，能在内存装下所有数据，是否可以替代redis，从redis的优点跟mysql没有的点思考\n回答：不能替代\nmysql的所有模块，比如buffer pool、日志技术、事务并发模块都是面向磁盘页设计的，因此首要目标不是减少内存访问的代价，而是I/O访问的代价，所以内存访问代价并不是最优的选择，而redis是面向内存设计的数据库\nmysql在内存查询一个数据页的时候，都需要先查询页表，也就是走b+树的搜索过程，时间复杂度是O(logdN),而redis提供了多种的数据类型，比如Hash数据对象的时候，可以在O(1)时间复杂度查到数据\nmysql在更新数据的时候，mysql为了保证事务的隔离性，需要加锁，而redis更新操作都是不需要加锁的，还有Mysql为了保证事务的持久性，还需要刷盘redolog日志和binlog日志，Redis可以选择不持久化数据\n因此，即使buffer pool无限大，Mysql缓存的性能还是没有redis好\n既然有了innodb buffer pool为什么要有redis? - 知乎\nmysql基础篇\nhttps://mp.weixin.qq.com/s?__biz=Mzg5ODU2ODczMQ==\u0026mid=2247486128\u0026idx=1\u0026sn=afbd3ca37f4727db9d32460f98e73d5a\u0026chksm=c061cdc4f71644d228cad54d6a8395e27a46a9540f219a4f3776e5aa023608d131f9ec70b687#rd\nmysql原理篇\nhttps://mp.weixin.qq.com/s?__biz=Mzg5ODU2ODczMQ==\u0026mid=2247487888\u0026idx=1\u0026sn=973635eeaf7d1916e62bbceda72d27bd\u0026chksm=c061d6e4f7165ff271ee4bfc71de630c6538802b1d49c747bc0eb0be9264ae7619ed0648c47c#rd\nmysql性能篇\nhttps://mp.weixin.qq.com/s?__biz=Mzg5ODU2ODczMQ==\u0026mid=2247494731\u0026idx=1\u0026sn=e1bb64dd33c008cf46d5995044589228\u0026chksm=c0622b3ff715a229ef1831b468eb47b07aabd1edfb87637bf5c45408418dd37e3cf4ee9eca2e\u0026scene=178\u0026cur_album_id=2225658380164055048#rd\nMysql基础篇 1.Mysql是什么？ 回答：Mysql是一种传统的RDBM数据库，也就是关系型数据库，广泛应用于OLTP场景\n2.OLTP和OLAP的区别？ 回答：\nOLTP（联机事务处理）：是传统的关系型数据库的主要应用，用于基本的、日常的事务处理，例如银行的交易记录\nOLAP（联机分析处理）：是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供了直观易懂的查询结果。最常见的应用是复杂的动态报表系统\n总体来说：OLTP用于日常处理，OLAP用于数据分析\n3.数据库的三范式分别是什么？ 回答：\n第一范式：字段不可分。强调的是列的原子性，即数据库表的每一列都是不可分割的原子数据项\n第二范式：有主键，非主键字段依赖主键。\n第三范式：非主键字段不能互相依赖，任何非主键属性不依赖于其它非主属性\n4.DML是什么？ 回答：DML是数据操作语言，用于检索或者修改数据，平时最常使用的增删改查就是DML\n5.DDL是什么？ 回答：DDL是数据定义语言，用于操作数据结构，比如创建表，删除表，更改索引等都是DDL\n6.DCL是什么？ 回答：DCL是数据控制语言，用于定义数据库用户的权限，比如创建用户，授权用户，删除用户等都是DCL\n7.varchar与char的区别是什么？ 回答：char是一种固定长度的类型，varchar则是一种可变长度的类型。比如char(128)和varchar(128)，前者无论字符串长短，在磁盘上，都会占据固定的128字符大小，后者是可变长度，不过它的长度不超过128\n8.既然varchar是变长，那是不是设置varchar(1000)一定比varchar(100)好？ 回答：不是，虽然varchar是变长，在相同长度下，磁盘占用空间一样，将值设置更大，弹性空间也一样，但是这是由代价的，在内存加载的时候，每次都是按最大空间来分配的，显然，在排序场景，或者一些临时表聚合场景，更大的空间会产生明显的不利影响\n9.varchar是变长，char是定长，那能用varchar完全替代char么？ 回答：不能。varchar的优点是更灵活，但是char也有它的优势\n首先varchar会额外占用一个字节存储长度信息，而char则节省了一个字节；\n其次，char的存储空间是一次性分配的，存储是固定连续的，而varchar的存储的长度是可变的，当varchar更改前后的数据长度不一致时，就不可避免会出现碎片问题。针对此，需要进行碎片消除作业，也是额外的成本\n一般来说，长度固定的字段，还是用char比较合适，比如Hash，就很适合用char\n10.varchar(11)和int(11)中的11，有什么区别？ 回答：varchar中代表能存11个字符，int中只是代表显示长度，对大多数应用没有意义，只是规定一些工具用来显示字符的个数，比如int(1)和int(20)存储和计算其实是一样的\n11.delete和truncate的区别？ 回答：delete是删除行；truncate是整表删除。具体来说，有以下区别：\ntruncate之后，会释放空间；delete之后，不会释放空间，因为delete只是在行标记删除，后续可以复用；\ndelete因为是DML，会产生redo log；truncate是DDL则不会\ntruncate的效率更高\ntruncate之后，id从头开始；delete不会\n12.Mysql 有哪些存储引擎？ 回答：首先是InnoDB引擎，它提供了ACID事务的支持，并且还提供了行级锁和外键的约束。InnoDB的设计目的就是处理大数据容量的数据库系统\n还有MyIASM引擎，它是原本Mysql的默认引擎，不提供事务支持，也不支持行级锁和外键\n最后是一个MEMORY引擎，它的所有数据都是在内存中，数据的处理速度快，但是安全性不高，很少使用\n13.ACID是什么？ 回答：它是原子性、一致性、隔离性、持久性的缩写\n原子性：操作要么成功还是全失败\n一致性：数据执行前后保持一致\n隔离性：事务之间隔离，互不影响\n持久性：数据持久化，不会丢失\n14.主键和外键有什么区别？ 回答：主键是表中的一个或者多个字段，它的值用于唯一的标识表中的某一条记录\n外键是说某张表b的主键，在另外一张表a中被使用，那么a中该字段可以使用的范围取决于b。外键约束主要用来维护两张表之间数据的一致性\n15.那么一张表一定有主键吗？ 回答；是的，一定有。如果主动设置，则采用设置的，否则会自动生成一个默认的行\n16.你怎么查看有多少个SQL语句正在执行？ 回答：使用show processlist，它是显示用户正在运行的线程的命令。但是除非是root用户，或者进行了授权的用户，都只能看见自己正在运行的线程\n","date":"0001-01-01","id":36,"permalink":"/interviews/mysql/","summary":"分析：count()函数是返回表中某个列的非NULL值数量","tags":"","title":""},{"content":"HTTP的协议有什么特点？ HTTP协议基于文本传输的，支持不同的****数据格式，例如HTML、JSON、XML等数据格式，并且http是无状态的，每个http请求之间相互独立，采用了请求-应答模式，有很好的扩展性，可以通过扩展头部、方法等支持行方式\nHTTP报文格式？怎么分割 http的报文格式分为请求头、请求行、请求体，请求头包含了请求方式、url、http版本，请求行包含了key-value对的信息，有connection，content-lenth等字段，请求体包含了实际的请求数据；请求头和请求行通过/r/n进行分割，请求行和请求体通过一行空白行进行分割\nHTTP有什么方法？ GET、PUT、DELETE、post、head、options、trace、connect\n哪些http方法是安全的？哪些是幂等的 get、head是安全的 post、put、delete是不安全的\nget、head、put、delete是幂等的 post是不幂等的\nGET和POST请求的区别？追问：GET请求一定是安全且幂等的吗？ get请求是从服务器获取资源，post请求向服务器提交数据，\nget请求是读操作，是安全且幂等的；post请求因为会修改服务器的资源，且多次post请求会创建多个资源，所以是不安全且不幂等的 get请求一般是将请求参数放在url的查询字符串中，浏览器对url的长度有限制，所以get请求的请求参数有长度限制。post请求的数据放在请求体，post请求的请求参数没有长度限制\nHTTP有哪些状态码？ 100类：属于提示信息，为协议处理中的中间状态 200类：表示服务器成功处理客户端的请求\n200：表示成功处理，返回期望的结果 204：与200状态码相似，但是响应头没有body数据 206：http分块下载或断点续传的几次， 300类：表示请求的资源发生了变动，需要客户端用新的URL重新发送请求，就是重定向 301：永久性的重定向，后续请求可以直接重定向访问 302：临时访问， 304： 400类：表示客户端发送的报文有误，服务器无法处理 403：请求的权限不够 404：请求的资源不存在 500类：表示服务器处理 时内部发生了错误，属于服务器端的错误码 什么情况下会出现502错误码？ 502（Bad GateWay）表示码表示服务器在充当网关或代理时，在尝试满足请求时从它访问的入站服务器接收到无效响应 如果客户端访问服务是通过nginx来反向代理到应用服务器，那么如果应用服务器出现故障，导致nginx无法从应用服务获得响应，这时候nginx就会返回502错误码给客户端\n有个服务出现504错误码，这个服务出现了什么问题 504是网关超时错误，通过nginx将请求代理到后端应用，后端程序没有在规定时间内返回数据，需要开发检查接口超时问题，比如是否出现死循环、sql慢查询等\n重定向是哪一类状态码？临时重定向和永久重定向有什么区别？ 重定向是300类状态码，301表示永久重定向，302表示临时重定向 永久重定向，客户端会记忆重定向后的url，下次访问的时候不需要访问旧url，直接跳转新url访问 临时重定向，客户端会收到302状态码，不会记忆重定向后的url，下次访问依旧访问旧url，再跳转到新的url\nHTTP1.1和2.0的区别 2.0引入stream概念，可以在同一个tcp连接中，实现并发传输，而1.1不能并发传输，必须在一个请求结束之后才能进行下一个请求应答，浏览器是通过建立多个tcp连接，实现http1.1的并发，比较消耗内存\n报文改进，1.1发生的是文本数据，2.0发生二进制数据，通过HPACK算法压缩HTTP头部，提高了传输效率\nhttp2.0支持服务器主动推送数据\nHTTP2.0和HTTP3.0的区别？ HTTP2.0和HTTP3.0的最大区别是传输层使用的协议不同了，HTTP2.0使用的是TCP协议连接，HTTP3.0使用UDP协议；\nHTTP2.0会出现TCP队头阻塞问题，（http2.0的tcp阻塞问题，是因为http2.0的并发传输是在一条TCP连接上实现的，在传输过程中，如果某个stream发生了丢包，服务端不仅不能处理这个stream，也不会处理其他的stream，必须等丢失的包重传，才能继续处理其他stream，这个就发生了tcp队头阻塞），但是HTTP3.0通过一个在UDP协议上实现了一个可靠的QUIC协议，当stream发生丢包时，只会阻塞这个stream，其他stream不会受影响\nhttp3.0建立连接比http2.0高效，http3.0：3次握手就能建立连接+TLS握手成功；http2.0需要3次TCP握手+TLS四次握手\nhttp3.0在网络切换的环境下无需重新建立连接，通过在应用层的唯一id来确定连接\n简述JWT的原理和校验机制 jwt的数据个数是header.payload.signature，头部、负载、签名三部分组成，\nheader包含：令牌的类型以及令牌签名的算法\npayload：向服务器传递的数据，比如包含认证信息\n签名：对前面两部分的签名，防止数据篡改（使用在Header中公开的特点签名算法，通过特定的密钥（由服务器进行保密），对前面两部分进行加密计算\n验证JWT令牌的流程：\n服务端接收到客户端发来的JWT，取出header+payload，然后服务端根据自己的加密密钥进行加密计算 把加密的结果和客户端发来JWT的signature进行对比，如果完全相同，则表示前面两部分没有动，如果不相同表示被篡改了 当令牌没有被篡改后，服务端可以进行其它验证：令牌过期，用户是否有权限访问等 jwt令牌是由3个部分组成，分别是头部、负载、签名，头部包括类型和签名算法，负载包含了用户信息等数据，签名是对头部和负载两部分的签名，使用头部的签名算法，通过服务器的密钥对前面两部分内容进行加密计算\n校验jwt的过程是服务端接收到客户端发过来的jwt令牌后，服务端会取出头部和负载数据，然后用自己的密钥对头部和负载进行加密计算，将得到的加密结果和客户端发送过来的jwt的签名机械能对比，如果相同，表示前面两部分没有内中间人篡改，这个时候服务器可以进行其他检查，比如检查jwt是否过期，如果没有问题，正常执行业务逻辑\n什么是跨域？什么情况下会发生跨域？ 当网页尝试访问不同源的资源的使用，就会发生跨域，只要域名、协议、端口这三个信息任意一个不同，都认为是不同源的URL 可以用跨域资源共享技术，在服务器需要的响应头上添加Access-Control-Allow-Origin的字段，\n什么是Restful？RestFul请求的url有什么特点？ restful是一种api接口设计规范，用url定位资源，用http方法表示接口的动作，用http状态码表示接口处理的情况\nHTTP和HTTPS有什么区别？ 安全性：HTTP使用明文传输，HTTPS通过SSL/TLS协议对数据进行加密处理，提供更高的安全性和数据保护\n建立连接：HTTP建立只需要TCP三次握手；HTTPS在TCP三次握手后还需要进行SSL/TLS的握手过程\n端口：HTTP的端口是80；HTTPS的端口是443\n证书：HTTPS需要使用数字证书来验证服务器的身份，并确保数据传输的安全性。证书由第三方机构颁发，用于证明服务器的身份和所有权。而HTTP没有使用证书进行身份验证和加密。\n加密算法？ 对称加密算法，非对称加密算法，哈希算法\n3.3 HTTPS RSA 握手解析\nHTTPS建立连接过程 第一次TLS握手：客户端发送一个client hello消息，消息里面有客户端使用的TLS版本号、支持的密码套件、客户端生成的随机数， 第二次TLS握手：当服务端接收到客户端的消息后，会返回Server Hello消息，有确认的TLS版本号，密码套件，服务端生成的随机数。接着发送Server Certificate给客户端，包含数字证书，发送Server Hello Done消息 校验证书：客户端收到服务端的数字证书的时候，会对校验服务端的证书，如果证书合法，客户端会从CA机构的公钥解密数字证书拿到服务端的公钥 第三次TLS握手：客户端再次生成一个随机数，用服务端的公钥加密后，通过client key exchange消息传给服务端。服务端通过私钥解密得到客户端的第二个随机数。这里有三个随机数了，双方根据这三个随机数生成对称密钥。生成密钥后，客户端发一个消息给服务端开始使用对称加密方式发送消息，并且对之前发送的数据做个摘要，再用对称加密算法加密，让服务端做个验证，确保对称密钥是否可用，以及之前的握手信息是否被篡改 第四次握手：服务端也是同样操作，发送消息告诉客户端开始用对称加密方式发送消息，并且对数据做个摘要，并用对称密钥进行加密，让客户端做个校验，如果双方都验证加密和解密都没问题，那么TLS四次握手正式完成了。 HTTPS过程中进行了多少次非对称加密？多少次对称加密？ https握手之前： 服务端向CA机构注册证书时，CA机构会用CA私钥对服务端的公钥进行签名，形成数字证书，这里涉及到1次非对称加密 https握手期间： 客户端向服务端的公钥加密随机数，服务端再用私钥进行解密，这里涉及1次非对称加密 客户端和服务端生成对称密钥后，都需要对之前握手的数据做个摘要，并用对称密钥加密一下，这个过程客户端和服务端都涉及到，所以HTTPS握手期间用了两次对称加密，客户端和服务端都做了一次 https握手完成之后： https数据传输期间都是用对称密钥进行加密和解密 SSL握手流程为什么要使用非对称加密？ 为了保护对称密钥的安全\n为什么HTTPS不用非对称加密算法加密HTTP报文？ 非对称加密使用到了公钥和私钥，加密和解密的过程相对较慢， 不适合大数据的加密传输，相比之下对称加密算法比较快，适合大数据的加密，而HTTP报文包含大量的数据，如果使用非对称算法会导致性能下降和延迟增加\nHttps会对url进行加密，url属于http报文的头部信息，https会对整个http报文都加密，所以https是会对url加密的\n","date":"0001-01-01","id":37,"permalink":"/interviews/network/http/","summary":"HTTP协议基于文本传输的，支持不同的****数据格式，例如HTML、JSON、XML等数据格式，并且http是无状态的，每个http请求之间相互独立，采用了请求-应答模式，有很好的扩展性，可以通过扩展头部、方法等支持行方式","tags":"","title":""},{"content":"TCP三次握手 TCP头部有哪些字段？ tcp报文段 ： tcp头部+tcp数据部分\ntcp头部：\n源端口：16位 目的端口：16位 序号：32位 确认号：32位 数据偏移：4位 保留：6位 窗口：16位 校验和：16位 紧急指针：16位 选项和填充：最多为40字节 控制位： URG：紧急指针标志，为1时标识紧急指针有效，该报文应该优先传送，为0则忽略紧急指针 ACK：确认序号标志，为1时表示确认号有效。携带ACK标识的TCP报文段被称为确认报文段 RST：重置连接 SYN：表示请求建立一个连接 FIN：用于释放连接 PSH：为1表示带有push标志的数据，优先将这个报文提交给应用程序，而不是缓冲区排队 tcp头部的最长是60字节\n数据部分：。。。\n回答：tcp头部主要是源端口、目的端口、序列号、确认号、标记位：SYN、RST、ACK、FIN、头部长度、窗口大小，可扩展的选项等\n其中序列号和确认号的大小为32位，序列号保证数据的有序性，接收方按照发送方顺序发来的数据来组装有序的数据；确认号保证数据的可靠性，当发送方已发送的数据，超过一段时间没收到确认报文，就会重传报文。\n源端口和目的端口的大小是16位，源端口是发送方的端口号，目的端口是接收方使用的端口号，端口的作用是标识TCP连接是哪个进程\nTCP之报文首部格式 - Jummyer - 博客园\nTCP三次握手连接过程 客户端和服务端一开始都处于close状态，服务端会监听一个端口，处于listen状态\n第一次握手：客户端产生随机初始化序号，放到tcp报文头部的序号字段，同时把SYN标志设置位1，标识SYN报文。接着把SYN报文发送给服务端，之后客户端处于SYN_SEND状态\n服务端收到SYN报文后，服务端也生成随机初始化序号，放到TCP报文头部的序号字段中，对客户端的初始化序号+1作为确认号，放到TCP报文头部的确认应答字段中，并将SYN和ACK标志设置为1，表示SYN-ACK报文，把报文发送给客户端，之后服务端处于SYN_RECD状态\n客户端收到服务端SYN-ACK报文后，客户端发送一个ACK确认报文，该报文的确认号为服务端的初始化序号+1，并将ACK标志设置为1。客户端处于ESTABLISHED状态\n服务端收到ACK确认报文，服务端也处于ESTABLISHED状态\n以上就是TCP三次握手的过程\n4.1 TCP 三次握手与四次挥手面试题\n为什么需要三次握手？两次握手不行吗？ 避免历史连接的建立，避免资源浪费\n三次握手可以确认客户端和服务端是否同时具备发送和接收的能力\n如果第二次握手丢包，会发送什么？ 超时重传机制，第二次SYN-ACK报文中有\n第二次报文中的ACK，是第一次握手的确认报文，那么当第二次报文丢包时，会导致客户端一直没有接收到ACK而触发超时重传机制，重传SYN包，即第一次握手\n第二次报文中的SYN，是服务端建立TCP连接的报文，当第二次报文丢失后，客户端没有发送ACK报文，服务端没有收到第三次握手，于是服务端会触发超时重传机制，重传SYN-ACK报文\n如果第三次握手丢包，会发生什么？ 我的理解是第三次握手如果发生丢包，服务端会迟迟接收不到第三次握手的ACK包，触发超时重传机制，服务端会重新发生第二次握手的SYN-ACK包，直到最大重传次数的限制，或者收到第三次握手\nTCP的半连接队列和全连接队列？ 在tcp三次握手的时候，linux内核会维护两个队列，分别是：\nsyn队列：半连接队列\naccept队列：全连接队列\n服务端收到客户端发起的SYN请求后，内核会将为握手完成的连接存储到半连接队列，等待完成三次握手后转移到全连接队列\n全连接队列：服务端收到客户端的第三次握手，内核会将连接从半连接队列移除，然后创建新的完全连接，并将其添加到全连接队列，等待进程调用accept函数将连接取出\n4.4 TCP 半连接队列和全连接队列\nTCP四次挥手 TCP四次挥手的过程 tcp的四次挥手（断开连接）是可以客户端或者服务端断开\n客户端关闭连接，此时会发生一个fin报文，之后客户端进入fin_wait_1状态，\n服务端收到fin报文后，将向客户端发送ack报文，接着服务端进入close_wait状态\n客户端接收到ack应答报文后，之后进入fin_wait_2状态\n等待服务端处理完数据后，向客户端发送fin报文，服务端进入last_ack状态\n客户端收到服务端的fin报文后，回一个ack应答报文，客户端进入time_wait状态\n服务端接收到ack报文后，进入close状态，至此服务端完成连接的关闭\n客户端在time_wait状态经过2MSL一段时间后，自动进入close状态，至此客户端也完成连接的关闭\n为什么TCP需要四次挥手？ TCP是全双工协议，双方都具有发送和接收的能力，那么断开连接的期间，要确保双方能发送完自己的数据\n当客户端想要断开连接，发送fin报文给服务端，服务端接收到fin包后返回一个ack报文，但是此时还不会立即断开连接，因为服务端可能还有数据需要发送，需要等待数据发送完成后，由服务端主动发送fin报文给客户端，表示数据发送完成了可以断开连接。所以第二次和第三次挥手通常不会合并一起发送，而是分开发送，所以需要四次挥手\n如果只有三次挥手，那么就可能出现一方还要数据没有发送完就被迫关闭连接，这就会导致数据的丢失\nTIME_WAIT是如何产生的？ 当TCP连接的主动关闭方关闭连接时，与被动方进行了四次挥手的时候，在主动关闭方发送完第四次挥手后，也就是最后一个ack报文，主动关闭方的TCP连接回会进入time_wait状态，这个状态会维持2MSL的时间，以确保对方接收到最后一个ACK报文\nTIME_WAIT过多有什么危害？ 占用系统资源，比如内存资源，线程资源等（服务端TIME_WAIT过多）\n占用端口资源，端口资源是有限的（客户端TIME_WAIT过多）\nTDP和UDP TCP和UDP有什么区别？ 连接、可靠性、传输方式\nTCP是面向连接的协议，在发送数据的时候需要进行三次握手；而UDP是无连接的协议，可以直接发送数据\nTCP会通过超时重传、流量控制、拥塞控制保证数据的可靠性；而UDP不考虑数据的可靠性\nTCP发送的数据是以字节流的形式，没有边界；而UDP是一个包一个包的发送，是有边界的\nTCP vs UDP——哪个协议更快？\n什么时候用TCP？什么使用用UDP？ 如果关注数据的可靠性和有序性，可以选择TCP，比如FTP协议，HTTP协议都是基于TCP协议进行传输数据\n如果需要数据快速传输和实时性，不在意某些数据包的丢失，可以考虑UDP，例如视频会议、直播等场景\nlearn.lianglianglee.com\n视频会议用的是UDP还是TCP？如果使用TCP发送丢包会怎么样？ 视频会议使用的是UDP，因为视频会议的实时性很重要；UDP协议的实时性比TCP协议更好，采用UDP协议传输音视频的话，如果发生了丢包，只会出现一瞬间的卡顿，丢失该时刻的视频和音频，还可以继续进行沟通；如果采用TCP协议，由于TCP的可靠传输，如果发生丢包，可能画面会卡住不动，等待丢包重传才会推进画面，这样实时性就比较差了\nUDP怎么改造为可靠运输？ 在应用层实现，添加序列号字段和确认号字段，实现超时重传机制；\n开辟缓冲区，实现滑动窗口，不仅可以实现流量控制还可以控制拥塞\nUDP和TCP可以共用一个端口吗？ 可以，socket是根据五元组信息唯一确认的：协议类型、源ip地址、源端口、目标ip地址、目标端口，只要有一个信息不同，就认为是不同的socket，不会引起冲突，所以TCP和UDP可以使用一个端口号\nTCP可靠性 4.2 TCP 重传、滑动窗口、流量控制、拥塞控制\nTCP的可靠性如何保证？ 建立连接：三次握手，确保双方都有接收和发生数据的能力，避免历史数据的建立\n超时重传机制：如果发生方迟迟没有接收到回文，就会触发超时重传机制，重新发送报文\n滑动窗口机制：tcp有流量控制机制，可以根据接收方的滑动窗口大小来发送报文，避免报文发送的数据太大，导致接收方接收不了数据导致丢包\n拥塞控制：tcp有拥塞控制机制，通过慢启动、拥塞避免、拥塞发送等算法调整发送速率避免网络拥塞。当网络出现拥塞时，TCP会降低发送速率，减少网络负载，保证数据的可靠传输\nTCP流量控制和拥塞控制有什么区别？ 流量控制是端到端，保护接收方不被数据淹没\n拥塞控制是网络层面的控制，保护网络不被过载\n滑动窗口是怎么实现的？解决什么问题？ 滑动窗口在发送方和接收方都有一个缓冲区，在发送方表示可发送的最大数据量，在接收方表示可接收的最大数据量\n发送方有了滑动窗口后，那么发送方可以不用等待接收方的确认报文，就可以继续发送下一批数据，提高传输效率\n接收方有了滑动窗口后，可以实现流量控制，让发送方按照自己的接收情况来发送数据，避免对方发送数据太快，导致接收方处理不过来\n","date":"0001-01-01","id":38,"permalink":"/interviews/network/tcp/","summary":"tcp报文段 ： tcp头部+tcp数据部分","tags":"","title":""},{"content":"ping的原理简述： ping命令是用来探测目标ip地址是否可以访问 Ping是通过ICMP协议实现的，ping的时候，会向接收方发送回送请求的ICMP报文，对方接收到后，会回复类型为回送应答的ICMP报文\n交换机和路由器有什么区别？ 交换机工作在MAC层，称为二层网络设备，主要负责数据帧的转发和交换，交换机会根据MAC地址来转发数据包，是实现局域网内设备的通信 路由器工作在IP层，称为三层网络设备，主要负责IP数据包的转发和路由选择，路由器会根据IP地址来转发数据包，实现不同网络间的通信 IP地址和MAC地址有什么区别？ IP地址用于网络中唯一标识和定位设备，它是网络层使用的地址，用于实现不同网络之间的通信 MAC地址用于局域网中唯一标识和定位设备，它在数据链路层使用的地址，实现局域网内设备之间的通信 NAT协议 网络地址转换协议NAT功能详解及NAT基础知识介绍\n5.1 IP 基础知识全家桶\n192.168.1.100/24中斜杠代表什么意思？ 斜杠（/）后面的数字表示子网掩码的位数\n比如，192.168.1.100/24中的斜杠后面数字表示子网掩码的位数，子网掩码用于划分IP地址中的网络部分和主机部分。将子网掩码和IP地址进行与运算，就可以得到网络号\n具体来说：192.168.1.100/24表示前24位是网络部分，后8位是主机部分\n","date":"0001-01-01","id":39,"permalink":"/interviews/network/%E7%BD%91%E7%BB%9C%E5%B1%82/","summary":"网络地址转换协议NAT功能详解及NAT基础知识介绍","tags":"","title":""},{"content":"OSI的7层网络模型？各层的协议有什么？ 应用层：确定进程间通信的性质以及满足用户需要以及提高网络和用户应用 表示层：主要解决用户信息的语法表达 会话层：复制建立、管理和终止表示层实体之间的通信会话 传输层：实现网络不同主机上的用户进程间的数据通信，可靠和不可靠的传输 网络层：本层通过IP寻址来建立两个节点之间的连接 数据链路层：将上层数据封装成帧，用MAC地址访问媒介 物理层：设备之间比特流的传输，物理接口 回答： OSI参考模型有7层，应用层、表示层、会话层、传输层、网络层、数据链路层、物理层 应用层有HTTP、HTTPS，传输层有TCP和UDP协议，网络层有IP、ICMP、ARP协议\n网络分层的好处：对各层之间进行解耦，层与层之间不产生关联，比如应用层HTTP协议从HTTP1.1升级到HTTP2.0的时候，不会对传输层和网络层有影响，或者网络层的IPv4协议升级到IPv6协议的时候，不会影响到应用，传输层\nTCP/IP协议是将OSI模型的应用层、表示层、会话层统一为应用层，数据链路层和物理层统一为网络接口层\nTCP/IP的四层网络模型？ 应用层 传输层 网络层 数据链路层（网络接口层） 五层因特网协议栈？ 应用层、运输层、网络层、链路层、物理层\nOSI七层网络协议 TCP/IP四层概念模型 对于网络协议 应用层\n\u0026mdash;\n表示层\n\u0026mdash;\n会话层 应用层（4） HTTP、TFTP、FTP、NFS、WAIS、SMTP\n\u0026ndash;\nTelnet、Rlogin、SNMP、Gopher\n\u0026ndash;\nSMTP、DNS 键入网址场景问题 键入网址后，期间发送了什么？ http/https -\u0026gt; dns -\u0026gt; tcp -\u0026gt; ip -\u0026gt; arp\n浏览器会解析网址，解析出域名，资源路径，端口等信息，构造HTTP请求报文 将域名解析为IP地址，先查看系统缓存是否有域名信息，有的话返回IP地址；没有就查看本地host文件没有域名信息，有就返回IP地址；如果再没有就查看本地DNS服务器，如果本地DNS服务器中有域名信息，就返回IP地址，否则本地DNS服务器分别去根域名服务器-\u0026gt;顶级域名服务器-\u0026gt;权威域名服务器询问，最后拿到IP地址 HTTP协议是基于TCP协议传输的，所以要先进行TCP三次握手， 然后到网络层，加上IP头，同时填上目标IP地址和源IP地址 然后到数据链路层，通过ARP协议，获取路由器的MAC地址，然后加上MAC头，填上目标MAC地址和源MAC地址 然后到物理层，直接把数据包转发给路由器，路由器再通过下一跳，找到最终的目的服务器 当双方完成三次握手后，如果是HTTP协议，客户端就会把HTTP请求发送给目标服务器；如果是HTTPS协议，还需要进行TLS四次握手，客户端才会把HTTP报文发送给目标服务器 目标服务器收到HTTP报文后，返回HTTP响应消息，浏览器对响应消息进行解析渲染，呈现给用户 DNS是如何解析的？属于哪一层的协议？ DNS属于应用层的协议，客户端在进行DNS解析时，首先会查看浏览器和操作系统是否缓存域名对应的IP地址，如果没有就向本地DNS服务器发出查询请求，接着本地DNS向根DNS发送查询请求，根DNS服务器返回顶级域名服务器地址，本地DNS服务器向顶级域名服务器发送查询请求，顶级域名服务器返回权威域名服务器的IP地址，本地DNS服务器再向权威域名服务器发出查询请求，权威域名服务器收到请求后，就返回域名对应的IP地址了，本地DNS服务器返回查询结果给客户端，然后将本次查询得到的结果保存到缓存里，以备下次使用\nDNS域名解析使用的是什么协议？ DNS中，域名的解析是通过UDP协议进行的\nUPD是一种无连接的传输层协议，提供了一种简单的传输机制，适用于实时性比较高的应用场景。DNS使用UDP协议进行域名解析是因为域名解析是短小且频繁的请求，UDP的无连接特性可以减少建立连接和断开连接的开销，提高传输效率\nUPD协议对于TCP协议的缺点是没办法保证数据传输的可靠性，针对这个缺点可以在应用层实现超时重传机制，如果域名解决请求在一定的时间内没有收到响应，那么就重发域名解析\n输入域名怎么找到端口号？ http的默认端口是80；https的默认端口号是443； 如果用户指定了端口，可以在url中获取，比如域名:8080，这时候使用的端口是8080\n网络传输场景 tcp连接一个不存在的IP地址会发生什么？ 如果IP地址是局域网内，客户端的内核在发生arp请求的时候，广播这个目标IP是谁的，但是由于网络中不存在这个IP地址，所以没有设备应答，会卡在arp协议，客户端的SYN报文无法发送出去 如果这个IP地址不是局域网的，客户端会将SYN报文交给路由器，由路由器继续转发，由于目标IP地址是不存在的，该SYN报文会在网络中消亡；客户端由于一直接收不到SYN报文的确认报文，会触发超时重传机制，直到最大的重试次数，客户端的连接会被释放 tcp连接一个IP地址存在但是端口不存在的服务端会发生什么？ 端口不存在的话，代表服务端没有监听这个端口，服务端在接收到客户端的SYN包后，返回RST报文，客户端接收到RST报文后，会断开连接\nUDP发送一个IP地址存在但是端口不存在报文会发生什么？ 服务端会回ICMP报文，报告端口不可用\n","date":"0001-01-01","id":40,"permalink":"/interviews/network/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/","summary":"网络分层的好处：对各层之间进行解耦，层与层之间不产生关联，比如应用层HTTP协议从HTTP1.1升级到HTTP2.0的时候，不会对传输层和网络层有影响，或者网络层的IPv4协议升级到IPv6协议的时候，不会影响到应用，传输层","tags":"","title":""},{"content":"2.1 TCP/IP网络模型 2.1 TCP/IP 网络模型有哪几层？\n前言：为什么要有TCP/IP网络模型？\n答：为了提供一套 通用的 网络协议\n因为在一台设备上的进程间通信有很多方式，比如管道、消息队列、共享内存、信号等方式，而对于不同的设备上的进程间通信，就需要网络通信，而设备是多样性的，需要兼容多种多样的设备，就需要一套 通用的网络协议\n这个网络协议是分层的，每一层都有各自的作用和责任\nTCP/IP网络模型分为4层：应用层\u0026ndash;\u0026gt;传输层\u0026ndash;\u0026gt;网络层\u0026ndash;\u0026gt;网络接口层(由上到下)\n接下来根据 [TCP/IP 网络模型 ]分别对每一层进行介绍：\n应用层（最上层） 最上层的，也是我们能直接接触到的就是应用层(Application Layer)，我们使用的应用软件都是在应用层实现的，当两台不同的设备的应用需要通信的时候，应用就把应用数据传给下一层，也就是传输层。\n应用层接收数据后把数据传入传输层\n所以，应用层只需要专注于为用户提供应用功能，比如HTTP、FTP、Telnet、DNS、SMTP等\n应用层不用关心数据是如何传输\n应用层是工作在操作系统的用户态，传输层****及其一下则工作在内核态\n传输层 应用层的数据包会传输到传输层，传输层(Transport Layer) 是为应用层提供网络支持\n在传输层会有两个传输协议，分别为TCP和UDP\nTCP的全称是“传输控制协议”(Transmission Control Protocol)，大部分应用使用的正是TCP传输层协议，比如HTTP应用层协议。\nTCP有很多特征：流量控制、超时重传、拥塞控制等，这些保证了数据包能可靠地传输给对方\nUDP相对来说比较协议，简单到只负责发送数据包，不保证数据包是否能抵达对方，但是实时性相对更好，传输效率也高。\nUDP也可以实现可靠传输，把TCP的特性在应用层上实现就行，（不过要实现一个商用的可靠UDP传输协议也不简单）\n应用需要传输的数据可能会非常大，如果直接传输就不好控制，因此当传输层的数据包大小超过MSS（TCP最大报文段长度），就要将数据包分块，这样即使在传输过程中一个分块缺失或者损坏了，只需要重新发送这一分开，而不用重新发送整个数据包。\n在TCP协议中，每一个分块称为一个TCP段(TCP Segment)\n当设备作为接收方时，传输层则要负责把数据包传给应用层，但是一台设备上可能会有很多应用在接收或者传输数据，因此需要一个编号将应用区分开来，这个编号就是端口\n比如 80 端口通常是 Web 服务器用的，22 端口通常是远程登录服务器用的。而对于浏览器（客户端）中的每个标签栏都是一个独立的进程，操作系统会为这些进程分配临时的端口号。\n由于传输层的报文中会携带端口号，因此接收方可以识别出该报文是发送给哪个应用。\n传输层并不负责将数据从一个设备传输到另一个设备\n网络层 在实际场景中，一个设备的数据要传输给另一个设备，就需要在各种各样的路径和节点进行选择，其中的网络环节是错综复杂的。而传输层的设计理念是简单、高效、专注，如果传输层还负责这一块功能就有点违背设计原则\n我们不希望传输层协议处理太多的事情，只需要服务好应用即可，让其作为应用间数据传输的媒介，帮助实现应用到应用的通信，而实际的传输功能就交给下一层，也就是网络层(Internet Layer)\n个人理解：应用层把大量的数据发送给传输层，传输层将这些大量的数据进行打包，分段，确定好目的应用，然后由网络层进行传输。\n网络层最常用的是IP协议(Internet Protocol)，IP协议会将传输层的报文作为数据部分，再加上IP包头组装成IP报文，如果IP报文大小超过了MTU(以太网中一般为1500字节)就会再次进行分片，得到一个继续发送网络的IP报文\n网络层负责将数据从一个设备传输到另一个设备，但是世界上那么多设备，如何找到对方呢，因此，网络层需要有区分设备的编号\n一般用IP地址给设备进行编号，对于IPv4协议，IP地址共32位，分成了四段（比如127.0.0.1，分成四段，每段8位）。但是寻址起来特别麻烦，不能一个一个去匹配。\n因此，需要将IP地址分成两种意义：\n一个是网络号，负责标识该IP地址是属于那个[ 子网 ]的\n一个是主机号，负责标识同一[ 子网 ]下的不同主机\n怎么区分网络号和主机号呢？这需要配合子网掩码才能算出IP地址的网络号和主机号\n举个例子，比如 10.100.122.0/24，后面的/24表示就是 255.255.255.0 子网掩码，255.255.255.0 二进制是「11111111-11111111-11111111-00000000」，大家数数一共多少个1？不用数了，是 24 个1，为了简化子网掩码的表示，用/24代替255.255.255.0。\n知道了子网掩码，该怎么计算出网络地址和主机地址呢？\n将 10.100.122.2 和 255.255.255.0 进行按位与运算，就可以得到网络号，如下图：\n将 255.255.255.0 取反后与IP地址进行进行按位与运算，就可以得到主机号\n~255.255.255.0 = 0.0.0.255\n除了寻找能力，IP协议还有另一个重要的能力是路由。实际场景中，两台设备并不是用一条网线连接，而是通过很多网关、路由器、交换机等众多网络设备连接起来的。那么就会形成很多条网络的路径，因此当数据包到达一个网络节点，就需要通过路由算法决定下一步哪条路径\n路由器寻找工作中，就需要目标地址的子网，找到后进而把数据包发送到对应的网络内\n所以，IP 协议的寻址作用是告诉我们去往下一个目的地该朝哪个方向走，路由则是根据「下一个目的地」选择路径。寻址更像在导航，路由更像在操作方向盘\n网络接口层 生成IP头部后，接下来就是网络接口层(Link Layer)在IP头部的前面加上MAC头部，并封装成数据帧(Data frame)发送到网络上\nIP 头部中的接收方 IP 地址表示网络包的目的地，通过这个地址我们就可以判断要将包发到哪里，但在以太网的世界中，这个思路是行不通的。\n什么是以太网呢？电脑上的以太网接口，Wi-Fi接口，以太网交换机、路由器上的千兆，万兆以太网口，还有网线，它们都是以太网的组成部分。以太网就是一种在「局域网」内，把附近的设备连接起来，使它们之间可以进行通讯的技术。\n以太网在判断网络包目的地时和 IP 的方式不同，因此必须采用相匹配的方式才能在以太网中将包发往目的地，而 MAC 头部就是干这个用的，所以，在以太网进行通讯要用到 MAC 地址。\nMAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息，我们可以通过 ARP 协议获取对方的 MAC 地址。\n所以说，网络接口层主要为网络层提供「链路级别」传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。\n总结 综上所述，TCP/IP 网络通常是由上到下分成 4 层，分别是应用层，传输层，网络层和网络接口层。\n网络接口层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message）。但这些名词并没有什么本质的区分，可以统称为数据包。\n","date":"0001-01-01","id":41,"permalink":"/notes/cs/net/tcpip%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/","summary":"2.1 TCP/IP 网络模型有哪几层？","tags":"","title":""}]